[2023-03-03 14:48:55,806] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T14:48:51.747577+00:00 [queued]>
[2023-03-03 14:48:55,857] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T14:48:51.747577+00:00 [queued]>
[2023-03-03 14:48:55,858] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-03-03 14:48:55,859] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-03-03 14:48:55,859] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-03-03 14:48:55,922] {taskinstance.py:1377} INFO - Executing <Task(SparkSubmitOperator): spark_submit> on 2023-03-03 14:48:51.747577+00:00
[2023-03-03 14:48:55,934] {standard_task_runner.py:52} INFO - Started process 306 to run task
[2023-03-03 14:48:55,950] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'avg_product_price', 'spark_submit', 'manual__2023-03-03T14:48:51.747577+00:00', '--job-id', '14', '--raw', '--subdir', 'DAGS_FOLDER/avg_product_price.py', '--cfg-path', '/tmp/tmpzkw686pk', '--error-file', '/tmp/tmpn1fyptr0']
[2023-03-03 14:48:55,960] {standard_task_runner.py:80} INFO - Job 14: Subtask spark_submit
[2023-03-03 14:48:56,135] {task_command.py:370} INFO - Running <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T14:48:51.747577+00:00 [running]> on host 7f5e973bdd66
[2023-03-03 14:48:56,415] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ayyoub
AIRFLOW_CTX_DAG_ID=avg_product_price
AIRFLOW_CTX_TASK_ID=spark_submit
AIRFLOW_CTX_EXECUTION_DATE=2023-03-03T14:48:51.747577+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-03-03T14:48:51.747577+00:00
[2023-03-03 14:48:56,446] {base.py:68} INFO - Using connection ID 'spark-hadoop' for task execution.
[2023-03-03 14:48:56,448] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master local[*] --name arrow-spark /hadoop-data/map_reduce/spark/average_price.py
[2023-03-03 14:49:08,095] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO SparkContext: Running Spark version 3.3.2
[2023-03-03 14:49:08,429] {spark_submit.py:495} INFO - 23/03/03 14:49:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-03-03 14:49:08,829] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO ResourceUtils: ==============================================================
[2023-03-03 14:49:08,831] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-03-03 14:49:08,832] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO ResourceUtils: ==============================================================
[2023-03-03 14:49:08,834] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO SparkContext: Submitted application: average_product_price
[2023-03-03 14:49:08,935] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-03-03 14:49:08,994] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO ResourceProfile: Limiting resource is cpu
[2023-03-03 14:49:08,997] {spark_submit.py:495} INFO - 23/03/03 14:49:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-03-03 14:49:09,245] {spark_submit.py:495} INFO - 23/03/03 14:49:09 INFO SecurityManager: Changing view acls to: ***
[2023-03-03 14:49:09,246] {spark_submit.py:495} INFO - 23/03/03 14:49:09 INFO SecurityManager: Changing modify acls to: ***
[2023-03-03 14:49:09,248] {spark_submit.py:495} INFO - 23/03/03 14:49:09 INFO SecurityManager: Changing view acls groups to:
[2023-03-03 14:49:09,250] {spark_submit.py:495} INFO - 23/03/03 14:49:09 INFO SecurityManager: Changing modify acls groups to:
[2023-03-03 14:49:09,254] {spark_submit.py:495} INFO - 23/03/03 14:49:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2023-03-03 14:49:10,353] {spark_submit.py:495} INFO - 23/03/03 14:49:10 INFO Utils: Successfully started service 'sparkDriver' on port 33017.
[2023-03-03 14:49:10,462] {spark_submit.py:495} INFO - 23/03/03 14:49:10 INFO SparkEnv: Registering MapOutputTracker
[2023-03-03 14:49:10,624] {spark_submit.py:495} INFO - 23/03/03 14:49:10 INFO SparkEnv: Registering BlockManagerMaster
[2023-03-03 14:49:10,721] {spark_submit.py:495} INFO - 23/03/03 14:49:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-03-03 14:49:10,726] {spark_submit.py:495} INFO - 23/03/03 14:49:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-03-03 14:49:10,755] {spark_submit.py:495} INFO - 23/03/03 14:49:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-03-03 14:49:10,913] {spark_submit.py:495} INFO - 23/03/03 14:49:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0e2ced2c-0051-4d88-bc31-2859036417b9
[2023-03-03 14:49:11,011] {spark_submit.py:495} INFO - 23/03/03 14:49:11 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-03-03 14:49:11,092] {spark_submit.py:495} INFO - 23/03/03 14:49:11 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-03-03 14:49:15,236] {spark_submit.py:495} INFO - 23/03/03 14:49:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-03-03 14:49:16,269] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO Executor: Starting executor ID driver on host 7f5e973bdd66
[2023-03-03 14:49:16,292] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-03-03 14:49:16,384] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33477.
[2023-03-03 14:49:16,385] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO NettyBlockTransferService: Server created on 7f5e973bdd66:33477
[2023-03-03 14:49:16,391] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-03-03 14:49:16,419] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 14:49:16,436] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO BlockManagerMasterEndpoint: Registering block manager 7f5e973bdd66:33477 with 434.4 MiB RAM, BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 14:49:16,447] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 14:49:16,451] {spark_submit.py:495} INFO - 23/03/03 14:49:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 14:49:19,812] {spark_submit.py:495} INFO - 23/03/03 14:49:19 INFO AsyncEventQueue: Process of event SparkListenerResourceProfileAdded(Profile: id = 0, executor resources: cores -> name: cores, amount: 1, script: , vendor: ,memory -> name: memory, amount: 1024, script: , vendor: ,offHeap -> name: offHeap, amount: 0, script: , vendor: , task resources: cpus -> name: cpus, amount: 1.0) by listener AppStatusListener took 1.2574545s.
[2023-03-03 14:49:24,538] {spark_submit.py:495} INFO - 23/03/03 14:49:24 INFO AsyncEventQueue: Process of event SparkListenerExecutorAdded(1677854956345,driver,org.apache.spark.scheduler.cluster.ExecutorInfo@76a0a8c4) by listener AppStatusListener took 4.6977918s.
[2023-03-03 14:50:45,334] {spark_submit.py:495} INFO - 23/03/03 14:50:45 INFO AsyncEventQueue: Process of event SparkListenerApplicationStart(average_product_price,Some(local-1677854956036),1677854948029,***,None,None,None) by listener AppStatusListener took 80.4256521s.
[2023-03-03 14:50:47,727] {spark_submit.py:495} INFO - /opt/spark-3.3.2-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2023-03-03 14:50:49,783] {spark_submit.py:495} INFO - 23/03/03 14:50:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-03-03 14:50:49,822] {spark_submit.py:495} INFO - 23/03/03 14:50:49 INFO SharedState: Warehouse path is 'file:/home/***/spark-warehouse'.
[2023-03-03 14:51:04,041] {spark_submit.py:495} INFO - 23/03/03 14:51:04 INFO InMemoryFileIndex: It took 1928 ms to list leaf files for 1 paths.
[2023-03-03 14:51:09,239] {spark_submit.py:495} INFO - 23/03/03 14:51:09 INFO InMemoryFileIndex: It took 81 ms to list leaf files for 1 paths.
[2023-03-03 14:51:34,269] {spark_submit.py:495} INFO - 23/03/03 14:51:27 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@219adfb3)) by listener AppStatusListener took 1.0046536s.
[2023-03-03 14:51:41,396] {spark_submit.py:495} INFO - 23/03/03 14:51:41 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@219adfb3)) by listener SQLAppStatusListener took 2.3408988s.
[2023-03-03 14:52:41,620] {spark_submit.py:495} INFO - 23/03/03 14:52:40 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map()) by listener AppStatusListener took 6.8339994s.
[2023-03-03 14:52:46,643] {spark_submit.py:495} INFO - 23/03/03 14:52:45 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@222292)) by listener AppStatusListener took 2.7147017s.
[2023-03-03 14:53:19,950] {spark_submit.py:495} INFO - 23/03/03 14:53:18 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@77b21262)) by listener AppStatusListener took 1.1290285s.
[2023-03-03 14:53:59,964] {spark_submit.py:495} INFO - 23/03/03 14:53:58 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@4b28ddbc)) by listener AppStatusListener took 2.1910053s.
[2023-03-03 14:54:35,839] {spark_submit.py:495} INFO - 23/03/03 14:54:33 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map()) by listener AppStatusListener took 1.8184337s.
[2023-03-03 14:54:51,193] {spark_submit.py:495} INFO - 23/03/03 14:54:47 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@2f8c0639)) by listener AppStatusListener took 6.5932184s.
[2023-03-03 14:55:12,947] {spark_submit.py:495} INFO - 23/03/03 14:55:10 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map()) by listener AppStatusListener took 1.2445308s.
[2023-03-03 14:55:43,674] {spark_submit.py:495} INFO - 23/03/03 14:55:40 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@3e2b87e8)) by listener AppStatusListener took 4.4153461s.
[2023-03-03 14:56:21,270] {spark_submit.py:495} INFO - 23/03/03 14:56:16 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map()) by listener AppStatusListener took 9.020431s.
[2023-03-03 14:56:41,355] {spark_submit.py:495} INFO - 23/03/03 14:56:31 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map()) by listener ExecutionListenerBus took 1.048866s.
[2023-03-03 14:57:03,208] {spark_submit.py:495} INFO - 23/03/03 14:56:52 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@59edb34d)) by listener AppStatusListener took 4.916027s.
[2023-03-03 14:58:16,002] {spark_submit.py:495} INFO - 23/03/03 14:57:57 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6992b66c)) by listener ExecutionListenerBus took 1.7178942s.
[2023-03-03 14:58:56,318] {spark_submit.py:495} INFO - 23/03/03 14:58:16 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6992b66c)) by listener AppStatusListener took 18.2645022s.
[2023-03-03 14:59:13,089] {spark_submit.py:495} INFO - 23/03/03 14:58:53 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6992b66c)) by listener HeartbeatReceiver took 1.3424545s.
[2023-03-03 14:59:29,434] {spark_submit.py:495} INFO - 23/03/03 14:59:12 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6992b66c)) by listener SQLAppStatusListener took 1.3916935s.
[2023-03-03 15:17:25,323] {spark_submit.py:495} INFO - 23/03/03 15:17:09 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6755452e)) by listener ExecutionListenerBus took 1.1806536s.
[2023-03-03 15:18:02,004] {spark_submit.py:495} INFO - 23/03/03 15:17:09 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6755452e)) by listener HeartbeatReceiver took 1.1805461s.
[2023-03-03 15:18:32,468] {spark_submit.py:495} INFO - 23/03/03 15:17:21 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6755452e)) by listener AppStatusListener took 25.7258271s.
[2023-03-03 15:19:00,616] {spark_submit.py:495} INFO - 23/03/03 15:18:17 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@6755452e)) by listener SQLAppStatusListener took 2.6622098s.
[2023-03-03 15:19:25,768] {spark_submit.py:495} INFO - 23/03/03 15:19:18 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@636add1c)) by listener ExecutionListenerBus took 1.1028069s.
[2023-03-03 15:20:12,781] {spark_submit.py:495} INFO - 23/03/03 15:19:18 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@636add1c)) by listener AppStatusListener took 11.1694711s.
[2023-03-03 15:20:12,783] {spark_submit.py:495} INFO - 23/03/03 15:20:12 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from 7f5e973bdd66:33017 in 10000 milliseconds
[2023-03-03 15:20:12,852] {spark_submit.py:495} INFO - 23/03/03 15:20:12 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 171942 ms exceeds timeout 120000 ms
[2023-03-03 15:20:13,126] {spark_submit.py:495} INFO - 23/03/03 15:20:12 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:13,217] {spark_submit.py:495} INFO - org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
[2023-03-03 15:20:13,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
[2023-03-03 15:20:13,238] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
[2023-03-03 15:20:13,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
[2023-03-03 15:20:13,259] {spark_submit.py:495} INFO - at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
[2023-03-03 15:20:13,263] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
[2023-03-03 15:20:13,270] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:13,277] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1053)
[2023-03-03 15:20:13,286] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:13,289] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:13,294] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:13,299] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:13,304] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:13,306] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:13,309] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:13,313] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:13,418] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:13,428] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:13,445] {spark_submit.py:495} INFO - Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
[2023-03-03 15:20:13,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
[2023-03-03 15:20:13,464] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
[2023-03-03 15:20:13,471] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:293)
[2023-03-03 15:20:13,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:13,491] {spark_submit.py:495} INFO - ... 12 more
[2023-03-03 15:20:13,497] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN NettyRpcEnv: Ignored message: true
[2023-03-03 15:20:13,503] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(true)
[2023-03-03 15:20:13,505] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN NettyRpcEnv: Ignored message: true
[2023-03-03 15:20:13,510] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN NettyRpcEnv: Ignored message: true
[2023-03-03 15:20:13,512] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN NettyRpcEnv: Ignored message: true
[2023-03-03 15:20:13,520] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN NettyRpcEnv: Ignored message: true
[2023-03-03 15:20:14,067] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN NettyRpcEnv: Ignored message: true
[2023-03-03 15:20:14,118] {spark_submit.py:495} INFO - 23/03/03 15:20:13 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:14,126] {spark_submit.py:495} INFO - 23/03/03 15:20:13 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:14,128] {spark_submit.py:495} INFO - 23/03/03 15:20:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:14,133] {spark_submit.py:495} INFO - 23/03/03 15:20:13 WARN SparkContext: Killing executors is not supported by current scheduler.
[2023-03-03 15:20:14,279] {spark_submit.py:495} INFO - 23/03/03 15:20:14 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:14,285] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:14,295] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:14,313] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:14,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:14,319] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:14,321] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:14,323] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:14,324] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:14,326] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:14,327] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:14,328] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:14,329] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:14,330] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:14,331] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:14,338] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:14,341] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:14,350] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:14,351] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:14,357] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:14,383] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:14,393] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:14,401] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:14,405] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:14,418] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:14,420] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:14,422] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:14,432] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:14,435] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:14,445] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:14,447] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:14,449] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:14,451] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:14,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:14,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:14,520] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:14,522] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:14,537] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:14,569] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:14,574] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:14,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:14,595] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:14,599] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:14,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:14,641] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:14,654] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:14,681] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:14,682] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:14,684] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:14,689] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:14,726] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:14,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:14,741] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:14,743] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:14,748] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:14,755] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:14,763] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:14,774] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:14,786] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:14,801] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:14,802] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:14,804] {spark_submit.py:495} INFO - 23/03/03 15:20:14 ERROR Inbox: Ignoring error
[2023-03-03 15:20:14,805] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:14,805] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:14,814] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:14,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:14,830] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:14,831] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:14,837] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:14,839] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:14,844] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:14,848] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:14,857] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:14,859] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:14,859] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:14,861] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:14,863] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:14,864] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:14,866] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:14,867] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:14,868] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:14,869] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:14,870] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:14,880] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:14,883] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:14,888] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:14,898] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:14,899] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:14,905] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:14,906] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:14,907] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:14,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:14,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:14,913] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:14,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:14,918] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:14,920] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:14,924] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:14,928] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:14,931] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:14,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:14,938] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:14,942] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:14,949] {spark_submit.py:495} INFO - 23/03/03 15:20:14 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:14,951] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:14,951] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:14,952] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:14,953] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:14,955] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:14,956] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:14,958] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:14,959] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:14,960] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:14,962] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:14,978] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:14,978] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:14,980] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:14,982] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:14,985] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:14,987] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:14,988] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:14,991] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:14,994] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:14,996] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:14,999] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:15,005] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:15,006] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:15,007] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:15,008] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:15,009] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:15,032] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:15,034] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:15,035] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:15,036] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:15,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:15,037] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:15,050] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:15,114] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:15,114] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:15,115] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:15,117] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:15,118] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:15,120] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:15,124] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:15,126] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:15,129] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:15,146] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:15,153] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,154] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,155] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,160] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,160] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,161] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,165] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,172] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:15,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:15,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:15,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,190] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,194] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,197] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,212] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,231] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,232] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:15,234] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:15,243] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:15,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,249] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:15,252] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:15,253] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:15,255] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:15,256] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:15,258] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:15,260] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:15,262] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:15,270] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:15,277] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,280] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,281] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,295] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,301] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:15,303] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:15,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:15,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:15,319] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:15,334] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:15,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,373] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,390] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,401] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,404] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,406] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,415] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,417] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:15,419] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:15,420] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:15,420] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:15,423] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:15,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:15,467] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:15,468] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:15,470] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:15,472] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:15,481] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:15,505] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:15,512] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:15,523] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:15,534] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:15,544] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:15,548] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:15,550] {spark_submit.py:495} INFO - 23/03/03 15:20:14 ERROR Inbox: Ignoring error
[2023-03-03 15:20:15,555] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:15,563] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:15,571] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:15,579] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:15,590] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:15,606] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:15,626] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:15,627] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:15,642] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:15,644] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:15,646] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:15,650] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:15,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:15,666] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:15,667] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:15,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:15,669] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:15,682] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:15,690] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:15,697] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:15,699] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:15,722] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:15,732] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:15,732] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:15,733] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:15,734] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:15,734] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:15,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,735] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,754] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,755] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:15,755] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:15,765] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:15,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,773] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,774] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,779] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,781] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,782] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,782] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,784] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:15,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:15,789] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:15,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,791] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:15,792] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:15,792] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:15,793] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:15,794] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:15,795] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:15,798] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:15,803] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:15,805] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:15,806] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,807] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,815] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,816] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,817] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:15,819] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:15,824] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:15,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:15,826] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:15,827] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:15,827] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,828] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,829] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,830] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,833] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,834] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,835] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,836] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,837] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:15,838] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:15,838] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:15,839] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:15,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:15,842] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:15,843] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:15,844] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:15,846] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:15,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:15,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:15,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:15,850] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:15,851] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:15,853] {spark_submit.py:495} INFO - 23/03/03 15:20:14 ERROR Inbox: Ignoring error
[2023-03-03 15:20:15,853] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:15,855] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:15,855] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:15,857] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:15,858] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:15,859] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:15,859] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:15,860] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:15,860] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:15,862] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:15,862] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:15,867] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:15,869] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:15,870] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:15,871] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:15,872] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:15,873] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:15,873] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:15,874] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:15,875] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:15,876] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:15,879] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:15,881] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:15,881] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:15,882] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:15,883] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:15,884] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:15,884] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,885] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,904] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,957] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,961] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,973] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,977] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,979] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:15,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:15,982] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:15,984] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:15,987] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:15,988] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:15,988] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:15,990] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:15,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:15,992] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:15,993] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:15,995] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,003] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,006] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,006] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,007] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:16,010] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:16,013] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,018] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:16,018] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:16,019] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:16,020] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:16,023] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:16,024] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:16,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,026] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,027] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:16,028] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:16,028] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:16,030] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:16,030] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:16,031] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:16,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,033] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,035] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,036] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,037] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,037] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,042] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:16,044] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:16,044] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:16,045] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:16,046] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:16,046] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:16,047] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,047] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,048] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,053] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,055] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,055] {spark_submit.py:495} INFO - 23/03/03 15:20:14 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:16,056] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,057] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,058] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,059] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:16,059] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:16,060] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:16,061] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:16,061] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:16,062] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:16,063] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,064] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:16,065] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:16,065] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,066] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:16,067] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:16,068] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,069] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,070] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,070] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,071] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,071] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,073] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,078] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,080] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,085] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,086] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,087] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,087] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,088] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,089] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,089] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,090] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,091] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,092] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,093] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,094] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,095] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,095] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,096] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,096] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,097] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,098] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,098] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,099] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,100] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,100] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,108] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,110] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,110] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,113] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,116] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,119] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,120] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,129] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:16,130] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:16,131] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,131] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:16,132] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:16,133] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:16,133] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:16,134] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:16,135] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:16,135] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,136] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,136] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,137] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,138] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:16,138] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:16,139] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:16,140] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:16,140] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:16,141] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:16,142] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,143] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,146] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,149] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,152] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,153] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,161] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,162] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:16,164] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:16,165] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:16,166] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:16,170] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:16,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:16,172] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,173] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,173] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,174] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,174] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,175] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,175] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:16,176] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:16,176] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:16,177] {spark_submit.py:495} INFO - 23/03/03 15:20:14 ERROR Inbox: Ignoring error
[2023-03-03 15:20:16,177] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,178] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,178] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,179] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,179] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,180] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,180] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,181] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,182] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,184] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,186] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,189] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,190] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,190] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,191] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,191] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,192] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,193] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,193] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,194] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,194] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,195] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,196] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,196] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,196] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,197] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,198] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,199] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,199] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,200] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,200] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:16,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:16,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:16,203] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:16,204] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:16,204] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:16,205] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:16,205] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:16,206] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:16,207] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:16,208] {spark_submit.py:495} INFO - 23/03/03 15:20:14 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:16,209] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,210] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,211] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,212] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:16,212] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:16,213] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:16,214] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:16,215] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:16,215] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:16,216] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,217] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:16,217] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:16,218] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,219] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:16,219] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:16,220] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,221] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,221] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,224] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,225] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,225] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,227] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,228] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,229] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,230] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,230] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,231] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,232] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,235] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,236] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,236] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,237] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,238] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,238] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,239] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,240] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,241] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,242] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,243] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,245] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:16,246] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:16,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:16,248] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:16,249] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:16,250] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:16,251] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:16,251] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:16,252] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:16,253] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:16,253] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:16,254] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:16,255] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:16,255] {spark_submit.py:495} INFO - 23/03/03 15:20:14 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:16,256] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,256] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,257] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,258] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:16,259] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:16,260] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:16,260] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:16,261] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:16,262] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:16,263] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,263] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:16,264] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:16,265] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,265] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:16,267] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:16,268] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,269] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,270] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,270] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,271] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,273] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,277] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,278] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,283] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,283] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,284] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,285] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,285] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,288] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,289] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,290] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,290] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,291] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,292] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,293] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,294] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,296] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,299] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,302] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,304] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,306] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,308] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,313] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,314] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,314] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,316] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,317] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,318] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,319] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,320] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,321] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,322] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,323] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:16,323] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:16,324] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,325] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:16,325] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:16,326] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:16,326] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:16,327] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:16,327] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:16,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,329] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,330] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,330] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,331] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:16,331] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:16,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:16,332] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:16,333] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:16,334] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:16,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,335] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,339] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,341] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,344] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,347] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:16,348] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:16,349] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:16,350] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:16,351] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:16,351] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:16,352] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,353] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,354] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,355] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,356] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,356] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,357] {spark_submit.py:495} INFO - 23/03/03 15:20:14 ERROR Inbox: Ignoring error
[2023-03-03 15:20:16,357] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,358] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,360] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,360] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,361] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,362] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,365] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,368] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,369] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,369] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,370] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,370] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,371] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,372] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,373] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,374] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,375] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,376] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,377] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,378] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,378] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,381] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,382] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,383] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,384] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,385] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,386] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,387] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,396] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,398] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,404] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,405] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,407] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,408] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,409] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,411] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,416] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,418] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,418] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,419] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,420] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,421] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,422] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:16,422] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:16,423] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,424] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:16,425] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:16,427] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:16,428] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:16,430] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:16,437] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:16,442] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,455] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,471] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,533] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:16,575] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:16,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:16,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:16,700] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:16,701] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:16,701] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,702] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,704] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,705] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,705] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,707] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,707] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,708] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:16,709] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:16,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:16,710] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:16,710] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:16,711] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:16,711] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,712] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,713] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,713] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,714] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,714] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,715] {spark_submit.py:495} INFO - 23/03/03 15:20:14 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:16,716] {spark_submit.py:495} INFO - 23/03/03 15:20:15 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:16,717] {spark_submit.py:495} INFO - 23/03/03 15:20:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:16,718] {spark_submit.py:495} INFO - 23/03/03 15:20:15 ERROR Inbox: Ignoring error
[2023-03-03 15:20:16,718] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,719] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,719] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,720] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,720] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,721] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,721] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,722] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,722] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,723] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,724] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,724] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,725] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,728] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,728] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,729] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,729] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,730] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,731] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,731] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,732] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,732] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,734] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:16,737] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:16,737] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:16,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:16,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:16,739] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:16,739] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:16,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:16,740] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:16,741] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:16,741] {spark_submit.py:495} INFO - 23/03/03 15:20:15 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:16,742] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,742] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:16,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:16,744] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:16,744] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:16,745] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:16,746] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:16,746] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,747] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:16,747] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:16,748] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,748] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:16,749] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:16,750] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,750] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,751] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,752] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,752] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,753] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,753] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,754] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,754] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,754] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,755] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,755] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,756] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,756] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,757] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,757] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,759] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,760] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,760] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,760] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,761] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,761] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,763] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,764] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,765] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,765] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:16,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:16,767] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:16,767] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:16,768] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:16,768] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:16,769] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:16,769] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:16,770] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:16,770] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:16,771] {spark_submit.py:495} INFO - 23/03/03 15:20:15 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:16,771] {spark_submit.py:495} INFO - 23/03/03 15:20:15 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:16,771] {spark_submit.py:495} INFO - 23/03/03 15:20:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:16,772] {spark_submit.py:495} INFO - 23/03/03 15:20:15 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:16,772] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,773] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,773] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,774] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:16,774] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:16,775] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:16,775] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:16,776] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:16,776] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:16,777] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,777] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:16,778] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:16,779] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,779] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:16,779] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:16,780] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:16,780] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:16,781] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:16,781] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,782] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,782] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,783] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:16,783] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:16,783] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:16,784] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:16,785] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:16,785] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:16,785] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:16,786] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:16,786] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:16,787] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,789] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,798] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,799] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,801] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,802] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:16,802] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:16,805] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,806] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:16,807] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:16,809] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:16,813] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:16,826] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:16,827] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,829] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,844] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,847] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,849] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,850] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,854] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,854] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,861] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,862] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,863] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,864] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,866] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,867] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,867] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,870] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,879] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,887] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,889] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:16,890] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,894] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:16,895] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:16,896] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:16,897] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:16,898] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:16,899] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:16,900] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:16,901] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:16,902] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:16,905] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,906] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,911] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,917] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:16,918] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:16,920] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:16,921] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:16,921] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:16,922] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:16,923] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:16,925] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:16,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:16,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:16,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:16,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:16,945] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:16,953] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:16,954] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:16,955] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:16,956] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:16,958] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:16,960] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:16,962] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:16,963] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:16,976] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:16,977] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:16,979] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:16,980] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:16,981] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:16,982] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:16,984] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:16,986] {spark_submit.py:495} INFO - 23/03/03 15:20:15 ERROR Inbox: Ignoring error
[2023-03-03 15:20:16,987] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:16,988] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:16,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:16,991] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:17,004] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:17,018] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:17,018] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:17,019] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:17,020] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:17,020] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:17,021] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:17,022] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:17,022] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:17,025] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:17,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:17,029] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:17,033] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:17,035] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:17,035] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:17,043] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:17,044] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:17,052] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:17,053] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:17,053] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:17,055] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:17,056] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:17,056] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:17,057] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:17,058] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:17,058] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:17,059] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:17,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:17,061] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:17,061] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:17,062] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:17,066] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:17,068] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:17,069] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:17,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:17,072] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:17,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:17,080] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:17,083] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:17,084] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:17,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:17,087] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:17,089] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:17,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:17,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:17,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:17,098] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:17,099] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:17,099] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:17,101] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:17,103] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:17,107] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:17,110] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:17,110] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:17,111] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:17,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:17,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:17,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:17,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:17,116] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:17,120] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:17,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:17,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:17,131] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:17,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:17,136] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:17,140] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:17,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:17,147] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:17,149] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:17,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:17,153] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:17,154] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:17,156] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:17,158] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:17,159] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:17,161] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:17,164] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:17,164] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:17,165] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:17,167] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:17,168] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:17,169] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:17,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:17,172] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:17,173] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:17,175] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:17,176] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:17,178] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:17,179] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:17,180] {spark_submit.py:495} INFO - 23/03/03 15:20:16 ERROR Inbox: Ignoring error
[2023-03-03 15:20:17,181] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:17,182] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:17,183] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:17,184] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:17,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:17,186] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:17,187] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:17,188] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:17,189] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:17,194] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:17,197] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:17,202] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:17,203] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:17,205] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:17,207] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:17,208] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:17,209] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:17,213] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:17,215] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:17,218] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:17,223] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:17,226] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:17,227] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:17,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:17,229] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:17,230] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:17,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:17,232] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:17,234] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:17,260] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:17,267] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:17,268] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:17,270] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:17,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:17,272] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:17,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:17,275] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:17,282] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:17,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:17,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:17,289] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:17,292] {spark_submit.py:495} INFO - 23/03/03 15:20:16 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:17,308] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:17,308] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:17,309] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:17,312] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:17,314] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:17,319] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:17,321] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:17,333] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:17,334] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:17,336] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:17,337] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:17,337] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:17,338] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:17,339] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:17,340] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:17,341] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:17,342] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:17,345] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:17,350] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:17,351] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:17,352] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:17,353] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:17,353] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:17,354] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:17,355] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:17,356] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:17,357] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:17,358] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:17,358] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:17,359] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:17,360] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:17,374] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:17,376] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:17,377] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:17,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:17,387] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:17,389] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:17,390] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:17,391] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:17,392] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:17,394] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:17,395] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:17,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:17,403] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:17,413] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:17,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:17,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:17,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:18,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:18,287] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:18,287] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:18,288] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:18,289] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:18,289] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:18,290] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:18,291] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:18,291] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:18,292] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:18,293] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:18,308] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:18,310] {spark_submit.py:495} INFO - 23/03/03 15:20:16 ERROR Inbox: Ignoring error
[2023-03-03 15:20:18,311] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,311] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,312] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,312] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:18,313] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:18,314] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:18,314] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:18,315] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:18,319] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:18,321] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:18,331] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:18,340] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:18,341] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:18,343] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:18,344] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:18,345] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:18,348] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:18,349] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,350] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:18,351] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:18,351] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:18,352] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:18,353] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:18,356] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:18,357] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:18,361] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:18,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:18,363] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,363] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,364] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,365] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,366] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:18,366] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:18,367] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:18,367] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:18,368] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:18,368] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:18,369] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:18,369] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:18,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:18,383] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:18,383] {spark_submit.py:495} INFO - 23/03/03 15:20:16 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:18,384] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,385] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,385] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:18,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:18,388] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:18,388] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:18,389] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:18,389] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:18,390] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:18,391] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:18,391] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:18,392] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,392] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:18,393] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:18,394] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:18,394] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:18,395] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:18,396] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,396] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,397] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,397] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:18,398] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:18,399] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:18,400] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:18,401] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:18,402] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:18,403] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:18,403] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:18,404] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:18,404] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:18,405] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:18,405] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:18,406] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:18,407] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:18,407] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,408] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:18,408] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:18,409] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:18,410] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:18,410] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:18,411] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:18,411] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:18,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,413] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:18,419] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:18,420] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:18,421] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:18,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:18,423] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:18,423] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:18,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:18,425] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:18,426] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:18,427] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:18,428] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:18,429] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:18,429] {spark_submit.py:495} INFO - 23/03/03 15:20:16 ERROR Inbox: Ignoring error
[2023-03-03 15:20:18,431] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,432] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:18,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:18,438] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:18,439] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:18,440] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:18,440] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:18,441] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:18,441] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:18,442] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:18,443] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:18,445] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:18,446] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:18,446] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:18,453] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:18,454] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,455] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:18,456] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:18,461] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:18,461] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:18,463] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:18,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:18,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:18,465] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:18,466] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:18,467] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,468] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,481] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,482] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,484] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:18,485] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:18,487] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:18,487] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:18,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:18,489] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:18,490] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:18,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:18,491] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:18,491] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:18,495] {spark_submit.py:495} INFO - 23/03/03 15:20:16 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:18,499] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,500] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,502] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:18,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:18,504] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:18,504] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:18,505] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:18,506] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:18,506] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:18,507] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:18,507] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:18,508] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,509] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:18,510] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:18,510] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:18,511] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:18,511] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:18,512] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,523] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,540] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,542] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:18,546] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:18,557] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:18,560] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:18,566] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:18,588] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:18,591] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:18,595] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:18,599] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:18,603] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:18,605] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:18,606] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:18,607] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:18,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:18,614] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,619] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:18,628] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:18,629] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:18,629] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:18,630] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:18,630] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:18,631] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:18,632] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,633] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,633] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,634] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,635] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:18,636] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:18,637] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:18,638] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:18,639] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:18,639] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:18,640] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:18,641] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:18,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:18,651] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:18,653] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:18,654] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:18,655] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:18,657] {spark_submit.py:495} INFO - 23/03/03 15:20:16 ERROR Inbox: Ignoring error
[2023-03-03 15:20:18,658] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,672] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,674] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,677] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:18,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:18,684] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:18,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:18,687] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:18,688] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:18,689] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:18,691] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:18,691] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:18,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:18,693] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:18,694] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:18,696] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:18,697] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:18,699] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,700] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:18,703] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:18,714] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:18,717] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:18,719] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:18,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:18,725] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:18,725] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:18,726] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:18,730] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,731] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,742] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:18,756] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:18,767] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:18,771] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:18,773] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:18,774] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:18,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:18,776] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,787] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,797] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,799] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:18,805] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:18,806] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:18,826] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:18,826] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:18,827] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:18,828] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:18,829] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,830] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:18,832] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:18,833] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:18,834] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:18,835] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:18,836] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:18,836] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:18,837] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:18,838] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:18,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:18,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:18,842] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:18,845] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:18,846] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:18,848] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:18,850] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:18,850] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:18,854] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:18,856] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,857] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,858] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,859] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,862] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:18,862] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:18,866] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:18,868] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:18,870] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:18,874] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:18,876] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:18,878] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:18,879] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:18,880] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:18,881] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:18,882] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:18,884] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:18,887] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:18,888] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:18,889] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:18,890] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:18,890] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:18,891] {spark_submit.py:495} INFO - 23/03/03 15:20:16 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:18,892] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,899] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,901] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,902] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:18,903] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:18,904] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:18,906] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:18,907] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:18,908] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:18,909] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:18,910] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:18,911] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:18,913] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,914] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:18,915] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:18,917] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:18,920] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:18,921] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:18,924] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:18,926] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:18,927] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:18,928] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:18,929] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:18,929] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:18,930] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:18,931] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:18,931] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:18,933] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:18,946] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:18,947] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:18,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:18,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:18,951] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:18,953] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:18,954] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:18,955] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:18,956] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:18,957] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:18,958] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:18,958] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:18,959] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:18,960] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:18,962] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:18,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,965] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,968] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,969] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:18,969] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:18,970] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:18,971] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:18,972] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:18,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:18,973] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:18,973] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,974] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:18,975] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:18,977] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:18,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:18,982] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:18,983] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:18,983] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:18,984] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:18,985] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:18,986] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:18,987] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:18,988] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:18,988] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:18,989] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:18,989] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:18,990] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:18,991] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:18,993] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:18,998] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:19,000] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:19,001] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,002] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,002] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,003] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,004] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:19,005] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:19,005] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:19,006] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:19,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:19,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:19,008] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,011] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,012] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,020] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,021] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,021] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,022] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,023] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:19,024] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:19,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:19,025] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:19,026] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:19,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:19,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,028] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,029] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,030] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,031] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,032] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,035] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:19,038] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:19,038] {spark_submit.py:495} INFO - 23/03/03 15:20:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:19,039] {spark_submit.py:495} INFO - 23/03/03 15:20:16 ERROR Inbox: Ignoring error
[2023-03-03 15:20:19,040] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,040] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,041] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,043] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,044] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,044] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,045] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,046] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,047] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,047] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,048] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,050] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,051] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,056] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,057] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,058] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,059] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,060] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,061] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,061] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,062] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,063] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,063] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,064] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,065] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,066] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,067] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,068] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,071] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:19,074] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:19,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:19,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:19,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:19,077] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:19,079] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:19,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:19,080] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:19,081] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:19,081] {spark_submit.py:495} INFO - 23/03/03 15:20:16 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:19,082] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,084] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,084] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,085] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:19,086] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:19,095] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:19,096] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:19,097] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:19,097] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:19,098] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,099] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:19,099] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:19,101] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,101] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:19,102] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:19,103] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,104] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,104] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,105] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,106] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,107] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,108] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,109] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,112] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,118] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,118] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,119] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,120] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,120] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,121] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,122] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,122] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,123] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,123] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,124] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,125] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,125] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,126] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,128] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,129] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,129] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,131] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,134] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,135] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:19,136] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:19,137] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:19,138] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:19,139] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:19,139] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:19,140] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:19,141] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:19,142] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:19,143] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:19,144] {spark_submit.py:495} INFO - 23/03/03 15:20:17 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:19,145] {spark_submit.py:495} INFO - 23/03/03 15:20:17 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:19,145] {spark_submit.py:495} INFO - 23/03/03 15:20:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:19,146] {spark_submit.py:495} INFO - 23/03/03 15:20:17 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:19,147] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,148] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,148] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:19,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:19,150] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:19,152] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:19,153] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:19,154] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:19,154] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,155] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:19,156] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:19,158] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,159] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:19,161] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:19,162] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,164] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,165] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,165] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,166] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,167] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,168] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,169] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,169] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,170] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,171] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,171] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,172] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,173] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,177] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,183] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,184] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,185] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,187] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,188] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,188] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,189] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,189] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,190] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,191] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,192] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,192] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,193] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,194] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,194] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,195] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,197] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:19,200] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:19,205] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:19,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:19,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:19,207] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:19,208] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:19,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:19,209] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:19,210] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:19,210] {spark_submit.py:495} INFO - 23/03/03 15:20:17 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:19,211] {spark_submit.py:495} INFO - 23/03/03 15:20:17 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:19,212] {spark_submit.py:495} INFO - 23/03/03 15:20:17 ERROR Inbox: Ignoring error
[2023-03-03 15:20:19,213] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,213] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,214] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,215] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,216] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,216] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,217] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,218] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,218] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,221] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,222] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,223] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,224] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,224] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,225] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,229] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,229] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,230] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,231] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,232] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,232] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,235] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,236] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,236] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,237] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,238] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,242] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:19,245] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:19,245] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:19,246] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:19,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:19,248] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:19,249] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:19,249] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:19,250] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:19,251] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:19,251] {spark_submit.py:495} INFO - 23/03/03 15:20:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:19,252] {spark_submit.py:495} INFO - 23/03/03 15:20:17 ERROR Inbox: Ignoring error
[2023-03-03 15:20:19,253] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,254] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,254] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,256] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,257] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,257] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,258] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,260] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,261] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,262] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,263] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,265] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,266] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,267] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,267] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,268] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,269] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,269] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,270] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,271] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,279] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,280] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,282] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,283] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,284] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,285] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,287] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,288] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,289] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,289] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,290] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,291] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,292] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,293] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,295] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,297] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,299] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,302] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,306] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,308] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:19,309] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:19,309] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,310] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:19,311] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:19,311] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:19,312] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:19,313] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:19,313] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:19,314] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,316] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,317] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,320] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:19,325] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:19,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:19,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:19,327] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:19,328] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:19,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,329] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,330] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,330] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,333] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,334] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,334] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,335] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:19,336] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:19,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:19,337] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:19,338] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:19,339] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:19,339] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,340] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,342] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,342] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,344] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,345] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,345] {spark_submit.py:495} INFO - 23/03/03 15:20:17 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:19,346] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,347] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,348] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,349] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:19,349] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:19,350] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:19,352] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:19,355] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:19,355] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:19,356] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,357] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:19,358] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:19,358] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,359] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:19,360] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:19,361] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,361] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,362] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,363] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,363] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,364] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,367] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,368] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,370] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,371] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,372] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,375] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,376] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,377] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,378] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,378] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,381] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,382] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,383] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,384] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,385] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,385] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,386] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,387] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,387] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,388] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,388] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,390] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,390] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,391] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,391] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,392] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,394] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,396] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,398] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,400] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,401] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,402] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,403] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,404] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,405] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,406] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,408] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,411] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:19,412] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:19,412] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,413] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:19,414] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:19,415] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:19,419] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:19,420] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:19,421] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:19,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,423] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,425] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,426] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,428] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:19,429] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:19,431] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:19,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:19,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:19,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:19,435] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,437] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,437] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,438] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,440] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,441] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,441] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,442] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,445] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,447] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:19,447] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:19,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:19,449] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:19,450] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:19,451] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:19,453] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,454] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,454] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,458] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,459] {spark_submit.py:495} INFO - 23/03/03 15:20:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:19,459] {spark_submit.py:495} INFO - 23/03/03 15:20:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:19,460] {spark_submit.py:495} INFO - 23/03/03 15:20:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:19,461] {spark_submit.py:495} INFO - 23/03/03 15:20:18 ERROR Inbox: Ignoring error
[2023-03-03 15:20:19,462] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,463] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,472] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,473] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,477] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,479] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,481] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,483] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,484] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,486] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,487] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,487] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,488] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,489] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,490] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,490] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,491] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,492] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,492] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,493] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,494] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,495] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,497] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,500] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,503] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,505] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,506] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,507] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,507] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,508] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,512] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,513] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,515] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,517] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,518] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,519] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,520] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,524] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,525] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,527] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,529] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,530] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,530] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,531] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:19,533] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:19,534] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,536] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:19,537] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:19,538] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:19,541] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:19,542] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:19,543] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:19,543] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,544] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,545] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,545] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,546] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:19,547] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:19,548] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:19,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:19,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:19,557] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:19,559] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,560] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,563] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,563] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,564] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,565] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,566] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,566] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,568] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,568] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,569] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:19,570] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:19,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:19,572] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:19,573] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:19,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:19,576] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,577] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,578] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,584] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,586] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,588] {spark_submit.py:495} INFO - 23/03/03 15:20:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:19,595] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,606] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,607] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,608] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:19,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:19,612] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:19,614] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:19,616] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:19,639] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:19,641] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,643] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:19,644] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:19,649] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,650] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:19,656] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:19,657] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,659] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,661] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,662] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,664] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,665] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,666] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,669] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,673] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,674] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,674] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,675] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,677] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,678] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,679] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,680] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,680] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,682] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,683] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,685] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,686] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,687] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,692] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,692] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,696] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,698] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,699] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,702] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,704] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,704] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,705] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,710] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,711] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,716] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,717] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,721] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:19,722] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:19,723] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,725] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:19,726] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:19,727] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:19,727] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:19,730] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:19,730] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:19,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,732] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,737] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:19,737] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:19,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:19,739] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:19,740] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:19,742] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:19,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,744] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,747] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,748] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,751] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,753] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,755] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,756] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:19,757] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:19,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:19,759] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:19,761] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:19,763] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:19,763] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,764] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,765] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,766] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,767] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,768] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,769] {spark_submit.py:495} INFO - 23/03/03 15:20:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:19,769] {spark_submit.py:495} INFO - 23/03/03 15:20:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:19,770] {spark_submit.py:495} INFO - 23/03/03 15:20:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:19,772] {spark_submit.py:495} INFO - 23/03/03 15:20:18 ERROR Inbox: Ignoring error
[2023-03-03 15:20:19,773] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,773] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,774] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,774] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,775] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:19,776] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:19,776] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:19,777] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:19,778] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:19,778] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:19,783] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:19,785] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:19,786] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,786] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,787] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,788] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,790] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,791] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,791] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:19,792] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,793] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,795] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,797] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:19,798] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:19,798] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:19,800] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:19,801] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:19,802] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,837] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,839] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,844] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,845] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,847] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,847] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,849] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,850] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,853] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,863] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,865] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,868] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,869] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,871] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,872] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,874] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,875] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,876] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,878] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,879] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,880] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:19,881] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,882] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:19,884] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:19,885] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,886] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:19,887] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:19,891] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:19,895] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:19,901] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:19,902] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:19,906] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,910] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,911] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:19,911] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:19,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:19,913] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:19,915] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:19,917] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:19,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:19,922] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:19,924] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:19,925] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:19,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:19,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:19,927] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:19,928] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:19,928] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:19,929] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:19,933] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:19,935] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:19,936] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:19,937] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:19,938] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:19,938] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:19,939] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:19,941] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:19,944] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:19,946] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:19,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:19,948] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:19,949] {spark_submit.py:495} INFO - 23/03/03 15:20:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:19,950] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,951] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,952] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,953] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:19,954] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:19,955] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:19,956] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:19,956] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:19,959] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:19,973] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:19,973] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:19,975] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:19,976] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:19,977] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:19,978] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:19,980] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:19,981] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:19,982] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:19,990] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:19,991] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:19,992] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:19,995] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:19,999] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:20,001] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:20,013] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:20,021] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:20,023] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:20,024] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:20,031] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:20,032] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:20,032] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,033] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,034] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,039] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:20,041] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:20,042] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:20,045] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:20,047] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:20,050] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:20,050] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:20,051] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:20,052] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,053] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,054] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,057] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,061] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,062] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,064] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,064] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,065] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,066] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,068] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,071] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,078] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,080] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,081] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,082] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,084] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,086] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:20,087] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:20,089] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:20,090] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:20,090] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:20,091] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:20,093] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:20,094] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:20,095] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:20,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,097] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,100] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,103] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:20,103] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:20,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:20,108] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:20,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:20,110] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:20,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,112] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,116] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,119] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,120] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,120] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,121] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:20,122] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:20,123] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:20,124] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:20,125] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:20,125] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:20,126] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,132] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,136] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:20,142] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:20,142] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:20,143] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:20,144] {spark_submit.py:495} INFO - 23/03/03 15:20:19 ERROR Inbox: Ignoring error
[2023-03-03 15:20:20,145] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:20,146] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:20,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:20,148] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:20,151] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:20,154] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:20,155] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:20,159] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:20,160] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:20,162] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:20,163] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:20,163] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:20,165] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,166] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,168] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,170] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,173] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:20,173] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:20,176] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:20,177] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:20,178] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:20,179] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:20,180] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:20,180] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:20,181] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:20,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:20,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,183] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,189] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,190] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,193] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,194] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,196] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,197] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,198] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,200] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,204] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,204] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,207] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,208] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,210] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,212] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:20,213] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:20,214] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:20,215] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:20,216] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:20,218] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:20,219] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:20,221] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:20,222] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:20,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,229] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:20,230] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:20,231] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:20,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:20,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:20,235] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:20,236] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,238] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,240] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,240] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,242] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,242] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,243] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,244] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:20,244] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:20,245] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:20,246] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:20,247] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:20,249] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:20,252] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,254] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,254] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,256] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:20,256] {spark_submit.py:495} INFO - 23/03/03 15:20:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:20,258] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:20,259] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:20,260] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:20,263] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:20,277] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:20,279] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:20,279] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:20,280] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:20,283] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:20,284] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:20,286] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:20,287] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:20,288] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:20,289] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:20,289] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:20,292] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:20,293] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:20,293] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:20,295] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:20,296] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:20,298] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:20,299] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:20,300] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:20,301] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:20,303] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:20,305] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:20,306] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:20,308] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:20,310] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:20,312] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:20,312] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,313] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,314] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,315] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,321] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:20,333] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:20,334] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:20,335] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:20,336] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:20,337] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:20,338] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:20,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:20,340] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,341] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,342] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,343] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,344] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,346] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,347] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,347] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,349] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,351] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,352] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,353] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,355] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,355] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,356] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,358] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,358] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,360] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,361] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,362] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:20,363] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:20,365] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:20,365] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:20,367] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:20,369] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:20,372] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:20,374] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:20,377] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:20,380] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,381] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,382] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,383] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,383] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:20,385] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:20,386] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:20,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:20,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:20,388] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:20,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,390] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,391] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,400] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,401] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,402] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,402] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:20,404] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:20,405] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:20,405] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:20,407] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:20,408] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:20,409] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,410] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,410] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,411] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,413] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,415] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:20,421] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:20,423] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:20,423] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:20,424] {spark_submit.py:495} INFO - 23/03/03 15:20:19 ERROR Inbox: Ignoring error
[2023-03-03 15:20:20,425] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:20,425] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:20,426] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:20,427] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:20,428] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:20,434] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:20,440] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:20,451] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:20,454] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:20,457] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:20,459] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:20,460] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:20,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,463] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,465] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,466] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:20,467] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:20,468] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:20,469] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:20,470] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:20,471] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:20,472] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:20,472] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:20,473] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:20,475] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:20,475] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,476] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,477] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,478] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,478] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,479] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,479] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,480] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,480] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,481] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,481] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,484] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,485] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,563] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,649] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:20,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,655] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:20,656] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:20,657] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:20,658] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:20,659] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:20,660] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:20,664] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:20,667] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:20,678] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:20,680] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,680] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,681] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,682] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,686] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:20,689] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:20,689] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:20,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:20,691] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:20,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:20,692] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:20,693] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:20,693] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:20,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:20,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:20,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:20,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:20,696] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:20,696] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:20,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:20,698] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:20,698] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:20,699] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:20,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:20,700] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:20,700] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:20,705] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:20,706] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:20,708] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:20,721] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:20,722] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:20,723] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:20,724] {spark_submit.py:495} INFO - 23/03/03 15:20:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:20,725] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:20,741] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:20,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:20,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:20,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:20,746] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:20,747] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:20,748] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:20,750] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:20,751] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:20,752] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:20,753] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:20,754] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:20,755] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:20,758] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:20,759] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:20,761] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:20,764] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:20,765] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:20,975] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:21,002] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:21,003] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:21,004] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:21,005] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:21,006] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:21,007] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:21,008] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:21,009] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:21,009] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:21,010] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:21,011] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:21,012] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:21,013] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:21,014] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:21,015] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:21,016] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:21,018] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:21,019] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:21,019] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:21,020] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:21,021] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:21,021] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:21,023] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:21,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,029] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:21,031] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:21,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,035] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,036] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:21,037] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:21,039] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:21,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:21,041] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,043] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:21,044] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:21,044] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,048] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,051] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,063] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,071] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:21,088] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:21,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:21,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:21,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,114] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:21,114] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:21,119] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:21,120] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:21,122] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:21,123] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:21,124] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:21,125] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:21,125] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:21,131] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,134] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,134] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,135] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:21,138] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:21,141] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:21,143] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:21,145] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:21,146] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:21,146] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,153] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:21,154] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:21,156] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,157] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,158] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,160] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,161] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:21,161] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:21,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:21,168] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:21,172] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:21,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:21,185] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:21,191] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:21,195] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:21,200] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:21,206] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:21,213] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:21,218] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:21,223] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:21,229] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:21,234] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:21,241] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:21,246] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:21,258] {spark_submit.py:495} INFO - 23/03/03 15:20:19 ERROR Inbox: Ignoring error
[2023-03-03 15:20:21,279] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:21,293] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:21,301] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:21,307] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:21,314] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:21,326] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:21,337] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:21,374] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:21,391] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:21,396] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:21,409] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:21,413] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:21,420] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:21,424] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:21,429] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:21,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:21,443] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:21,451] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:21,456] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:21,463] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:21,468] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:21,476] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:21,479] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:21,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:21,486] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:21,490] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:21,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:21,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,511] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:21,517] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:21,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,529] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,536] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,539] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:21,542] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:21,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:21,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:21,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,557] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:21,563] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:21,567] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,573] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,576] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,579] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:21,581] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:21,586] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:21,591] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:21,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,597] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:21,600] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:21,606] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:21,609] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:21,612] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:21,616] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:21,621] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:21,624] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:21,628] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:21,631] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,634] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,637] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,644] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:21,647] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:21,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:21,654] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:21,657] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:21,660] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:21,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,669] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:21,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:21,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,682] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,688] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:21,691] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:21,694] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:21,697] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:21,701] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:21,712] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:21,715] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:21,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:21,721] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:21,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:21,735] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:21,739] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:21,742] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:21,751] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:21,755] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:21,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:21,762] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:21,767] {spark_submit.py:495} INFO - 23/03/03 15:20:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:21,777] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:21,780] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:21,784] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:21,787] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:21,791] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:21,799] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:21,803] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:21,808] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:21,811] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:21,814] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:21,818] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:21,825] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:21,838] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:21,841] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:21,850] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:21,853] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:21,857] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:21,860] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:21,863] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:21,872] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:21,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:21,879] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:21,883] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:21,887] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:21,894] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:21,898] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:21,902] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:21,906] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:21,910] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:21,920] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:21,923] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:21,926] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:21,931] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:21,934] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:21,943] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:21,946] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:21,950] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:21,953] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:21,956] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:21,960] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:21,966] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:21,969] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:21,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:21,975] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:21,978] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:21,989] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:21,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:21,995] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:21,999] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,002] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,011] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,017] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,020] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,026] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,028] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,032] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,033] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,037] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,037] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,038] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:22,039] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:22,041] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,043] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:22,048] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:22,050] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:22,051] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:22,052] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:22,053] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:22,054] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,059] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,061] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:22,062] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:22,063] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:22,063] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:22,065] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:22,070] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:22,071] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,073] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,082] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,082] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,084] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,086] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,092] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,094] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,095] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,096] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:22,097] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:22,098] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:22,099] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:22,106] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:22,107] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:22,108] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,110] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,113] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,114] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,115] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,121] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,122] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:22,123] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:22,124] {spark_submit.py:495} INFO - 23/03/03 15:20:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:22,124] {spark_submit.py:495} INFO - 23/03/03 15:20:19 ERROR Inbox: Ignoring error
[2023-03-03 15:20:22,125] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,126] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:22,134] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:22,136] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:22,141] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:22,143] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:22,144] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:22,145] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:22,147] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:22,148] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:22,150] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,151] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,152] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,153] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,156] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,160] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,161] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:22,162] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:22,163] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:22,165] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:22,166] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:22,169] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:22,170] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:22,174] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:22,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:22,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,197] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,210] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,214] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,217] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,220] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,221] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,222] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,224] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,226] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,228] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,228] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,231] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,232] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,235] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,237] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,242] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,245] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:22,246] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:22,247] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,247] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:22,248] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:22,250] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:22,251] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:22,252] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:22,253] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:22,254] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,255] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,263] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,267] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:22,269] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:22,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:22,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:22,274] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:22,280] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:22,282] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,286] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,288] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,290] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,291] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,293] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,295] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,296] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,297] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:22,298] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:22,299] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:22,300] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:22,301] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:22,305] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:22,307] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,308] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,309] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,310] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,311] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,312] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,317] {spark_submit.py:495} INFO - 23/03/03 15:20:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:22,320] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,324] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:22,329] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:22,331] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:22,333] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:22,334] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:22,335] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:22,336] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,336] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:22,337] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:22,338] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,339] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:22,340] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:22,341] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:22,342] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:22,343] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:22,344] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,345] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,346] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,347] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:22,352] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:22,353] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:22,354] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:22,355] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:22,356] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:22,357] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:22,358] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:22,359] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:22,360] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,361] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,362] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,363] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,366] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,367] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:22,368] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,369] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:22,370] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:22,371] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:22,372] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:22,372] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:22,375] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,378] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,380] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,381] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,382] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,383] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,385] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,386] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,388] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,391] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,392] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,394] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,394] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,395] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,396] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,397] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,401] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,402] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,403] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,404] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,406] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,407] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:22,409] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:22,410] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,411] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:22,412] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:22,414] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:22,416] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:22,419] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:22,421] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:22,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,423] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,426] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,427] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:22,427] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:22,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:22,429] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:22,430] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:22,431] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:22,433] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,436] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,438] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,439] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,440] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,440] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,442] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,443] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,445] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,447] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,449] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:22,450] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:22,452] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:22,454] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:22,456] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:22,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:22,459] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,461] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,465] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,470] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,472] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,473] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,474] {spark_submit.py:495} INFO - 23/03/03 15:20:20 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:22,475] {spark_submit.py:495} INFO - 23/03/03 15:20:20 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:22,476] {spark_submit.py:495} INFO - 23/03/03 15:20:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:22,478] {spark_submit.py:495} INFO - 23/03/03 15:20:20 ERROR Inbox: Ignoring error
[2023-03-03 15:20:22,479] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,480] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,481] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:22,486] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:22,487] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:22,488] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:22,489] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:22,490] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:22,490] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:22,492] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:22,493] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:22,494] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,495] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,497] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,498] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,502] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,503] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:22,504] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:22,505] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:22,506] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:22,506] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:22,507] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:22,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:22,510] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:22,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:22,513] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,515] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,518] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,520] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:22,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:22,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:22,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:22,523] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:22,524] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:22,525] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:22,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:22,527] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:22,529] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:22,533] {spark_submit.py:495} INFO - 23/03/03 15:20:20 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:22,535] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,538] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,539] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,539] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:22,540] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:22,541] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:22,542] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:22,542] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:22,543] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:22,544] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,545] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:22,546] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:22,547] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,550] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:22,551] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:22,552] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:22,554] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:22,555] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:22,557] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,558] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,559] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,560] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:22,561] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:22,562] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:22,563] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:22,566] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:22,582] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:22,589] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:22,590] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:22,591] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:22,592] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,593] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,593] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,598] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,602] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,604] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,605] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:22,606] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,607] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:22,608] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:22,609] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:22,610] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:22,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:22,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,613] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,614] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,615] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,615] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:22,616] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:22,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:22,618] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:22,619] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:22,626] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:22,630] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:22,632] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:22,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:22,639] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:22,645] {spark_submit.py:495} INFO - 23/03/03 15:20:20 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:22,647] {spark_submit.py:495} INFO - 23/03/03 15:20:20 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:22,651] {spark_submit.py:495} INFO - 23/03/03 15:20:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:22,653] {spark_submit.py:495} INFO - 23/03/03 15:20:20 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:22,654] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,655] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,655] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:22,657] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:22,657] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:22,658] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:22,659] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:22,660] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:22,661] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,661] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:22,663] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:22,664] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,666] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:22,666] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:22,668] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:22,672] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:22,673] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:22,674] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,676] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,677] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,677] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:22,678] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:22,681] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:22,682] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:22,683] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:22,684] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:22,684] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:22,685] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:22,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:22,687] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,691] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,692] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:22,692] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,693] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:22,694] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:22,695] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:22,695] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:22,696] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:22,696] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,700] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,702] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,702] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,728] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,742] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,746] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,757] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,766] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,771] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,772] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,773] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,788] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,793] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,795] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,796] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,798] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,801] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:22,816] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:22,817] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,819] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:22,819] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:22,820] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:22,821] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:22,822] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:22,823] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:22,824] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,825] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,826] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,828] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,829] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:22,832] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:22,834] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:22,835] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:22,835] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:22,836] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:22,837] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,838] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,838] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,844] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,848] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,849] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,851] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,852] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:22,853] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:22,854] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:22,854] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:22,855] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:22,856] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:22,856] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,857] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,858] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,858] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,859] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,860] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,861] {spark_submit.py:495} INFO - 23/03/03 15:20:20 ERROR Inbox: Ignoring error
[2023-03-03 15:20:22,862] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,871] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,872] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,873] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:22,874] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:22,875] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:22,876] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:22,876] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:22,877] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:22,877] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:22,878] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:22,879] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:22,880] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,880] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,881] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,882] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,883] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,884] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:22,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:22,886] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:22,887] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:22,887] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:22,888] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:22,889] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:22,890] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:22,891] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:22,901] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:22,902] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,903] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,904] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,905] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,905] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,906] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,907] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,908] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,909] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,910] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,911] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,911] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,913] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,915] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,916] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,917] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:22,920] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,921] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:22,922] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:22,923] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:22,923] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:22,924] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:22,925] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:22,927] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:22,928] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:22,929] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:22,930] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,931] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,932] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,936] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:22,937] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:22,938] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:22,939] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:22,940] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:22,941] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:22,942] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:22,943] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:22,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:22,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:22,948] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:22,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:22,964] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:22,965] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:22,966] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:22,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:22,968] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:22,969] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:22,970] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:22,971] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:22,972] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:22,973] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:22,974] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,975] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:22,976] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:22,976] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:22,977] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:22,978] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:22,979] {spark_submit.py:495} INFO - 23/03/03 15:20:21 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:22,980] {spark_submit.py:495} INFO - 23/03/03 15:20:21 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:22,981] {spark_submit.py:495} INFO - 23/03/03 15:20:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:22,982] {spark_submit.py:495} INFO - 23/03/03 15:20:21 ERROR Inbox: Ignoring error
[2023-03-03 15:20:22,983] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:22,984] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:22,984] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:22,985] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:22,986] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:22,987] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:22,987] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:22,988] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:22,990] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:22,991] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:22,992] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:22,992] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:22,993] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:22,995] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,000] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,001] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,002] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,002] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,004] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,013] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,014] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,015] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,016] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,018] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,019] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,020] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,022] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,023] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:23,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:23,026] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:23,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:23,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:23,035] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:23,035] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:23,036] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:23,037] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:23,038] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:23,040] {spark_submit.py:495} INFO - 23/03/03 15:20:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:23,040] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,041] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,043] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:23,043] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:23,044] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:23,046] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:23,047] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:23,049] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:23,050] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,051] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:23,052] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:23,053] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,057] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:23,060] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:23,061] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,062] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,063] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,063] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,065] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,068] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,069] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,070] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,071] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,072] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,073] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,073] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,074] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,075] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,078] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,079] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,080] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,081] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,083] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,084] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,085] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,085] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,086] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,088] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,089] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,090] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,091] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:23,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:23,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:23,097] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:23,097] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:23,098] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:23,099] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:23,100] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:23,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:23,102] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:23,103] {spark_submit.py:495} INFO - 23/03/03 15:20:21 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:23,104] {spark_submit.py:495} INFO - 23/03/03 15:20:21 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:23,106] {spark_submit.py:495} INFO - 23/03/03 15:20:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:23,108] {spark_submit.py:495} INFO - 23/03/03 15:20:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:23,109] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,110] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,112] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,114] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:23,115] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:23,119] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:23,122] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:23,123] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:23,124] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:23,125] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,126] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:23,127] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:23,128] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,129] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:23,129] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:23,130] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,134] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,135] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,136] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,137] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,138] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,139] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,140] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,141] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,142] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,143] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,144] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,145] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,146] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,147] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,148] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,150] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,152] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,153] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,154] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,155] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,155] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,157] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,158] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,160] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,161] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,161] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,163] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,164] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,165] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,167] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,169] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,169] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,170] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,171] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,174] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,175] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,177] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,183] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,184] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,185] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,189] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:23,190] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:23,190] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,191] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:23,192] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:23,193] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:23,195] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:23,196] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:23,197] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:23,197] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,199] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,200] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,207] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:23,211] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:23,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:23,212] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:23,213] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:23,214] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:23,214] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,216] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,217] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,219] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,220] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,221] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,221] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,222] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,223] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:23,225] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:23,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:23,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:23,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:23,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:23,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,229] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,230] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,234] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,236] {spark_submit.py:495} INFO - 23/03/03 15:20:21 ERROR Inbox: Ignoring error
[2023-03-03 15:20:23,237] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,237] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,238] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,239] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,239] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,240] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,241] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,241] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,242] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,243] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,244] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,245] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,246] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,246] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,247] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,249] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,250] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,251] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,252] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,255] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,256] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,259] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,260] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,260] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,261] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,262] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,263] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,265] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,267] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,268] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,268] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,269] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,270] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,272] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,273] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,273] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,275] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,275] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,276] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,277] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,278] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,280] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,281] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,283] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,286] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:23,291] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:23,294] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,295] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:23,296] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:23,297] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:23,298] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:23,298] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:23,299] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:23,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,314] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,314] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,315] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:23,316] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:23,317] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:23,318] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:23,319] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:23,320] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:23,320] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,321] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,322] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,325] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,327] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,329] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,330] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,331] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:23,332] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:23,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:23,333] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:23,334] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:23,335] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:23,336] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,336] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,337] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,338] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,338] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,339] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,340] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:23,341] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:23,341] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:23,342] {spark_submit.py:495} INFO - 23/03/03 15:20:22 ERROR Inbox: Ignoring error
[2023-03-03 15:20:23,343] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,347] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,348] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,350] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,352] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,354] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,354] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,355] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,356] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,356] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,357] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,358] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,360] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,361] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,362] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,363] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,363] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,364] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,365] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,366] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,368] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,370] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,371] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,373] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,374] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,379] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,380] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,381] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,382] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,383] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,383] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,384] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,385] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,387] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,390] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,391] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,395] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,397] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,398] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,398] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,400] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,401] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,402] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:23,403] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:23,404] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,405] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:23,406] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:23,406] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:23,407] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:23,410] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:23,417] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:23,421] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,425] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,425] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,426] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:23,427] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:23,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:23,428] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:23,429] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:23,430] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:23,432] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,435] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,438] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,439] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,441] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,441] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,442] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,443] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,444] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,445] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:23,446] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:23,447] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:23,447] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:23,449] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:23,449] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:23,450] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,451] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,452] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,453] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,454] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,455] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,456] {spark_submit.py:495} INFO - 23/03/03 15:20:22 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:23,457] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,462] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:23,465] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:23,466] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:23,467] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:23,468] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:23,469] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:23,469] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,470] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:23,471] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:23,472] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,473] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:23,474] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:23,475] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,476] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,477] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,477] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,478] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,480] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,481] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,485] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,486] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,487] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,488] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,489] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,489] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,490] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,491] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,494] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,495] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,495] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,497] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,499] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,501] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,504] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,506] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,506] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,507] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,508] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,509] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,509] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,512] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,513] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,514] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,514] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,515] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,517] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,517] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,518] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,520] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,522] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,523] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,529] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,535] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,536] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:23,537] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:23,539] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,540] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:23,541] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:23,541] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:23,542] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:23,543] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:23,544] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:23,545] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,552] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,555] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:23,558] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:23,558] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:23,562] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:23,567] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:23,568] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:23,568] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,569] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,572] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,573] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,574] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,574] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,575] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,576] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:23,576] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:23,577] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:23,578] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:23,579] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:23,580] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:23,580] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,582] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,584] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,586] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,588] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,589] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,590] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:23,591] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:23,592] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:23,594] {spark_submit.py:495} INFO - 23/03/03 15:20:22 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:23,595] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,596] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,597] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,598] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:23,598] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:23,599] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:23,600] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:23,601] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:23,602] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:23,602] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,604] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:23,608] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:23,609] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,611] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:23,612] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:23,613] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,613] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,614] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,616] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,616] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,617] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,618] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,620] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,620] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,622] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,623] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,623] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,626] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,631] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,632] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,633] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,636] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,637] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,637] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,638] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,639] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,641] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,642] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,643] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,644] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,645] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,655] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,657] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,658] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,658] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,661] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,661] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,667] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,669] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,673] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,674] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:23,677] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:23,678] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,680] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:23,681] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:23,691] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:23,693] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:23,693] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:23,694] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:23,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,696] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,698] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,699] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:23,699] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:23,700] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:23,701] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:23,702] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:23,704] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:23,705] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,706] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,710] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,713] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,716] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,718] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:23,719] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:23,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:23,720] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:23,721] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:23,722] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:23,723] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,725] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,728] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,729] {spark_submit.py:495} INFO - 23/03/03 15:20:22 ERROR Inbox: Ignoring error
[2023-03-03 15:20:23,731] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,732] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,733] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,734] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,735] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,736] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,738] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,739] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,739] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,740] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,741] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,742] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,746] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,747] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,749] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,750] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,752] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,753] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,753] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,754] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,755] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,755] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,756] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,757] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,758] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,759] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,760] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,761] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,762] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,763] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,764] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,765] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,771] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,772] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,773] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,773] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,774] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,776] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,778] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,779] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,781] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,782] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,783] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:23,785] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:23,786] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,787] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:23,788] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:23,789] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:23,789] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:23,790] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:23,790] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:23,791] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,793] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,793] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,794] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,796] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:23,797] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:23,799] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:23,800] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:23,801] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:23,813] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:23,814] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,815] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,818] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,819] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,820] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,820] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,822] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,822] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,824] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,827] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,833] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:23,834] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:23,835] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:23,837] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:23,837] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:23,838] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:23,839] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,841] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,841] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,842] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,843] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:23,843] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:23,844] {spark_submit.py:495} INFO - 23/03/03 15:20:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:23,844] {spark_submit.py:495} INFO - 23/03/03 15:20:22 ERROR Inbox: Ignoring error
[2023-03-03 15:20:23,845] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,847] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,850] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,851] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,852] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,860] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,861] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,861] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:23,862] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:23,867] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:23,868] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,869] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,871] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,872] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,874] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,883] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,884] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:23,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,887] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,888] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,889] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:23,890] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:23,891] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:23,892] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:23,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:23,894] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,895] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,897] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,898] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,899] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,902] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,903] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,906] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,907] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,913] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,915] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,918] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,919] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,923] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,927] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,928] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:23,929] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,931] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:23,932] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:23,933] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,934] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:23,934] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:23,935] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:23,936] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:23,937] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:23,938] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:23,938] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,939] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,940] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,941] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,942] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:23,943] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:23,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:23,945] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:23,946] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:23,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:23,948] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:23,949] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:23,950] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:23,950] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:23,951] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:23,952] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:23,953] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:23,954] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:23,955] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:23,956] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:23,957] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:23,958] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:23,959] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:23,960] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:23,961] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:23,962] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:23,963] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:23,964] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:23,964] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:23,965] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:23,966] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:23,967] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:23,968] {spark_submit.py:495} INFO - 23/03/03 15:20:22 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:23,969] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,970] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,971] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,972] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:23,977] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:23,978] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:23,978] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:23,979] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:23,980] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:23,981] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:23,982] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:23,983] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:23,983] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:23,984] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:23,985] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:23,986] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:23,988] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:23,989] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:23,990] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:23,991] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:23,992] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:23,993] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:23,994] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:23,995] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:23,996] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:23,997] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:23,998] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:23,999] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:24,000] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:24,001] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:24,004] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,005] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,006] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,008] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,009] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,009] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:24,011] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,012] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:24,013] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:24,014] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:24,015] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:24,016] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:24,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,018] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,020] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,022] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,024] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,026] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,026] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,028] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,029] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,031] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,034] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,035] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,036] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,038] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,038] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,040] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:24,042] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:24,043] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,044] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:24,045] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:24,047] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:24,048] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:24,050] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:24,053] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:24,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,056] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,056] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,057] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,062] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:24,067] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:24,068] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:24,069] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:24,070] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:24,071] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:24,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,074] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,080] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,083] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,084] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,093] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:24,094] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:24,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:24,096] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:24,097] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:24,098] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:24,098] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,099] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,100] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,103] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,105] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:24,105] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:24,106] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:24,107] {spark_submit.py:495} INFO - 23/03/03 15:20:23 ERROR Inbox: Ignoring error
[2023-03-03 15:20:24,108] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,109] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,112] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,113] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:24,113] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:24,115] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:24,115] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:24,117] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:24,118] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:24,118] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:24,119] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:24,120] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:24,121] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,122] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,123] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,124] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,125] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,132] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,132] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:24,133] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:24,134] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:24,135] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:24,136] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:24,137] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:24,138] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:24,138] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:24,139] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:24,140] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,140] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,140] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,141] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,142] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,142] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,144] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,144] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,146] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,146] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,152] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,154] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,155] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,155] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,156] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,156] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,157] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,157] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,158] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,158] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:24,159] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:24,160] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,160] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:24,161] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:24,162] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:24,162] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:24,163] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:24,163] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:24,164] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,165] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,166] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,174] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:24,175] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:24,175] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:24,176] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:24,176] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:24,177] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:24,177] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,178] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,181] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,182] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,182] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,183] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,184] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:24,184] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:24,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:24,185] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:24,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:24,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:24,189] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,190] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,191] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,193] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,196] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,196] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,197] {spark_submit.py:495} INFO - 23/03/03 15:20:23 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:24,197] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,198] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,199] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,200] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:24,203] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:24,204] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:24,211] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:24,213] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:24,215] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:24,216] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,222] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:24,223] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:24,224] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,224] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:24,225] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:24,226] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:24,227] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:24,227] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:24,228] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,229] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,230] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:24,237] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:24,238] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:24,239] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:24,240] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:24,241] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:24,241] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:24,243] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:24,244] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:24,245] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,264] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,279] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,289] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,302] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:24,305] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,307] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:24,309] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:24,312] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:24,313] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:24,314] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:24,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,316] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,316] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,317] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,318] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,320] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,353] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,355] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,356] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,359] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,363] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,366] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,371] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,374] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,376] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,380] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,382] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,384] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,397] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,400] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:24,402] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:24,413] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,417] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:24,423] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:24,425] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:24,425] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:24,426] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:24,427] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:24,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,430] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,431] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,435] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:24,436] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:24,437] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:24,438] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:24,439] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:24,440] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:24,440] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,441] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,447] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,447] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,449] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,452] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,454] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,456] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,457] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:24,459] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:24,460] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:24,461] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:24,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:24,463] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:24,463] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,468] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,469] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,470] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,472] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,473] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:24,473] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:24,475] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:24,476] {spark_submit.py:495} INFO - 23/03/03 15:20:23 ERROR Inbox: Ignoring error
[2023-03-03 15:20:24,477] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,479] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:24,484] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:24,485] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:24,486] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:24,487] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:24,488] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:24,489] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:24,490] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:24,491] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:24,494] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,495] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,495] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,496] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,498] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,507] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,508] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:24,513] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:24,517] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:24,522] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:24,524] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:24,543] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:24,546] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:24,548] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:24,550] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:24,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,557] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,559] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,559] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,562] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,565] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,566] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,568] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,578] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,579] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,586] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,591] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,599] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,605] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,607] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,608] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,608] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,611] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:24,612] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:24,613] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,613] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:24,614] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:24,616] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:24,618] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:24,618] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:24,619] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:24,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,627] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,632] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,634] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,638] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:24,640] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:24,641] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:24,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:24,655] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:24,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:24,658] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,660] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,661] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,667] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,669] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,673] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:24,674] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:24,680] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:24,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:24,686] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:24,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:24,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,695] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,695] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,696] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,699] {spark_submit.py:495} INFO - 23/03/03 15:20:23 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:24,700] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,701] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,702] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,703] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:24,704] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:24,704] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:24,710] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:24,711] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:24,712] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:24,713] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,713] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:24,714] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:24,715] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,718] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:24,718] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:24,719] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:24,720] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:24,721] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:24,727] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,728] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,729] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:24,729] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:24,730] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:24,732] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:24,733] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:24,734] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:24,735] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:24,743] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:24,744] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:24,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,746] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,747] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,748] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,749] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:24,750] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,750] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:24,751] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:24,752] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:24,753] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:24,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:24,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,755] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,768] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,769] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,770] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,771] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,771] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,772] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,773] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,774] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,775] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,776] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,787] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,789] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,793] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,796] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,803] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:24,808] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,813] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:24,815] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:24,816] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,818] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:24,820] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:24,821] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:24,827] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:24,832] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:24,835] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:24,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,842] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,849] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,851] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,852] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:24,854] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:24,857] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:24,864] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:24,872] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:24,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:24,878] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:24,879] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:24,880] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:24,885] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:24,887] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:24,892] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:24,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:24,896] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:24,898] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:24,901] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:24,902] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:24,904] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:24,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:24,910] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:24,913] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:24,914] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:24,915] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,916] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,916] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,917] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,918] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,918] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,919] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:24,921] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:24,921] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:24,922] {spark_submit.py:495} INFO - 23/03/03 15:20:23 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:24,923] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,924] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,925] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,926] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:24,927] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:24,928] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:24,929] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:24,930] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:24,934] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:24,935] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:24,935] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:24,936] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:24,937] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,939] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:24,940] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:24,941] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:24,942] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:24,943] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:24,943] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:24,946] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:24,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:24,950] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:24,954] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:24,956] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:24,957] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:24,958] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:24,958] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:24,959] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:24,960] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:24,963] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:24,971] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:24,974] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:24,976] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:24,978] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:24,985] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:24,988] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:24,989] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:24,991] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:24,995] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:24,997] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:25,003] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:25,004] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:25,005] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:25,009] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,011] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,020] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,031] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,035] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,036] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,041] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,042] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,043] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,043] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,044] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,053] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,054] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,054] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,056] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,058] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,061] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:25,062] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:25,063] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:25,064] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:25,065] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:25,067] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:25,068] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:25,069] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:25,070] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:25,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,071] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,072] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,072] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,073] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:25,074] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:25,074] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:25,075] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:25,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:25,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:25,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,079] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,080] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,084] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,086] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,088] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,088] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,089] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,089] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:25,090] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:25,091] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:25,093] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:25,094] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:25,095] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:25,097] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,099] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,103] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,105] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:25,105] {spark_submit.py:495} INFO - 23/03/03 15:20:23 ERROR Inbox: Ignoring error
[2023-03-03 15:20:25,106] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:25,123] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:25,123] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:25,124] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:25,125] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:25,126] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:25,128] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:25,131] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:25,141] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:25,143] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:25,144] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:25,144] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:25,145] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,146] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,151] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,153] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:25,153] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:25,154] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:25,155] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:25,156] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:25,160] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:25,160] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:25,161] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:25,162] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:25,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:25,163] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,164] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,166] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,170] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,171] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,173] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,174] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,175] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,175] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,177] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,177] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,181] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,183] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,189] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,192] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:25,193] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:25,194] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:25,198] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:25,203] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:25,205] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:25,206] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:25,207] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:25,208] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:25,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,210] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,212] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:25,213] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:25,213] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:25,214] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:25,215] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:25,216] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:25,217] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,218] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,219] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,220] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,221] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,222] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,223] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,224] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,226] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:25,227] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:25,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:25,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:25,229] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:25,230] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:25,230] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,232] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,232] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,235] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:25,239] {spark_submit.py:495} INFO - 23/03/03 15:20:23 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:25,241] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:25,244] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:25,245] {spark_submit.py:495} INFO - 23/03/03 15:20:24 ERROR Inbox: Ignoring error
[2023-03-03 15:20:25,246] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:25,246] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:25,247] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:25,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:25,249] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:25,249] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:25,250] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:25,251] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:25,252] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:25,252] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:25,253] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:25,254] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:25,259] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,262] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,263] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,264] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,265] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,266] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:25,267] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:25,268] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:25,269] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:25,269] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:25,270] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:25,271] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:25,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:25,273] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:25,284] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:25,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,285] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,287] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,288] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,289] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,291] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,291] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,293] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,304] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,307] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,334] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,334] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,336] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,337] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,340] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:25,341] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:25,342] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:25,343] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:25,343] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:25,345] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:25,345] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:25,350] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:25,352] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:25,354] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,356] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,363] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,375] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:25,376] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:25,378] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:25,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:25,384] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:25,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:25,388] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,390] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,394] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,395] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,398] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,400] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,404] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,406] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:25,409] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:25,409] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:25,410] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:25,413] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:25,417] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:25,423] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,443] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,445] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,446] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,448] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:25,450] {spark_submit.py:495} INFO - 23/03/03 15:20:24 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:25,451] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:25,453] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:25,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:25,460] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:25,461] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:25,462] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:25,466] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:25,467] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:25,471] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:25,473] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:25,474] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:25,475] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:25,476] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:25,477] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:25,478] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:25,478] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:25,479] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:25,480] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:25,481] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:25,481] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:25,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:25,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:25,484] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:25,487] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:25,488] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:25,489] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:25,489] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:25,498] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:25,503] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:25,505] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:25,507] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,509] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,512] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,513] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,516] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:25,517] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:25,517] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:25,518] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:25,520] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:25,524] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:25,525] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:25,526] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:25,526] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,527] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,528] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,529] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,530] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,531] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,532] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,534] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,537] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,543] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,544] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,548] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,548] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,552] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,553] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,559] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,560] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,562] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,564] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:25,565] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:25,566] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:25,568] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:25,568] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:25,569] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:25,570] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:25,571] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:25,577] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:25,578] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,579] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,580] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,581] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,582] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:25,583] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:25,585] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:25,587] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:25,588] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:25,593] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:25,595] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,597] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,597] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,598] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,599] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,604] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,605] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,606] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,607] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:25,608] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:25,608] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:25,609] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:25,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:25,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:25,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,613] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,614] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,615] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,615] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,616] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:25,617] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:25,618] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:25,618] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:25,620] {spark_submit.py:495} INFO - 23/03/03 15:20:24 ERROR Inbox: Ignoring error
[2023-03-03 15:20:25,622] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:25,623] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:25,624] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:25,625] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:25,626] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:25,627] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:25,627] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:25,628] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:25,628] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:25,629] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:25,630] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:25,631] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:25,631] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,632] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,633] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,635] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:25,636] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:25,637] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:25,638] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:25,639] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:25,643] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:25,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:25,647] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:25,648] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:25,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:25,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,650] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,655] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,656] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,657] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,658] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,663] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,668] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,669] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,671] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,673] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,686] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:25,687] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:25,688] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:25,689] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:25,690] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:25,690] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:25,691] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:25,692] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:25,692] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:25,693] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,696] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,696] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:25,698] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:25,698] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:25,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:25,723] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:25,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:25,737] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,738] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,746] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,747] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,747] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,750] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:25,751] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:25,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:25,768] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:25,769] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:25,769] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:25,773] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,775] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,775] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,777] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,778] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,779] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:25,793] {spark_submit.py:495} INFO - 23/03/03 15:20:24 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:25,802] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:25,813] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:25,831] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:25,832] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:25,833] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:25,834] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:25,835] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:25,840] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:25,851] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:25,851] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:25,855] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:25,863] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:25,873] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:25,883] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:25,883] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:25,884] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:25,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:25,885] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:25,886] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:25,887] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:25,887] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:25,888] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:25,888] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:25,889] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:25,889] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:25,890] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:25,890] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:25,899] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:25,900] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:25,901] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:25,902] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:25,906] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:25,907] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:25,907] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:25,909] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:25,910] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:25,912] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:25,915] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:25,916] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:25,916] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:25,917] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:25,918] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:25,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:25,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:25,920] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:25,921] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:25,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:25,964] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:25,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:25,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:25,966] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:25,969] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:25,973] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:25,983] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:25,993] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:26,011] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:26,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:26,023] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:26,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:26,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:26,028] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:26,034] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:26,036] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:26,037] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:26,039] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:26,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:26,056] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:26,062] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:26,064] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:26,066] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:26,073] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:26,113] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:26,127] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:26,147] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:26,151] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:26,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:26,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:26,194] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:26,207] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:26,221] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:26,225] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:26,237] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:26,256] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:26,333] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:26,338] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:26,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:26,340] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:26,344] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:26,348] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:26,351] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:26,352] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:26,449] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:26,468] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:26,470] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:26,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:26,484] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:26,489] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:26,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:26,495] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:26,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:26,500] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:26,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:26,506] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:26,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:26,512] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:26,517] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:26,520] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:26,523] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:26,524] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:26,525] {spark_submit.py:495} INFO - 23/03/03 15:20:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:26,528] {spark_submit.py:495} INFO - 23/03/03 15:20:24 ERROR Inbox: Ignoring error
[2023-03-03 15:20:26,529] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:26,532] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:26,533] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:26,534] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:26,548] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:26,549] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:26,552] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:26,581] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:26,581] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:26,582] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:26,584] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:26,597] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:26,599] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:26,604] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:26,605] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:26,605] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:26,606] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:26,607] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:26,608] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:26,610] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:26,611] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:26,612] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:26,613] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:26,615] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:26,617] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:26,622] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:26,641] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:26,642] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:26,643] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:26,644] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:26,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:26,646] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:26,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:26,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:26,650] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:26,659] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:26,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:26,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:26,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:26,664] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:26,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:26,673] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:26,675] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:26,677] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:26,678] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:26,680] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:26,686] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:26,691] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:26,699] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:26,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:26,712] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:26,723] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:26,733] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:26,735] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:26,743] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:26,753] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:26,763] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:26,773] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:26,782] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:26,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:26,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:26,798] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:26,805] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:26,808] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:26,810] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:26,810] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:26,811] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:26,813] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:26,816] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:26,817] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:26,818] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:26,821] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:26,821] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:26,822] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:26,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:26,845] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:26,846] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:26,847] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:26,849] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:26,850] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:26,851] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:26,852] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:26,854] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:26,854] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:26,855] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:26,860] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:26,862] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:26,863] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:26,864] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:26,870] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:26,872] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:26,893] {spark_submit.py:495} INFO - 23/03/03 15:20:24 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:26,898] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:26,900] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:26,903] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:26,906] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:26,908] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:26,911] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:26,912] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:26,914] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:26,915] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:26,918] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:26,919] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:26,920] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:26,921] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:26,921] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:26,922] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:26,923] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:26,923] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:26,924] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:26,925] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:26,927] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:26,929] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:26,931] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:26,934] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:26,945] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:26,948] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:26,949] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:26,949] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:26,950] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:26,951] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:26,951] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:26,954] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:26,965] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:26,967] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:26,969] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:26,970] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:26,973] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:26,980] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:26,985] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:26,990] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:27,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:27,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:27,032] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:27,037] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:27,039] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,045] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,049] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,052] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,053] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,059] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,061] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,068] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,072] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,083] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,097] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,103] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,120] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,124] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,127] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,131] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,152] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:27,158] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:27,161] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:27,164] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:27,167] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:27,183] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:27,188] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:27,204] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:27,215] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:27,226] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,238] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,293] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:27,294] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:27,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:27,306] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:27,313] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:27,323] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:27,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,327] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,343] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,346] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,354] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,363] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,377] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:27,397] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:27,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:27,399] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:27,400] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:27,401] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:27,411] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,422] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,423] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,424] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,424] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,425] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:27,426] {spark_submit.py:495} INFO - 23/03/03 15:20:25 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:27,426] {spark_submit.py:495} INFO - 23/03/03 15:20:25 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:27,427] {spark_submit.py:495} INFO - 23/03/03 15:20:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:27,431] {spark_submit.py:495} INFO - 23/03/03 15:20:25 ERROR Inbox: Ignoring error
[2023-03-03 15:20:27,433] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:27,434] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:27,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:27,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:27,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:27,436] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:27,437] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:27,438] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:27,439] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:27,439] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:27,440] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:27,441] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:27,442] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,442] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,443] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,444] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,444] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,445] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:27,446] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:27,446] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:27,447] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:27,447] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:27,448] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:27,456] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:27,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:27,462] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:27,463] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:27,464] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,465] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,484] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,485] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,489] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,490] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,491] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,494] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,503] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,505] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,507] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,509] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,511] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,513] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,514] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,520] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,521] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:27,530] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:27,541] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:27,542] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:27,543] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:27,543] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:27,544] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:27,546] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:27,554] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:27,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,565] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,572] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,599] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:27,600] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:27,602] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:27,603] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:27,607] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:27,608] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:27,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,610] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,614] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,615] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,616] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,619] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:27,620] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:27,623] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:27,625] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:27,626] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:27,626] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:27,627] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,628] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,628] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,629] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,630] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,631] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:27,632] {spark_submit.py:495} INFO - 23/03/03 15:20:25 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:27,633] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:27,634] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:27,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:27,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:27,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:27,641] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:27,642] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:27,645] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:27,647] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:27,648] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:27,650] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:27,650] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:27,651] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:27,653] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:27,654] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:27,655] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:27,656] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:27,656] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:27,657] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:27,658] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:27,663] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:27,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:27,669] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:27,671] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:27,671] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:27,673] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:27,674] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:27,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:27,689] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:27,692] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:27,694] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,700] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,701] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,701] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,702] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:27,703] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:27,703] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:27,704] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:27,705] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:27,706] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:27,707] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:27,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:27,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,721] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,723] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,725] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,725] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,726] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,729] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,730] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,732] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,732] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,737] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,741] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,748] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,749] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,754] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:27,755] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:27,755] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:27,757] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:27,758] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:27,759] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:27,761] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:27,761] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:27,763] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:27,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,765] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,765] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,767] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:27,768] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:27,768] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:27,769] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:27,770] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:27,771] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:27,773] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,774] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,781] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,782] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,784] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,786] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,787] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,793] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:27,795] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:27,796] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:27,797] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:27,799] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:27,800] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:27,801] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,802] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,803] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,803] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,804] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,808] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:27,814] {spark_submit.py:495} INFO - 23/03/03 15:20:25 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:27,815] {spark_submit.py:495} INFO - 23/03/03 15:20:25 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:27,816] {spark_submit.py:495} INFO - 23/03/03 15:20:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:27,817] {spark_submit.py:495} INFO - 23/03/03 15:20:25 ERROR Inbox: Ignoring error
[2023-03-03 15:20:27,818] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:27,820] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:27,821] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:27,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:27,824] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:27,825] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:27,826] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:27,827] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:27,828] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:27,828] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:27,829] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:27,830] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:27,831] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,832] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,841] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,843] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,844] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:27,845] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:27,847] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:27,848] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:27,856] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:27,856] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:27,859] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:27,871] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:27,872] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:27,873] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:27,874] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,875] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,875] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,876] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,877] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,878] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,879] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,887] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,888] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,890] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,891] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,894] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,896] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,896] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,897] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,897] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,899] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,900] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,907] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:27,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,917] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:27,918] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:27,918] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:27,919] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:27,919] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:27,920] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:27,921] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:27,922] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:27,923] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:27,924] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,925] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,927] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:27,928] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:27,929] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:27,929] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:27,930] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:27,931] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:27,932] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:27,933] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:27,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:27,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:27,936] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:27,937] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:27,937] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:27,938] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:27,938] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:27,939] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:27,940] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:27,940] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:27,941] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:27,942] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:27,943] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:27,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:27,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,949] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,950] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,950] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,951] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,952] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:27,952] {spark_submit.py:495} INFO - 23/03/03 15:20:25 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:27,954] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:27,955] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:27,956] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:27,957] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:27,958] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:27,959] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:27,960] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:27,961] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:27,967] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:27,967] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:27,968] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:27,969] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:27,970] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:27,970] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:27,971] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:27,972] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:27,972] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:27,973] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:27,976] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:27,977] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:27,978] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:27,979] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:27,982] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:27,983] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:27,984] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:27,985] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:27,985] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:27,986] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:27,987] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:27,988] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:27,988] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:27,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:27,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:27,990] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:27,991] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:27,992] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:27,993] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:27,994] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:27,998] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:28,001] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:28,004] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:28,005] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:28,005] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:28,006] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,009] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,010] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,014] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,015] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,018] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,021] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,029] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:28,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,030] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,039] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,041] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,042] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,043] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,043] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,044] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:28,058] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,060] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:28,062] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:28,064] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:28,065] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:28,066] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:28,067] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:28,069] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:28,072] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:28,074] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:28,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,082] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,083] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,086] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:28,090] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:28,098] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:28,099] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:28,099] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:28,100] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:28,101] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,101] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,102] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,103] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,103] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,106] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,106] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,108] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,111] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:28,117] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:28,120] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:28,122] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:28,123] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:28,126] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:28,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:28,129] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:28,130] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:28,131] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:28,138] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:28,139] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:28,141] {spark_submit.py:495} INFO - 23/03/03 15:20:26 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:28,143] {spark_submit.py:495} INFO - 23/03/03 15:20:26 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:28,144] {spark_submit.py:495} INFO - 23/03/03 15:20:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:28,145] {spark_submit.py:495} INFO - 23/03/03 15:20:26 ERROR Inbox: Ignoring error
[2023-03-03 15:20:28,146] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:28,146] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:28,148] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:28,148] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:28,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:28,150] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:28,151] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:28,152] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:28,152] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:28,153] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:28,154] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:28,161] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:28,164] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:28,164] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:28,166] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:28,170] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:28,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:28,172] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:28,173] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:28,175] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:28,176] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:28,176] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:28,177] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:28,178] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:28,180] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:28,183] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:28,184] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:28,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,186] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:28,190] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:28,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:28,192] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:28,193] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:28,195] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:28,204] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:28,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:28,210] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:28,212] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:28,215] {spark_submit.py:495} INFO - 23/03/03 15:20:26 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:28,216] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:28,217] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:28,217] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:28,218] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:28,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:28,220] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:28,228] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:28,231] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:28,245] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:28,246] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:28,250] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:28,252] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:28,263] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:28,264] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:28,265] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:28,266] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:28,267] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:28,270] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:28,274] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:28,275] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:28,276] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:28,277] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:28,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:28,278] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:28,279] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:28,280] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:28,281] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:28,282] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:28,284] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:28,284] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:28,285] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:28,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:28,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:28,288] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:28,290] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:28,293] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:28,295] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:28,296] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:28,297] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:28,298] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:28,299] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:28,301] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:28,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:28,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,303] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,304] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,304] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 15:20:28,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 15:20:28,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 15:20:28,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 15:20:28,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 15:20:28,310] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 15:20:28,311] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 15:20:28,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 15:20:28,312] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 15:20:28,316] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 15:20:28,317] {spark_submit.py:495} INFO - 23/03/03 15:20:26 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:28,318] {spark_submit.py:495} INFO - 23/03/03 15:20:26 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:28,319] {spark_submit.py:495} INFO - 23/03/03 15:20:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:28,319] {spark_submit.py:495} INFO - 23/03/03 15:20:26 ERROR Inbox: Ignoring error
[2023-03-03 15:20:28,320] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:28,321] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:28,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:28,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:28,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:28,328] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:28,329] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:28,330] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:28,330] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:28,333] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:28,334] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:28,336] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:28,339] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:28,340] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:28,343] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:28,345] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:28,347] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:28,348] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:28,349] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:28,350] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:28,351] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:28,352] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:28,353] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:28,354] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:28,354] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:28,356] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:28,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:28,359] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,360] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,361] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,363] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,371] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,372] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,380] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,382] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,383] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,386] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:28,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,393] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,394] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,395] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,396] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,400] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,401] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,402] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,403] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:28,404] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,406] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:28,407] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:28,409] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:28,411] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:28,412] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:28,413] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:28,414] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:28,414] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:28,416] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:28,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,420] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,425] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,426] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:28,427] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:28,432] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:28,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:28,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:28,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:28,438] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,440] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,443] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,445] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,447] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,447] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,449] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:28,450] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:28,450] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:28,451] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:28,452] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:28,453] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:28,453] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:28,454] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:28,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:28,456] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:28,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:28,457] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:28,458] {spark_submit.py:495} INFO - 23/03/03 15:20:26 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 15:20:28,458] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:28,459] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:28,460] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:28,461] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 15:20:28,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 15:20:28,468] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 15:20:28,469] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 15:20:28,469] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 15:20:28,470] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 15:20:28,473] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:28,474] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 15:20:28,474] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 15:20:28,475] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:28,476] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 15:20:28,476] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 15:20:28,477] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:28,478] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:28,483] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:28,485] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:28,487] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:28,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:28,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:28,494] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:28,494] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:28,495] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:28,496] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:28,496] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:28,497] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:28,498] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:28,498] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:28,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:28,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:28,500] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:28,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:28,502] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:28,503] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:28,505] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:28,522] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:28,523] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:28,523] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:28,524] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:28,525] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:28,529] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:28,534] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,534] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,535] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,536] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,537] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,538] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,540] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,541] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,542] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,543] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,545] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:28,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,548] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,557] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,558] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,574] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,582] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,585] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,586] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,587] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,588] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:28,589] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,590] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:28,591] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:28,592] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:28,593] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:28,604] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:28,605] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:28,607] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:28,608] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:28,608] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:28,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,613] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:28,619] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:28,623] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:28,643] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:28,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:28,647] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:28,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:28,649] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:28,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:28,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:28,658] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:28,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:28,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:28,662] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:28,662] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:28,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:28,665] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:28,668] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:28,673] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:28,678] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:28,679] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:28,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 15:20:28,683] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:28,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:28,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:28,685] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:28,687] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:28,692] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 15:20:28,694] {spark_submit.py:495} INFO - 23/03/03 15:20:27 INFO Executor: Told to re-register on heartbeat
[2023-03-03 15:20:28,696] {spark_submit.py:495} INFO - 23/03/03 15:20:27 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None) re-registering with master
[2023-03-03 15:20:28,698] {spark_submit.py:495} INFO - 23/03/03 15:20:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 33477, None)
[2023-03-03 15:20:28,700] {spark_submit.py:495} INFO - 23/03/03 15:20:27 ERROR Inbox: Ignoring error
[2023-03-03 15:20:28,701] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 15:20:29,591] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 15:20:29,591] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 15:20:29,592] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 15:20:29,593] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 15:20:29,654] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 15:20:29,657] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 15:20:29,658] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 15:20:29,662] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 15:20:29,663] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 15:20:29,664] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 15:20:29,664] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 15:20:29,666] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 15:20:29,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 15:20:29,682] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 15:20:29,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 15:20:29,696] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 15:20:29,698] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 15:20:29,702] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 15:20:29,703] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 15:20:29,704] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 15:20:29,705] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 15:20:29,705] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:33017
[2023-03-03 15:20:29,706] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 15:20:29,707] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 15:20:29,710] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 15:20:29,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 15:20:29,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:29,719] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:29,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:29,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:29,723] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:29,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:29,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:29,725] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:29,726] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:29,727] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:29,728] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:29,728] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:29,729] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:29,730] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:29,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:29,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:29,732] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:29,732] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:29,733] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:29,734] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:29,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:29,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 15:20:29,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:29,739] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 15:20:29,740] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 15:20:29,741] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 15:20:29,743] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 15:20:29,743] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 15:20:29,744] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 15:20:29,744] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 15:20:29,745] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 15:20:29,749] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 15:20:29,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:29,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:29,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:29,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:29,754] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 15:20:29,755] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 15:20:29,756] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 15:20:29,760] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 15:20:29,761] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 15:20:29,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 15:20:29,776] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 15:20:29,777] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 15:20:29,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 15:20:29,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 15:20:29,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 15:20:29,803] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 15:20:29,806] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 15:20:29,810] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 15:20:29,814] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 15:20:29,816] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 15:20:29,816] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 15:20:29,820] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 15:20:29,822] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 15:20:29,822] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 15:20:29,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 15:20:29,824] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
