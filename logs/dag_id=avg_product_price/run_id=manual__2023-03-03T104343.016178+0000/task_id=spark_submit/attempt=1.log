[2023-03-03 10:43:46,738] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T10:43:43.016178+00:00 [queued]>
[2023-03-03 10:43:46,765] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T10:43:43.016178+00:00 [queued]>
[2023-03-03 10:43:46,765] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-03-03 10:43:46,766] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-03-03 10:43:46,766] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-03-03 10:43:46,797] {taskinstance.py:1377} INFO - Executing <Task(SparkSubmitOperator): spark_submit> on 2023-03-03 10:43:43.016178+00:00
[2023-03-03 10:43:46,802] {standard_task_runner.py:52} INFO - Started process 2148 to run task
[2023-03-03 10:43:46,806] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'avg_product_price', 'spark_submit', 'manual__2023-03-03T10:43:43.016178+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/avg_product_price.py', '--cfg-path', '/tmp/tmpto6uz1p2', '--error-file', '/tmp/tmp1caf118b']
[2023-03-03 10:43:46,808] {standard_task_runner.py:80} INFO - Job 3: Subtask spark_submit
[2023-03-03 10:43:46,884] {task_command.py:370} INFO - Running <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T10:43:43.016178+00:00 [running]> on host 7f5e973bdd66
[2023-03-03 10:43:47,022] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ayyoub
AIRFLOW_CTX_DAG_ID=avg_product_price
AIRFLOW_CTX_TASK_ID=spark_submit
AIRFLOW_CTX_EXECUTION_DATE=2023-03-03T10:43:43.016178+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-03-03T10:43:43.016178+00:00
[2023-03-03 10:43:47,034] {base.py:68} INFO - Using connection ID 'spark-hadoop' for task execution.
[2023-03-03 10:43:47,036] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master local[*] --name arrow-spark /hadoop-data/map_reduce/spark/average_price.py
[2023-03-03 10:44:07,763] {spark_submit.py:495} INFO - 23/03/03 10:44:07 INFO SparkContext: Running Spark version 3.3.2
[2023-03-03 10:44:07,963] {spark_submit.py:495} INFO - 23/03/03 10:44:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-03-03 10:44:08,300] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO ResourceUtils: ==============================================================
[2023-03-03 10:44:08,301] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-03-03 10:44:08,302] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO ResourceUtils: ==============================================================
[2023-03-03 10:44:08,303] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO SparkContext: Submitted application: average_product_price
[2023-03-03 10:44:08,360] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-03-03 10:44:08,391] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO ResourceProfile: Limiting resource is cpu
[2023-03-03 10:44:08,393] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-03-03 10:44:08,539] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO SecurityManager: Changing view acls to: ***
[2023-03-03 10:44:08,541] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO SecurityManager: Changing modify acls to: ***
[2023-03-03 10:44:08,542] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO SecurityManager: Changing view acls groups to:
[2023-03-03 10:44:08,544] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO SecurityManager: Changing modify acls groups to:
[2023-03-03 10:44:08,545] {spark_submit.py:495} INFO - 23/03/03 10:44:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2023-03-03 10:44:09,197] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO Utils: Successfully started service 'sparkDriver' on port 35723.
[2023-03-03 10:44:09,273] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO SparkEnv: Registering MapOutputTracker
[2023-03-03 10:44:09,378] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO SparkEnv: Registering BlockManagerMaster
[2023-03-03 10:44:09,432] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-03-03 10:44:09,434] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-03-03 10:44:09,447] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-03-03 10:44:09,537] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-46d16dd9-843c-47f2-8757-b39187fb0b9d
[2023-03-03 10:44:09,584] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-03-03 10:44:09,620] {spark_submit.py:495} INFO - 23/03/03 10:44:09 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-03-03 10:44:47,149] {base_job.py:229} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 219, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2877, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2950, in _merge
    merged = self.get(mapper.class_, key[1], identity_token=key[2])
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2702, in get
    identity_token=identity_token,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2800, in _get_impl
    load_options=load_options,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 535, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-03-03 10:46:08,765] {base_job.py:229} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 201, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2877, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2950, in _merge
    merged = self.get(mapper.class_, key[1], identity_token=key[2])
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2702, in get
    identity_token=identity_token,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2800, in _get_impl
    load_options=load_options,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 535, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-03-03 10:46:38,982] {spark_submit.py:495} INFO - 23/03/03 10:46:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-03-03 10:46:41,041] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO Executor: Starting executor ID driver on host 7f5e973bdd66
[2023-03-03 10:46:41,166] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-03-03 10:46:41,361] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43621.
[2023-03-03 10:46:41,362] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO NettyBlockTransferService: Server created on 7f5e973bdd66:43621
[2023-03-03 10:46:41,379] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-03-03 10:46:41,478] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:46:41,524] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO BlockManagerMasterEndpoint: Registering block manager 7f5e973bdd66:43621 with 434.4 MiB RAM, BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:46:41,544] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:46:41,550] {spark_submit.py:495} INFO - 23/03/03 10:46:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:46:42,675] {spark_submit.py:495} INFO - /opt/spark-3.3.2-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2023-03-03 10:46:43,140] {spark_submit.py:495} INFO - 23/03/03 10:46:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-03-03 10:46:43,154] {spark_submit.py:495} INFO - 23/03/03 10:46:43 INFO SharedState: Warehouse path is 'file:/home/***/spark-warehouse'.
[2023-03-03 10:47:05,364] {base_job.py:229} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 201, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2877, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2950, in _merge
    merged = self.get(mapper.class_, key[1], identity_token=key[2])
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2702, in get
    identity_token=identity_token,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2800, in _get_impl
    load_options=load_options,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 535, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-03-03 10:50:01,111] {spark_submit.py:495} INFO - 23/03/03 10:50:01 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 198707 ms exceeds timeout 120000 ms
[2023-03-03 10:50:01,311] {spark_submit.py:495} INFO - 23/03/03 10:50:01 WARN SparkContext: Killing executors is not supported by current scheduler.
[2023-03-03 10:50:02,100] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:02,102] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:02,108] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:02,220] {spark_submit.py:495} INFO - 23/03/03 10:50:02 ERROR Inbox: Ignoring error
[2023-03-03 10:50:02,222] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:02,222] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:02,223] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:02,223] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:02,224] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:02,225] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:02,229] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:02,230] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:02,231] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:02,233] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:02,235] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:02,236] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:02,238] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,238] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,239] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,249] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,262] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:02,265] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:02,266] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:02,267] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:02,270] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:02,271] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:02,273] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:02,274] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:02,289] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:02,291] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:02,292] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,293] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,300] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,312] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,316] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,317] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,324] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,325] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,329] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,343] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,351] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,356] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,383] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:02,393] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:02,403] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:02,405] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:02,409] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:02,413] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:02,423] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:02,433] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:02,435] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:02,439] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,442] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,445] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,455] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,463] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:02,465] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:02,467] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:02,475] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:02,481] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:02,489] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:02,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,494] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,501] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,504] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,506] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,507] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,508] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,509] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,511] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,521] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:02,522] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:02,524] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:02,530] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:02,533] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:02,534] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:02,537] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,540] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,543] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,544] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,546] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,550] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:02,551] {spark_submit.py:495} INFO - 23/03/03 10:50:02 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:02,552] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:02,553] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:02,557] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:02,559] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:02,561] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:02,565] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:02,568] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:02,570] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:02,572] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:02,574] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:02,574] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:02,575] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:02,576] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:02,577] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:02,578] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:02,579] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:02,579] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:02,580] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:02,582] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:02,583] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:02,584] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:02,585] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:02,586] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:02,586] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:02,587] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:02,588] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:02,590] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:02,591] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:02,592] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:02,593] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:02,601] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,602] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,603] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,604] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,605] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,605] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:02,606] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:02,607] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:02,608] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:02,608] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:02,609] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:02,610] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:02,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:02,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,612] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,615] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,616] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,618] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,619] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,620] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,621] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,621] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,622] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,623] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,623] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,624] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,625] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,627] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,629] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,630] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,632] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,633] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,634] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:02,639] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:02,641] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:02,642] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:02,643] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:02,643] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:02,644] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:02,650] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:02,651] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:02,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,655] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,660] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:02,661] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:02,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:02,663] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:02,665] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:02,666] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:02,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,668] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,668] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,669] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,672] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,674] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,676] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:02,677] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:02,678] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:02,680] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:02,682] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:02,683] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:02,683] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,685] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,686] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,687] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,687] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:02,688] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:02,689] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:02,690] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:02,691] {spark_submit.py:495} INFO - 23/03/03 10:50:02 ERROR Inbox: Ignoring error
[2023-03-03 10:50:02,692] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:02,692] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:02,693] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:02,697] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:02,700] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:02,706] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:02,707] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:02,707] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:02,708] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:02,709] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:02,717] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:02,719] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:02,722] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,723] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,725] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,729] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:02,729] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:02,730] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:02,731] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:02,734] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:02,735] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:02,737] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:02,737] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:02,738] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:02,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:02,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,740] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,741] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,742] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,745] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,748] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,755] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,755] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,755] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,756] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,756] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,757] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,758] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,758] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,759] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,760] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,760] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,761] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:02,763] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:02,764] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:02,766] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:02,768] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:02,770] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:02,772] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:02,776] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:02,776] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:02,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,786] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,786] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,787] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,788] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:02,788] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:02,789] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:02,790] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:02,791] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:02,791] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:02,792] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,793] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,794] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,795] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,797] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,799] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,801] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,802] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,803] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,803] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,804] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:02,805] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:02,805] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:02,806] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:02,807] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:02,808] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:02,809] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,810] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,811] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,812] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,812] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,813] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:02,821] {spark_submit.py:495} INFO - 23/03/03 10:50:02 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:02,822] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:02,822] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:02,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:02,824] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:02,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:02,825] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:02,826] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:02,827] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:02,828] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:02,828] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:02,829] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:02,830] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:02,831] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:02,833] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:02,834] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:02,835] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:02,836] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:02,836] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:02,837] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:02,838] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:02,839] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:02,839] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:02,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:02,841] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:02,841] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:02,842] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:02,843] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:02,844] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:02,844] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:02,846] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:02,847] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,851] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,852] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,855] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:02,856] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:02,858] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:02,858] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:02,859] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:02,864] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:02,866] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:02,867] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:02,869] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,869] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,871] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,875] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,875] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,876] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,877] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,878] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,878] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,879] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,882] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,884] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,887] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,889] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,890] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,891] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,894] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,896] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,901] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,907] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:02,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,910] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:02,910] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:02,911] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:02,916] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:02,918] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:02,922] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:02,927] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:02,929] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:02,930] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:02,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,936] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,936] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:02,937] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:02,938] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:02,939] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:02,941] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:02,942] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:02,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:02,946] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:02,947] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:02,949] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:02,954] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:02,957] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:02,958] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:02,959] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:02,959] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:02,962] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:02,963] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:02,965] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:02,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:02,967] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:02,969] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:02,970] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:02,972] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:02,973] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:02,975] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:02,977] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:02,983] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:02,984] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:02,985] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:02,986] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:02,987] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:02,988] {spark_submit.py:495} INFO - 23/03/03 10:50:02 ERROR Inbox: Ignoring error
[2023-03-03 10:50:02,988] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:02,989] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:02,990] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:02,991] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:02,992] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:02,993] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:02,994] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:02,994] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:02,995] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:02,996] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:02,996] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:02,997] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:02,999] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,000] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,001] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,002] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,003] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,003] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,004] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,004] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,005] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,005] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,006] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,006] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,007] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,008] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,008] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,009] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,009] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,010] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,010] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,011] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,012] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,012] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,014] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,015] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,015] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,016] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,016] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,017] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,018] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,020] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,020] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,020] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,021] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,021] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,022] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,022] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,023] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,024] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,026] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,026] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,028] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,028] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,029] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,029] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,031] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,033] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,033] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,034] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,035] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,035] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,035] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,037] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,037] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,039] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,040] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,040] {spark_submit.py:495} INFO - 23/03/03 10:50:02 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,042] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,043] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,043] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,044] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,044] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,045] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,046] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,046] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,047] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,047] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,048] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,049] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,049] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,050] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,050] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,051] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,051] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,052] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,052] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,052] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,053] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,053] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,054] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,055] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,055] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,056] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,057] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,057] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,058] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,058] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,059] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,060] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,060] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,061] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,061] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,062] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,063] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,064] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,065] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,065] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,066] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,066] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,067] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,068] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,068] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,069] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,069] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,071] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,071] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,072] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,074] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,074] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,078] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,078] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,080] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,081] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,082] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,082] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,083] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,084] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,084] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,085] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,085] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,086] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,086] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,088] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,089] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,089] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,090] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,090] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,091] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,091] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,092] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,092] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,095] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,096] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,097] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,098] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,100] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,103] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,105] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,105] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,106] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,108] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,109] {spark_submit.py:495} INFO - 23/03/03 10:50:02 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,110] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,110] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,111] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,111] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,112] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,113] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,113] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,114] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,115] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,115] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,116] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,116] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,117] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,119] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,119] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,120] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,121] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,122] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,122] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,123] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,123] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,124] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,124] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,124] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,125] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,125] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,126] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,126] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,127] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,127] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:50:03,127] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:50:03,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:50:03,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:50:03,129] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:50:03,129] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:50:03,130] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:50:03,131] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:50:03,132] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:50:03,132] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:50:03,133] {spark_submit.py:495} INFO - 23/03/03 10:50:02 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,134] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,134] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,136] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,137] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,137] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,138] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,138] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,138] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,139] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,139] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,140] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,140] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,141] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,141] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,142] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,142] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,143] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,144] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,144] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,145] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,146] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,146] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,147] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,147] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,148] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,149] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,149] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,150] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,150] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,151] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,152] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,152] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,152] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,153] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,153] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,154] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,155] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,155] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,156] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,156] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,157] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,157] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,158] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,159] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,160] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,160] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:50:03,161] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:50:03,161] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:50:03,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:50:03,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:50:03,163] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:50:03,163] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:50:03,164] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:50:03,165] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:50:03,166] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:50:03,167] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,168] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,169] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,169] {spark_submit.py:495} INFO - 23/03/03 10:50:02 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,170] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,170] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,172] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,173] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,173] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,174] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,174] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,175] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,176] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,176] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,177] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,177] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,178] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,178] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,179] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,179] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,180] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,180] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,181] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,182] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,183] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,184] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,185] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,185] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,186] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,186] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,187] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,189] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,189] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,190] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,190] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,192] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,193] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,193] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,194] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,194] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,195] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,196] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,196] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,197] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,198] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,199] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,200] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,201] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,201] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,202] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,202] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,203] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,203] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,204] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,204] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,205] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,205] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,207] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,207] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,207] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,209] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,209] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,210] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,210] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,211] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,212] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,212] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,213] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,213] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,214] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,214] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,216] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,217] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,217] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,221] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,222] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,222] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,223] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,223] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,224] {spark_submit.py:495} INFO - 23/03/03 10:50:02 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,224] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,225] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,225] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,227] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,228] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,228] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,229] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,234] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,234] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,235] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,236] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,236] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,237] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,238] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,239] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,241] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,241] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,242] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,242] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,243] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,244] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,244] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,245] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,245] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,246] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,246] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,247] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,247] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,249] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,250] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,250] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,251] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,251] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,252] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,252] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,254] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,254] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,255] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,255] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,256] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,256] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,257] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,257] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,257] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,258] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,258] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,259] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,259] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,259] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,260] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,260] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,261] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,261] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,262] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,263] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,263] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,264] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,265] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,266] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,267] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,267] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,268] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,268] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,269] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,269] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,270] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,270] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,270] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,272] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,273] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,273] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,274] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,275] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,275] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,276] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,276] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,277] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,277] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,278] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,278] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,279] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,279] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,280] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,281] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,282] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,283] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,283] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,284] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,285] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,285] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,288] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,288] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,288] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,289] {spark_submit.py:495} INFO - 23/03/03 10:50:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,289] {spark_submit.py:495} INFO - 23/03/03 10:50:02 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,290] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,291] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,291] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,292] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,292] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,293] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,293] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,294] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,294] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,295] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,295] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,296] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,296] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,297] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,298] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,299] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,300] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,301] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,301] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,302] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,302] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,303] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,303] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,304] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,304] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,304] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,306] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,308] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,309] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,310] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,310] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,313] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,313] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,314] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,316] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,317] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,317] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,318] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,318] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,319] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,319] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,320] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,320] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,321] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,321] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,322] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,322] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,323] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,323] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,324] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,324] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,327] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,327] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,329] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,329] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,330] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,331] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,333] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,334] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,336] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,337] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,337] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,338] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,338] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,339] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,339] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,340] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,340] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,340] {spark_submit.py:495} INFO - 23/03/03 10:50:02 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,341] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,341] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,342] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,342] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,343] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,343] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,344] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,344] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,345] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,345] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,346] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,347] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,348] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,348] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,349] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,352] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,352] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,353] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,353] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,354] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,355] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,355] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,356] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,356] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,356] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,357] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,357] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,358] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,358] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,359] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,360] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,360] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,361] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,361] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,362] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,362] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,363] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,364] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,366] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,367] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,367] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,368] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,368] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,369] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,369] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,371] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,371] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,372] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,372] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,374] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,374] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,375] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,375] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,377] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,377] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,378] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,380] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,381] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,381] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,382] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,383] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,384] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,384] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,385] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,385] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,386] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,386] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,386] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,387] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,387] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,388] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,388] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,389] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,389] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,390] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,391] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,391] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,395] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,396] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,396] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,397] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,398] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,398] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,400] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,401] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,401] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,402] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,402] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,402] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,403] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,403] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,404] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,405] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,405] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,406] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,406] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,407] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,407] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,408] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,408] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,409] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,409] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,410] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,410] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,411] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,411] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,412] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,413] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,413] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,414] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,415] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,415] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,416] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,416] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,417] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,418] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,418] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,419] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,420] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,420] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,421] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,421] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,423] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,423] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,425] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:50:03,425] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:50:03,426] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:50:03,426] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:50:03,427] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:50:03,427] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:50:03,428] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:50:03,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:50:03,429] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:50:03,430] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:50:03,430] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,431] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,432] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,432] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,434] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,435] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,435] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,436] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,436] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,437] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,437] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,437] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,438] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,439] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,439] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,440] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,440] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,441] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,441] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,442] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,443] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,444] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,444] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,445] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,445] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,446] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,446] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,447] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,448] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,448] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,452] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,453] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,454] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,454] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,455] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,455] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,456] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,457] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,459] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,459] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,460] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,461] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,461] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,461] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,462] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:50:03,462] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:50:03,463] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:50:03,463] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:50:03,464] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:50:03,465] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:50:03,465] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:50:03,466] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:50:03,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:50:03,467] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:50:03,468] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,468] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,469] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,469] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,469] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,470] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,470] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,471] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,471] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,472] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,472] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,473] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,474] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,474] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,475] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,475] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,476] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,476] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,477] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,477] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,478] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,478] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,478] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,479] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,480] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,480] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,481] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,483] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,484] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,484] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,485] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,485] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,486] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,486] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,487] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,488] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,488] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,491] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,494] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,495] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,496] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,497] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,498] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,498] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,499] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,500] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,501] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,501] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,502] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,502] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,503] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,504] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,505] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,505] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,506] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,507] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,507] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,509] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,509] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,512] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,512] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,513] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,514] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,515] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,516] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,517] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,517] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,518] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,518] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,519] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,519] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,520] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,520] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,521] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,521] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,522] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,522] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,523] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,523] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,524] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,524] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,525] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,526] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,526] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,526] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,527] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,527] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,528] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,528] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,529] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,529] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,530] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,530] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,531] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,532] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,532] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,533] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,534] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,534] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,535] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,535] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,536] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,536] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,537] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,537] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,538] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,538] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,539] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,539] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,540] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,540] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,540] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,541] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,541] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,542] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,542] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,543] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,544] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,544] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,545] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,545] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,546] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,546] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,548] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,548] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,549] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,550] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,551] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,552] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,552] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,554] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,555] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,555] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,557] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,557] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,558] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,558] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,559] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,559] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,560] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,560] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,561] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,562] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,562] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,563] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,564] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,564] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,565] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,566] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,567] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,567] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,568] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,569] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,569] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,572] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,572] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,573] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,573] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,574] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,574] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,576] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,576] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,576] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,577] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,577] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,578] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,578] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,579] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,580] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,580] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,581] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,581] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,582] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,582] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,584] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,584] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,584] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,585] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,585] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,586] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,586] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,586] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,587] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,587] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,588] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,588] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,588] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,589] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,589] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,590] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,590] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,590] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,591] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,591] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,591] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,592] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,592] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,592] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,595] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,595] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,595] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,596] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,596] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,596] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,597] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,597] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,598] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,599] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,599] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,600] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,600] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,602] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,602] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,603] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,603] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,603] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,604] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,604] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,605] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,605] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,606] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,606] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,607] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,607] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,607] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,608] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,608] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,609] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,612] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,614] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,615] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,615] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,616] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,617] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,617] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,618] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,618] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,622] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,622] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,623] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,623] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,624] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,624] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,625] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,625] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,626] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,626] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,627] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,627] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,628] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,628] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,629] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,629] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,630] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,630] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,631] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,632] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,633] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,633] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,634] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,636] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,636] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,637] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,637] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,638] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,638] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,639] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,639] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,641] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,641] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,642] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,642] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,643] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,643] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,644] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,644] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,645] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,646] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,646] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,649] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,650] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,652] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,655] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,655] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,657] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,657] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,658] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,659] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,659] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,660] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,660] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,661] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,661] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,662] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,663] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,666] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,667] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,669] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,669] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,670] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,673] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,674] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,675] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,675] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,675] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,676] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,676] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,677] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,677] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,678] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,678] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,679] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,679] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,680] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,680] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,681] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,682] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,682] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,683] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,683] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,685] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,685] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,687] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,687] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,688] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,688] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,691] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,691] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,692] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,692] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,693] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,693] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,694] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,694] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,695] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,696] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,696] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,698] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,698] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,699] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,700] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,700] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,701] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,701] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,702] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,703] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,704] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,705] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,705] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,706] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,706] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,708] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,708] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,708] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,709] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,709] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,709] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,710] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,710] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,710] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,711] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,711] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,712] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,713] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,714] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,715] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,716] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,717] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,720] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,721] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,722] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,722] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,723] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,723] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,725] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,725] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,726] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,727] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,727] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,727] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,729] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,729] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,730] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,730] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,731] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,731] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,732] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,732] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,733] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,733] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,733] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,734] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,734] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,735] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,735] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,735] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,736] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,736] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,736] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,737] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,737] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,738] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,738] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,738] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,739] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,739] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,739] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,740] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,740] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,740] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,741] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,741] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,742] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,742] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,742] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,743] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,744] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,746] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,746] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,747] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,748] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,748] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,749] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,749] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,749] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,752] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,752] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,753] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,754] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,754] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,755] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,755] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,755] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,756] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,756] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,757] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,757] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,757] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,758] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,759] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,759] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,759] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,760] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,760] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,760] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,761] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,761] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,762] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,762] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,762] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,763] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,763] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,764] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,765] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,765] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,766] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,766] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,767] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,767] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,767] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,768] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,768] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,769] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,769] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,769] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,770] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,770] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,771] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,771] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,771] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,772] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,772] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,772] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,773] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,773] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,774] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,774] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,775] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,775] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,775] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,776] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,776] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,777] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,777] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,777] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,778] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,778] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,778] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,779] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,779] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,779] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,780] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,780] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,781] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,781] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,782] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,782] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,784] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,784] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,784] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,785] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,785] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,786] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,786] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,787] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,787] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,787] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,789] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,789] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,789] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,791] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,791] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,792] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,792] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,792] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,793] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,793] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,793] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,794] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,794] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,795] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,795] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,796] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,796] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,797] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,798] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,798] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,799] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,799] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,800] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,800] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,801] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,801] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,802] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,802] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,803] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,803] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,804] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,804] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,805] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,805] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,806] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,806] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,806] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,807] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,807] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,808] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,808] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,808] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,809] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,809] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,810] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,810] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,810] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,811] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,811] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,812] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,812] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,812] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,813] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,813] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,814] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,814] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,815] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,816] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,816] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,816] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,817] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,817] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,818] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,818] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,819] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,819] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,820] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,820] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,821] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,821] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,821] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,822] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,822] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,823] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,823] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,824] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,824] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,826] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,826] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,827] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,828] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,829] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,829] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,830] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,831] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,832] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,833] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,834] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,834] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,835] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,836] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,837] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,838] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,838] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,839] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,839] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,840] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,842] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,843] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,843] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,843] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,844] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,845] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,845] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,846] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,846] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,847] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,848] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,849] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,850] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,851] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,852] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,852] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,853] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,862] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,868] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,869] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,869] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,870] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,871] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,871] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,872] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,872] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,873] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,874] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,875] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,876] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,876] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,877] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,877] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,878] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,878] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,879] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,879] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,880] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,880] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,881] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,882] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,882] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,883] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,883] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,884] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,884] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,885] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,886] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,889] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,890] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,891] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,891] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,892] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:03,892] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,893] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,893] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,894] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:03,894] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:03,895] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:03,895] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:03,896] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:03,896] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:03,897] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,898] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:03,898] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:03,899] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,899] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:03,900] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:03,900] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,901] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,901] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,902] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,902] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,903] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,903] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,904] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,904] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,905] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,905] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,906] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,906] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,907] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,908] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,908] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,909] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,909] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,910] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,910] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,911] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,911] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,911] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,912] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,912] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,913] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,913] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,915] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,915] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,917] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,918] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,918] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,919] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,921] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,922] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,922] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,923] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,924] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,924] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,925] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,925] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,927] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,927] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,928] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,929] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,930] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,931] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,931] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,932] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,933] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,935] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,936] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,936] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,937] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,937] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,938] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,938] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,939] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,939] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,940] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,940] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,941] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,941] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,942] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,942] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,943] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,944] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,945] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,945] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,946] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,949] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,949] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,950] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,950] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,950] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,951] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,951] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,952] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,953] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,953] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,954] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,954] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,954] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,955] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,955] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,956] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,956] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,957] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,957] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,957] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,958] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,958] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:03,959] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:03,959] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:03,960] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:03,960] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:03,961] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:03,961] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:03,962] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:03,962] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:03,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:03,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,964] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,967] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,968] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,968] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,969] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,969] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,970] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,970] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,970] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,971] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,971] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,972] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,973] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,973] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:03,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,974] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:03,975] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:03,975] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:03,976] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:03,976] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:03,977] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:03,977] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:03,977] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:03,978] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:03,978] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,979] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,979] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,979] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,980] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:03,981] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:03,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:03,982] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:03,982] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:03,983] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:03,983] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:03,984] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:03,984] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:03,985] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:03,985] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:03,985] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:03,986] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:03,986] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:03,986] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:03,987] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:03,987] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:03,988] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:03,988] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:03,988] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:03,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:03,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:03,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,990] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:03,990] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:03,990] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:03,991] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:03,991] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:03,992] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:03,992] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:03,992] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:03,993] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:03,993] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:03,994] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:03,994] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:03,994] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:03,995] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:03,995] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:03,995] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:03,996] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:03,996] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:03,996] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:03,997] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:03,998] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:03,999] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:03,999] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,000] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,000] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,000] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,001] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,001] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,002] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,002] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,003] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,003] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,004] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,004] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,005] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,005] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,006] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,006] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,007] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,007] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,008] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,008] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,009] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,009] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,009] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,010] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,012] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,012] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,014] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,015] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,015] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,016] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,017] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,019] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,020] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,020] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,020] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,021] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,021] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,022] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,023] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,023] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,025] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,026] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,027] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,028] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,029] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,029] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,030] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,031] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,032] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,035] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,035] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,036] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,036] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,037] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,038] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,038] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,039] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,040] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,040] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,041] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,041] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,043] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,044] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,044] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,045] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:04,045] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,046] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,047] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,048] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:04,049] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:04,050] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:04,051] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:04,051] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:04,052] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:04,053] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,053] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:04,054] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:04,054] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,055] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:04,056] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:04,056] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,057] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,057] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,058] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,058] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,059] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,060] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,060] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,061] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,061] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,062] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,062] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,063] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,064] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,064] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,065] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,068] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,068] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,068] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,069] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,070] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,070] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,071] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,072] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,072] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,073] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,074] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,077] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,078] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,080] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,080] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,082] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,083] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,083] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,084] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,085] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,086] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,088] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,089] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,090] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,091] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,091] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,092] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,093] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,093] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,094] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,094] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,097] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,098] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,098] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,100] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,100] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,101] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,102] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,102] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,103] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,103] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,105] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,105] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,106] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,106] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,107] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,107] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,108] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,108] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,110] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,111] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,111] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,112] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,112] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,113] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:04,114] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:04,115] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:04,115] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:04,116] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,117] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,117] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:04,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:04,119] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:04,119] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:04,120] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:04,120] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:04,121] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,121] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:04,122] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:04,122] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,123] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:04,124] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:04,124] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,125] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,125] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,126] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,126] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,129] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,129] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,130] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,131] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,132] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,132] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,133] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,134] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,136] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,136] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,137] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,138] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,138] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,139] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,140] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,140] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,141] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,141] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,142] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,146] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,146] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,147] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,148] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,149] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,149] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,151] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,151] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,152] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,153] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,153] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,154] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,154] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,155] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,156] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,156] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,157] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,157] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,158] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,158] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,159] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,159] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,160] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,161] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,161] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,163] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,164] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,165] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,166] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,167] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,168] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,169] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,170] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,171] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,174] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,175] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,177] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,177] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,178] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,179] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,179] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,180] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,183] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,184] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,185] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,185] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,187] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,187] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:04,188] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,188] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,189] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,189] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,190] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,190] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,191] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,191] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,192] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,192] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,193] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,193] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,193] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,194] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,194] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,195] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,195] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,196] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,196] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,197] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,197] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,198] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,199] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,199] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,200] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,200] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,202] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,203] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,203] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,204] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,204] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,205] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,205] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,205] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,206] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,207] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,207] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,210] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,211] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,212] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,212] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,213] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,213] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,214] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,214] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,215] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,216] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,216] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,216] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,217] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,217] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,219] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,219] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,219] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,220] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,221] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,221] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,222] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,222] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,222] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,224] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,224] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,225] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,225] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,226] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,226] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,229] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,229] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,230] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,230] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,231] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,231] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:04,232] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:04,232] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:04,233] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:04,233] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,234] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,235] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:04,235] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:04,235] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:04,236] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:04,236] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:04,236] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:04,237] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,237] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:04,238] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:04,238] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,238] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:04,239] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:04,239] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,240] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,240] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,241] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,241] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,241] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,242] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,242] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,242] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,243] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,243] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,244] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,244] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,245] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,245] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,246] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,246] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,246] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,247] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,248] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,248] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,249] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,249] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,250] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,250] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,250] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,251] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,251] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,251] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,253] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,253] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,254] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,254] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,255] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,255] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,256] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,257] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,257] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,258] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,258] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,259] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,260] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,260] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,261] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,261] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,262] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,262] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,263] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,265] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,265] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,266] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,266] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,267] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,267] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,268] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,268] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,269] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,269] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,270] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,270] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,270] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,271] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,271] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,273] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,273] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,273] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,275] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,275] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,275] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,276] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,276] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,277] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,277] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,277] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,278] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,279] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,279] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,279] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,280] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,281] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,282] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:04,282] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,283] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,283] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,284] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,285] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,285] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,285] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,286] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,286] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,287] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,288] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,288] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,288] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,289] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,289] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,289] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,290] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,290] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,290] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,290] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,291] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,291] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,292] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,292] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,292] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,293] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,293] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,295] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,295] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,295] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,297] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,297] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,298] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,298] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,299] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,299] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,300] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,300] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,300] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,302] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,302] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,303] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,303] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,303] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,304] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,304] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,304] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,305] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,307] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,307] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,308] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,308] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,309] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,310] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,310] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,310] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,312] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,313] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,313] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,314] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,314] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,315] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,318] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,318] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,319] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,319] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:04,319] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:04,320] {spark_submit.py:495} INFO - 23/03/03 10:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:04,320] {spark_submit.py:495} INFO - 23/03/03 10:50:03 ERROR Inbox: Ignoring error
[2023-03-03 10:50:04,321] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,321] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,322] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,322] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,322] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,323] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,323] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,323] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,324] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,324] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,325] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,325] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,327] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,327] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,328] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,328] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,329] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,329] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,329] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,330] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,330] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,331] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,332] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,334] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,334] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,335] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,335] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,337] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,340] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,340] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,342] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,343] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,343] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,344] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,344] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,345] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,345] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,346] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,346] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,348] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,349] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,349] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,351] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,352] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,352] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,353] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,354] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,354] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,355] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,355] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,356] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,358] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,358] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,359] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,360] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,361] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,361] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,362] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,363] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,363] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,364] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,366] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,366] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,367] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,367] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,368] {spark_submit.py:495} INFO - 23/03/03 10:50:03 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:04,369] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,369] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,370] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,371] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:04,371] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:04,372] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:04,372] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:04,373] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:04,373] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:04,374] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,374] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:04,374] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:04,375] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,376] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:04,376] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:04,377] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,377] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,378] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,379] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,379] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,381] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,381] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,382] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,383] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,383] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,384] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,384] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,385] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,388] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,388] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,389] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,390] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,390] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,391] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,391] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,392] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,392] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,393] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,394] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,394] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,395] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,395] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,396] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,396] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,397] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,400] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,401] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,401] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,402] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,402] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,403] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,404] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,405] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,407] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,408] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,408] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,409] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,409] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,410] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,411] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,412] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,413] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,416] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,419] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,420] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,421] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,423] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,424] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,424] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,425] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,425] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,426] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,426] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,427] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,428] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,429] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,431] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,432] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,432] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,433] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,433] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,434] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,434] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,435] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,436] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,438] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,439] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,439] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,440] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,442] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,443] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:04,443] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:04,444] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:04,444] {spark_submit.py:495} INFO - 23/03/03 10:50:04 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:04,445] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,446] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,446] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,447] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:04,448] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:04,449] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:04,449] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:04,450] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:04,451] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:04,451] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,452] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:04,452] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:04,453] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,454] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:04,454] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:04,455] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,455] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,456] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,456] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,457] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,459] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,459] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,460] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,461] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,461] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,462] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,463] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,465] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,467] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,468] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,468] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,468] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,469] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,469] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,470] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,470] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,471] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,471] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,473] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,473] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,474] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,475] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,475] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,476] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,476] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,477] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,477] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,478] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,478] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,479] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,479] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,480] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,481] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,482] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,482] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,483] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,484] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,484] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,485] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,486] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,486] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,487] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,487] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,488] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,491] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,491] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,494] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,498] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,498] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,499] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,499] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,500] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,501] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,502] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,502] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,504] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,504] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,505] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,505] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,506] {spark_submit.py:495} INFO - 23/03/03 10:50:04 ERROR Inbox: Ignoring error
[2023-03-03 10:50:04,507] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,507] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,509] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,509] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,510] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,511] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,511] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,512] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,512] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,513] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,515] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,516] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,517] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,518] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,519] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,520] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,520] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,521] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,522] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,522] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,523] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,523] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,524] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,524] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,526] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,527] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,527] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,528] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,528] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,529] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,530] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,531] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,532] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,533] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,534] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,534] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,535] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,536] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,537] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,537] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,538] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,539] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,539] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,540] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,540] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,541] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,541] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,542] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,542] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,543] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,543] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,544] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,545] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,545] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,546] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,548] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,550] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,550] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,552] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,552] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,554] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,555] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,555] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,557] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,558] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,558] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,559] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,560] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,560] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,560] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,561] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,562] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,562] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,563] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,564] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,567] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,568] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,568] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,569] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,570] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:04,570] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:04,571] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:04,572] {spark_submit.py:495} INFO - 23/03/03 10:50:04 ERROR Inbox: Ignoring error
[2023-03-03 10:50:04,573] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,574] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,576] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,577] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,577] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,578] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,578] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,579] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,580] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,580] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,581] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,582] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,584] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,584] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,585] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,585] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,586] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,586] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,587] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,588] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,588] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,589] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,589] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,590] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,590] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,591] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,592] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,592] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,594] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,595] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,595] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,596] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,598] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,599] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,602] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,602] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,603] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,604] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,605] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,605] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,606] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,606] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,607] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,607] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,608] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,608] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,610] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,611] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,613] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,614] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,615] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,616] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,616] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,617] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,617] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,618] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,618] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,618] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,622] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,622] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,623] {spark_submit.py:495} INFO - 23/03/03 10:50:04 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:04,623] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,624] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,624] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,625] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:04,625] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:04,626] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:04,626] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:04,627] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:04,628] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:04,628] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,629] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:04,629] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:04,630] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,631] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:04,631] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:04,632] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,633] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,634] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,634] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,635] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,636] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,636] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,637] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,637] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,638] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,638] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,639] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,639] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,641] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,641] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,642] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,643] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,644] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,644] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,646] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,646] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,648] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,654] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,655] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,657] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,657] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,658] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,661] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,661] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,664] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,665] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,665] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,666] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,666] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,667] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,667] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,668] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,669] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,673] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,673] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,675] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,675] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,676] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,677] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,677] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,678] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,679] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,679] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,680] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,680] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,681] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,682] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,683] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,683] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,684] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,685] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,685] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,686] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,687] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,687] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,687] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,688] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,689] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:04,689] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:04,689] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:04,690] {spark_submit.py:495} INFO - 23/03/03 10:50:04 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:04,690] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,691] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,691] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:04,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:04,693] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:04,693] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:04,694] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:04,694] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:04,695] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,695] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:04,696] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:04,696] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,697] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:04,697] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:04,698] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,699] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,699] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,700] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,700] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,701] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,701] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,702] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,702] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,703] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,703] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,704] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,704] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,705] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,705] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,706] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,706] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,706] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,707] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,707] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,708] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,708] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,709] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,709] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,710] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,710] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,711] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,711] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,712] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,717] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,717] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,719] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,722] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,723] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,723] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,725] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,726] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,727] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,727] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,728] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,728] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,729] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,730] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,731] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,732] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,734] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,735] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,736] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,737] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,737] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,738] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,739] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,741] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,741] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,742] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,742] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,743] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,744] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,746] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,746] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,747] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,747] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,748] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,749] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,749] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,750] {spark_submit.py:495} INFO - 23/03/03 10:50:04 ERROR Inbox: Ignoring error
[2023-03-03 10:50:04,750] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:04,751] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:04,752] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:04,752] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:04,752] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:04,753] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:04,753] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:04,754] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:04,754] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:04,755] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:04,755] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:04,756] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:04,756] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,757] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,757] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,759] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:04,760] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:04,760] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:04,760] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:04,761] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:04,761] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:04,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:04,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:04,763] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:04,763] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:04,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,765] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,767] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,768] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,768] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,769] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,769] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,770] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,770] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,771] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,772] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,772] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,773] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,774] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,774] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,775] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,776] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:04,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,778] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:04,779] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:04,780] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:04,780] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:04,781] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:04,782] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:04,782] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:04,783] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:04,783] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:04,784] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,786] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,786] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:04,787] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:04,787] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:04,788] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:04,789] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:04,789] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:04,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:04,791] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:04,791] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:04,792] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:04,792] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:04,793] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:04,793] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:04,793] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:04,794] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:04,794] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:04,795] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:04,795] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:04,795] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:04,796] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:04,796] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:04,797] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:04,798] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:04,799] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:04,799] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:04,800] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:04,801] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:04,801] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:04,944] {spark_submit.py:495} INFO - 23/03/03 10:50:04 INFO InMemoryFileIndex: It took 290 ms to list leaf files for 1 paths.
[2023-03-03 10:50:05,165] {spark_submit.py:495} INFO - 23/03/03 10:50:05 INFO InMemoryFileIndex: It took 16 ms to list leaf files for 1 paths.
[2023-03-03 10:50:15,118] {spark_submit.py:495} INFO - 23/03/03 10:50:14 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:15,481] {spark_submit.py:495} INFO - 23/03/03 10:50:15 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:17,383] {spark_submit.py:495} INFO - 23/03/03 10:50:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:22,000] {spark_submit.py:495} INFO - 23/03/03 10:50:21 ERROR Inbox: Ignoring error
[2023-03-03 10:50:22,006] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:22,007] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:22,008] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:22,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:22,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:22,010] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:22,011] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:22,011] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:22,012] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:22,012] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:22,013] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:22,013] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:22,014] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:22,014] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:22,015] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:22,015] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:22,016] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:22,016] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:22,017] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:22,017] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:22,018] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:22,018] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:22,019] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:22,019] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:22,020] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:22,020] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:22,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:22,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,022] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:22,023] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:22,023] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,023] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,025] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:22,025] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:22,026] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:22,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:22,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,028] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:22,028] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:22,029] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,029] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,031] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:22,032] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:22,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:22,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:22,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,034] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:22,035] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:22,035] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:22,036] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:22,036] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:22,037] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:22,037] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:22,038] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:22,039] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:22,039] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,041] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,041] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:22,042] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:22,043] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:22,043] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:22,044] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:22,044] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:22,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,046] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:22,047] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:22,047] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,048] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,048] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,049] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,049] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:22,050] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:22,050] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:22,051] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:22,051] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:22,052] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:22,052] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:22,053] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:22,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:22,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:22,055] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:22,055] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:22,056] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:22,056] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:22,057] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:22,069] {spark_submit.py:495} INFO - 23/03/03 10:50:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:22,070] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:22,070] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:22,071] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:22,071] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:22,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:22,073] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:22,073] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:22,074] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:22,074] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:22,075] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:22,076] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:22,077] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:22,078] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:22,079] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:22,080] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:22,080] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:22,081] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:22,082] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:22,082] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:22,083] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:22,083] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:22,084] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:22,085] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:22,085] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:22,086] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:22,086] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:22,087] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:22,087] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:22,088] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:22,088] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:22,088] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:22,089] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:22,089] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:22,090] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:22,090] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:22,091] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:22,092] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:22,092] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:22,093] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:22,093] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:22,094] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:22,094] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:22,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:22,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,096] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:22,097] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:22,097] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,100] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,100] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:22,101] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:22,101] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:22,102] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:22,102] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,103] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:22,103] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:22,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,106] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:22,106] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:22,107] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:22,107] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:50:22,108] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,108] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:50:22,108] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:50:22,109] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:22,109] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:50:22,110] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:50:22,110] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:50:22,111] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:50:22,112] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:50:22,113] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:50:22,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,116] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:50:22,116] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:50:22,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:50:22,117] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:50:22,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:50:22,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:50:22,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:22,119] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:22,120] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:22,120] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:22,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:50:22,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:50:22,122] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:50:22,122] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:50:22,123] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:50:22,123] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:50:22,124] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:50:22,124] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:50:22,125] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:50:22,125] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:50:22,126] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:50:22,126] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:50:22,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:22,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:22,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:22,129] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:22,129] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:22,130] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:22,350] {spark_submit.py:495} INFO - 23/03/03 10:50:22 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:50:22,420] {spark_submit.py:495} INFO - 23/03/03 10:50:22 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:50:22,434] {spark_submit.py:495} INFO - 23/03/03 10:50:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:50:22,908] {spark_submit.py:495} INFO - 23/03/03 10:50:22 ERROR Inbox: Ignoring error
[2023-03-03 10:50:23,000] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:23,000] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:23,001] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:23,001] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:23,002] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:23,002] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:23,003] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:23,003] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:23,004] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:23,004] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:23,005] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:23,005] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:23,005] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:23,006] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:23,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:23,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:23,008] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:23,008] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:23,009] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:23,009] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:23,010] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:23,010] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:23,011] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:23,011] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:23,012] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:23,013] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:23,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:23,014] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:23,014] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:23,015] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:23,016] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:23,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:50:23,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:50:23,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:50:23,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:50:23,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:50:23,019] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:50:23,020] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:50:23,020] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:50:23,021] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:50:23,021] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:50:23,022] {spark_submit.py:495} INFO - 23/03/03 10:50:22 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:50:23,022] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:23,023] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:23,023] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:23,024] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:50:23,024] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:50:23,025] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:50:23,025] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:50:23,026] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:50:23,027] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:50:23,027] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:50:23,028] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:50:23,029] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:50:23,029] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:23,030] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:50:23,031] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:50:23,032] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:50:23,032] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:50:23,033] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:50:23,034] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:50:23,035] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:50:23,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:50:23,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:50:23,037] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:50:23,037] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:50:23,038] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:50:23,038] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:50:23,039] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:50:23,039] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:50:23,040] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:50:23,040] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:50:23,041] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:50:23,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:50:23,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:50:23,043] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:50:23,044] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:50:23,044] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:50:23,045] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:50:23,046] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:50:23,046] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:50:23,047] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:50:23,048] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:50:23,049] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:50:23,050] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:50:23,050] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:50:23,051] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:50:23,052] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:50:23,052] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:50:23,053] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:50:23,054] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:50:23,054] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:50:23,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:50:23,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:50:23,056] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:50:23,056] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:50:23,057] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:50:23,058] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:50:23,059] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:52:21,191] {base_job.py:229} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 219, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2877, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2950, in _merge
    merged = self.get(mapper.class_, key[1], identity_token=key[2])
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2702, in get
    identity_token=identity_token,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2800, in _get_impl
    load_options=load_options,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 535, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-03-03 10:54:32,391] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:32,398] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:32,400] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:32,459] {spark_submit.py:495} INFO - 23/03/03 10:54:32 ERROR Inbox: Ignoring error
[2023-03-03 10:54:32,462] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:32,466] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:32,471] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:32,477] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:32,479] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:32,482] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:32,483] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:32,484] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:32,485] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:32,485] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:32,486] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:32,487] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:32,488] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:32,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:32,497] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:32,498] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:32,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:32,516] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:32,522] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:32,528] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:32,533] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:32,545] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:32,557] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:32,560] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:32,563] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:32,567] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:32,572] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:32,581] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:32,594] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:32,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:32,624] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:32,625] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:32,686] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:32,748] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:33,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:33,725] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:33,764] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:33,796] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:33,800] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:33,803] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:33,815] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:33,832] {spark_submit.py:495} INFO - 23/03/03 10:54:32 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:33,833] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:33,843] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:33,861] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:33,884] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:33,894] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:33,895] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:33,897] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:33,901] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:33,908] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:33,911] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:33,913] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:33,917] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:33,918] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:33,923] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:33,944] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:33,950] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:33,960] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:33,974] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:33,976] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:33,988] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:33,995] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:33,997] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:33,998] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:33,999] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:34,000] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:34,013] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:34,030] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:34,031] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:34,033] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:34,040] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:34,041] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:34,056] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:34,058] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:34,061] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:34,062] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:34,064] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:34,073] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:34,075] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:34,088] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:34,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:34,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:34,105] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:34,107] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:34,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,110] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:34,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:34,116] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:34,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:34,119] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:34,120] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:34,121] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:34,122] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:34,123] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:34,124] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:34,125] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:34,126] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:34,127] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:34,128] {spark_submit.py:495} INFO - 23/03/03 10:54:32 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:34,137] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:34,157] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:34,162] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:34,162] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:34,163] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:34,164] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:34,165] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:34,165] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:34,166] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:34,166] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:34,167] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:34,168] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:34,168] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:34,170] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:34,176] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:34,181] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:34,181] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:34,185] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:34,196] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:34,197] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:34,198] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:34,203] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:34,205] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:34,207] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:34,213] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:34,235] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:34,245] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:34,247] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:34,250] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:34,263] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:34,264] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:34,265] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:34,266] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:34,267] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:34,269] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:34,293] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:34,295] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:34,296] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:34,297] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:34,298] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:34,299] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:34,299] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:34,300] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:34,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,310] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,310] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,313] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,314] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,314] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,316] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:34,325] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,326] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,327] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,329] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,330] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,445] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,449] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:34,453] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,454] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:34,470] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:34,471] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:34,471] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:34,472] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:34,473] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:34,479] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:34,480] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:34,481] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:34,481] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,482] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,484] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:34,501] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:34,504] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:34,505] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:34,505] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:34,506] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:34,507] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,507] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,517] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,518] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,520] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,521] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,534] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,538] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,539] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:34,540] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:34,541] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:34,542] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:34,543] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:34,544] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:34,545] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:34,546] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:34,547] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:34,556] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:34,558] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:34,558] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:34,559] {spark_submit.py:495} INFO - 23/03/03 10:54:32 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from 7f5e973bdd66:35723 in 120 seconds
[2023-03-03 10:54:34,560] {spark_submit.py:495} INFO - 23/03/03 10:54:32 ERROR Inbox: Ignoring error
[2023-03-03 10:54:34,562] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:34,563] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:34,564] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:34,565] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:34,571] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:34,574] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:34,575] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:34,576] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:34,577] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:34,577] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:34,578] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:34,579] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:34,592] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:34,593] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:34,593] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:34,599] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:34,603] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:34,604] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:34,605] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:34,606] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:34,607] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:34,608] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:34,609] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:34,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:34,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:34,611] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:34,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:34,613] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,614] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,615] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,616] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,627] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,635] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,639] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,640] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,641] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:34,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,647] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,669] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,670] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,671] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:34,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,693] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:34,695] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:34,695] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:34,696] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:34,697] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:34,698] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:34,699] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:34,701] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:34,702] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:34,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,708] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:34,708] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:34,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:34,709] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:34,710] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:34,711] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:34,711] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,712] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,716] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,717] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,721] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:34,721] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:34,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:34,742] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:34,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:34,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:34,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:34,748] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:34,749] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:34,752] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:34,755] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:34,766] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:34,767] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:34,769] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:34,771] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:34,772] {spark_submit.py:495} INFO - 23/03/03 10:54:32 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:34,773] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:34,774] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:34,774] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:34,775] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:34,781] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:34,786] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:34,792] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:34,794] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:34,796] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:34,797] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:34,798] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:34,803] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:34,804] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:34,805] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:34,806] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:34,806] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:34,807] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:34,813] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:34,816] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:34,820] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:34,821] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:34,821] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:34,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:34,824] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:34,824] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:34,826] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:34,826] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:34,828] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:34,829] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:34,838] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:34,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:34,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:34,842] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:34,843] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:34,844] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:34,846] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:34,854] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:34,857] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:34,857] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:34,866] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:34,867] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:34,868] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:34,869] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:34,870] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,870] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,871] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,889] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,895] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,896] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,898] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,899] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,900] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,900] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,901] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:34,902] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,903] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,903] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,904] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,910] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,911] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:34,913] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,914] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:34,914] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:34,917] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:34,919] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:34,920] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:34,920] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:34,921] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:34,922] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:34,923] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:34,924] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,924] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,925] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,927] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:34,928] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:34,929] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:34,930] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:34,931] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:34,940] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:34,942] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:34,942] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:34,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:34,948] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:34,949] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:34,950] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:34,954] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:34,958] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:34,962] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:34,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:34,966] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:34,969] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:34,971] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:34,975] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:34,980] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:34,983] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:34,984] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:34,985] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:34,987] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:34,988] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:34,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:34,991] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:34,992] {spark_submit.py:495} INFO - 23/03/03 10:54:32 ERROR Inbox: Ignoring error
[2023-03-03 10:54:34,994] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:35,007] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:35,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:35,011] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:35,024] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:35,026] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:35,028] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:35,034] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:35,035] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:35,036] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:35,039] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:35,039] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:35,041] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:35,042] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:35,044] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:35,045] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:35,046] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:35,047] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:35,048] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:35,048] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:35,049] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:35,050] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:35,051] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:35,058] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:35,062] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:35,063] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:35,063] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:35,064] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,065] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:35,066] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:35,068] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,069] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,079] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:35,080] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:35,081] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:35,081] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:35,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,086] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:35,089] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:35,092] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,098] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:35,098] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:35,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:35,106] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:35,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,112] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:35,114] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:35,116] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:35,117] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:35,118] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:35,118] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:35,126] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:35,128] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:35,129] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:35,129] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,130] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,131] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,134] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:35,142] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:35,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:35,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:35,161] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:35,165] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:35,166] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,167] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:35,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:35,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,184] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,193] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:35,198] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:35,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:35,211] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:35,214] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:35,216] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:35,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:35,224] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:35,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:35,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:35,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:35,231] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:35,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:35,234] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:35,236] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:35,237] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:35,238] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:35,243] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:35,244] {spark_submit.py:495} INFO - 23/03/03 10:54:32 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:35,252] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:35,258] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:35,261] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:35,267] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:35,269] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:35,273] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:35,278] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:35,289] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:35,296] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:35,316] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:35,321] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:35,326] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:35,332] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:35,338] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:35,340] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:35,341] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:35,403] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:35,405] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:35,411] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:35,417] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:35,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:35,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:35,449] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:35,450] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:35,456] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:35,461] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:35,467] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:35,470] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:35,471] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:35,473] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:35,476] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:35,485] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:35,486] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:35,487] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:35,488] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:35,491] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:35,500] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:35,511] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:35,520] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:35,527] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:35,532] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:35,547] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:35,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:35,562] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,563] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:35,567] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:35,578] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,581] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,584] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,585] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,586] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:35,588] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:35,589] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:35,592] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:35,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,594] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:35,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:35,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,609] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,633] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,637] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:35,659] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:35,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:35,682] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:35,683] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,685] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:35,687] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:35,691] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:35,703] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:35,720] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:35,727] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:35,729] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:35,731] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:35,731] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:35,734] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,745] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:35,750] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:35,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:35,752] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:35,755] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:35,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:35,761] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,763] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:35,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:35,774] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,776] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:35,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:35,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:35,778] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:35,779] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:35,779] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:35,780] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:35,782] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:35,795] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:35,800] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:35,811] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:35,813] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:35,815] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:35,817] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:35,822] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:35,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:35,833] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:35,837] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:35,843] {spark_submit.py:495} INFO - 23/03/03 10:54:32 ERROR Inbox: Ignoring error
[2023-03-03 10:54:35,849] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:35,852] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:35,855] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:35,864] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:35,865] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:35,868] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:35,871] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:35,874] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:35,875] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:35,876] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:35,881] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:35,884] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:35,896] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:35,900] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:35,902] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:35,903] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:35,910] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:35,921] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:35,922] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:35,923] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:35,929] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:35,944] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:35,947] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:35,949] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:35,952] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:35,969] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:35,973] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:35,985] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:35,990] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:35,992] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:35,996] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:35,997] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,002] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,004] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,005] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,005] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,006] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,007] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,007] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,008] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,009] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,010] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,012] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,015] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,023] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,036] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,038] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,039] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,040] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:36,041] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:36,041] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,042] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:36,043] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:36,044] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:36,044] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:36,045] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:36,047] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:36,048] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,049] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,050] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,052] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,053] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:36,054] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:36,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:36,055] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:36,056] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:36,057] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:36,057] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,058] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,059] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,059] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,061] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,062] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,063] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,065] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,068] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:36,070] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:36,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:36,074] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:36,075] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:36,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:36,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,079] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,093] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,094] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,096] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,096] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,097] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:36,098] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:36,099] {spark_submit.py:495} INFO - 23/03/03 10:54:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:36,101] {spark_submit.py:495} INFO - 23/03/03 10:54:32 ERROR Inbox: Ignoring error
[2023-03-03 10:54:36,103] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,104] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,105] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,106] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:36,107] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:36,109] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:36,110] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:36,111] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:36,115] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:36,116] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:36,117] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:36,118] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:36,119] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,120] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,120] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,121] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,122] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,123] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,124] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:36,125] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:36,131] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:36,135] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:36,135] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:36,136] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:36,137] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:36,138] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:36,138] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:36,139] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,140] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,142] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,152] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,158] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,166] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,167] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,171] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,179] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,181] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,183] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,185] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,190] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,193] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,206] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:36,208] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:36,209] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,211] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:36,212] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:36,214] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:36,216] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:36,218] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:36,219] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:36,219] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,220] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,221] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,221] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,223] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:36,224] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:36,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:36,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:36,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:36,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:36,228] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,229] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,237] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,238] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,242] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,243] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,245] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:36,247] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:36,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:36,257] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:36,259] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:36,261] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:36,264] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,266] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,267] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,268] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,269] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,269] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,270] {spark_submit.py:495} INFO - 23/03/03 10:54:32 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:36,271] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,272] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,273] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:36,274] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:36,275] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:36,276] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:36,278] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:36,283] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:36,284] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,285] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:36,286] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:36,287] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,287] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:36,288] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:36,290] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:36,290] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:36,291] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:36,292] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,293] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,294] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,295] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:36,295] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:36,298] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:36,303] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:36,304] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:36,305] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:36,306] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:36,311] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:36,313] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:36,315] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,318] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,319] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,319] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:36,320] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,321] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:36,321] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:36,322] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:36,323] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:36,324] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:36,324] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,325] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,327] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,337] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,338] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,342] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,343] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,343] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,344] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,346] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,346] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,347] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,348] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,349] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,351] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,351] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:36,352] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:36,353] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,354] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:36,354] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:36,355] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:36,356] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:36,356] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:36,357] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:36,364] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,366] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,369] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,371] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:36,371] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:36,372] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:36,373] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:36,375] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:36,375] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:36,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,377] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,377] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,378] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,384] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,390] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,391] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,394] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:36,395] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:36,396] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:36,397] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:36,399] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:36,399] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:36,400] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,401] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,402] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,404] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,404] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,405] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,406] {spark_submit.py:495} INFO - 23/03/03 10:54:34 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:36,407] {spark_submit.py:495} INFO - 23/03/03 10:54:34 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:36,408] {spark_submit.py:495} INFO - 23/03/03 10:54:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:36,411] {spark_submit.py:495} INFO - 23/03/03 10:54:34 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:36,415] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,416] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,417] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,418] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:36,419] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:36,420] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:36,422] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:36,423] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:36,424] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:36,425] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,426] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:36,429] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:36,437] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,442] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:36,443] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:36,444] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:36,446] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:36,457] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:36,458] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,460] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:36,467] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:36,469] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:36,470] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:36,471] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:36,472] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:36,473] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:36,474] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:36,475] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:36,476] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,477] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,478] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,478] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,479] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,480] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,481] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:36,482] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,482] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:36,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:36,484] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:36,484] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:36,485] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:36,486] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,487] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,487] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,491] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,492] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,498] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,500] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,501] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,502] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,503] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,504] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,505] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,505] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,506] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,507] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,508] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,508] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:36,509] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:36,510] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,511] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:36,511] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:36,519] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:36,520] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:36,521] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:36,522] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:36,523] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,523] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,524] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,526] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:36,527] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:36,527] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:36,528] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:36,529] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:36,529] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:36,530] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,531] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,532] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,533] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,533] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,534] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,537] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,539] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,540] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,544] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,545] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:36,546] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:36,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:36,547] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:36,548] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:36,548] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:36,549] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,549] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,550] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,552] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,554] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,555] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,558] {spark_submit.py:495} INFO - 23/03/03 10:54:34 ERROR Inbox: Ignoring error
[2023-03-03 10:54:36,560] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,562] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,564] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,566] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:36,569] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:36,573] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:36,575] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:36,576] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:36,580] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:36,583] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:36,591] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:36,594] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:36,595] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,600] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,606] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,613] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,615] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:36,616] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:36,616] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:36,617] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:36,618] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:36,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:36,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:36,623] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:36,625] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:36,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,637] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,638] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,639] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,646] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,646] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,647] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,650] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,655] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,663] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,664] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,666] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:36,667] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:36,667] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,668] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:36,669] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:36,670] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:36,670] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:36,671] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:36,672] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:36,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,673] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,676] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:36,676] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:36,677] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:36,679] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:36,686] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:36,687] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:36,687] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,688] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,689] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,690] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,691] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,692] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,693] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,694] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,695] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,696] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:36,697] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:36,698] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:36,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:36,700] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:36,700] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:36,701] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,702] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,705] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,706] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,709] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,709] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,710] {spark_submit.py:495} INFO - 23/03/03 10:54:34 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:36,711] {spark_submit.py:495} INFO - 23/03/03 10:54:34 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:36,711] {spark_submit.py:495} INFO - 23/03/03 10:54:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:36,712] {spark_submit.py:495} INFO - 23/03/03 10:54:34 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:36,713] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,714] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,715] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,715] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:36,716] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:36,717] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:36,717] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:36,718] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:36,719] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:36,719] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,720] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:36,721] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:36,721] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,722] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:36,723] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:36,724] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:36,726] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:36,728] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:36,728] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:36,729] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:36,730] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:36,733] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:36,735] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:36,735] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:36,750] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:36,751] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:36,752] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:36,781] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:36,790] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:36,791] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:36,792] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:36,792] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:36,793] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:36,794] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:36,795] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:36,796] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:36,798] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:36,808] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:36,809] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:36,810] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:36,811] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:36,813] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:36,818] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:36,818] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,819] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,820] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,821] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,829] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,830] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,833] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,836] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,847] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,849] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,850] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,851] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,852] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,852] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,853] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,861] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,863] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,870] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,871] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,874] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,876] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:36,879] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,881] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:36,882] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:36,891] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:36,893] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:36,894] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:36,895] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:36,896] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:36,897] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:36,899] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:36,907] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,911] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,915] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:36,920] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:36,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:36,936] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:36,940] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:36,941] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:36,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:36,945] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:36,946] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:36,958] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:36,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:36,968] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:36,976] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:36,982] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:36,983] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:36,984] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:36,992] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:36,995] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:36,996] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:36,997] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:36,999] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:37,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:37,026] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,029] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,031] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,038] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,040] {spark_submit.py:495} INFO - 23/03/03 10:54:34 ERROR Inbox: Ignoring error
[2023-03-03 10:54:37,048] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,054] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,056] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,058] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:37,064] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:37,068] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:37,041] {base_job.py:229} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.19.0.9), port 5432 failed: FATAL:  the database system is shutting down


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 201, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2877, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2950, in _merge
    merged = self.get(mapper.class_, key[1], identity_token=key[2])
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2702, in get
    identity_token=identity_token,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2800, in _get_impl
    load_options=load_options,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 535, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.19.0.9), port 5432 failed: FATAL:  the database system is shutting down

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-03-03 10:54:37,081] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:37,083] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:37,089] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:37,091] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:37,094] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:37,096] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:37,105] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,107] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,113] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,119] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,120] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,121] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:37,121] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:37,122] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:37,123] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:37,125] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:37,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:37,130] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:37,133] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:37,134] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:37,135] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,136] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,140] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,142] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,149] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,154] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,155] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,156] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,158] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,159] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,159] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,161] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,174] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,177] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,180] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,181] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,181] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,183] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,184] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:37,186] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:37,188] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,190] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:37,196] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:37,199] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:37,201] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:37,202] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:37,206] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:37,207] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,210] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:37,212] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:37,214] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:37,216] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:37,218] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:37,221] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:37,221] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,222] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,226] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,235] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,239] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,240] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,242] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:37,243] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:37,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:37,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:37,256] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:37,257] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:37,258] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,261] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,265] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,272] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,277] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,278] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,279] {spark_submit.py:495} INFO - 23/03/03 10:54:35 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:37,280] {spark_submit.py:495} INFO - 23/03/03 10:54:35 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:37,281] {spark_submit.py:495} INFO - 23/03/03 10:54:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:37,281] {spark_submit.py:495} INFO - 23/03/03 10:54:35 ERROR Inbox: Ignoring error
[2023-03-03 10:54:37,282] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,283] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,285] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,287] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:37,296] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:37,302] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:37,304] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:37,306] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:37,306] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:37,307] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:37,308] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:37,308] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:37,312] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,313] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,313] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,314] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,315] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,315] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,316] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:37,316] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:37,317] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:37,318] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:37,319] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:37,319] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:37,320] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:37,321] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:37,321] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:37,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,329] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,330] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,331] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,334] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,344] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,346] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,347] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,347] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,348] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,349] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,356] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,356] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,359] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,360] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,361] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,363] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:37,364] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:37,365] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,365] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:37,366] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:37,367] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:37,367] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:37,368] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:37,369] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:37,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,374] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,375] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,376] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:37,377] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:37,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:37,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:37,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:37,381] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:37,382] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,383] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,387] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,388] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,390] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,391] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,392] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,392] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,393] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,394] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:37,395] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:37,413] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:37,415] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:37,415] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:37,416] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:37,416] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,417] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,418] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,418] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,419] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,420] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,420] {spark_submit.py:495} INFO - 23/03/03 10:54:35 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:37,421] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,422] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,423] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,424] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:37,424] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:37,425] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:37,426] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:37,427] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:37,427] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:37,428] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,429] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:37,429] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:37,436] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,438] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:37,439] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:37,439] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:37,440] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:37,441] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:37,442] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,442] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,443] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,444] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:37,445] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:37,445] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:37,446] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:37,452] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:37,453] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:37,453] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:37,454] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:37,455] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:37,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,456] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,456] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,458] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,459] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:37,460] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,460] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:37,461] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:37,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:37,469] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:37,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:37,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,471] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,473] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,477] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,477] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,478] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,479] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,480] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,481] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,482] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,487] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,500] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,500] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,501] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,501] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,502] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,503] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,504] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:37,505] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:37,505] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,506] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:37,507] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:37,507] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:37,508] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:37,509] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:37,510] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:37,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,512] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,513] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,513] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:37,520] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:37,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:37,522] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:37,522] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:37,523] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:37,524] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,525] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,526] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,527] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,527] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,531] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,532] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,533] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,533] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,534] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:37,535] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:37,536] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:37,537] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:37,539] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:37,540] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:37,541] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,541] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,545] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,546] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,547] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,548] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,548] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:37,549] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:37,550] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:37,551] {spark_submit.py:495} INFO - 23/03/03 10:54:36 ERROR Inbox: Ignoring error
[2023-03-03 10:54:37,552] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,552] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,554] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:37,555] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:37,555] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:37,556] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:37,557] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:37,557] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:37,558] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:37,559] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:37,559] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:37,560] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,561] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,562] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,563] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,567] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,568] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,570] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:37,572] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:37,573] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:37,574] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:37,576] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:37,577] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:37,578] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:37,578] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:37,579] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:37,580] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,580] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,581] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,582] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,583] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,584] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,584] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,589] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,590] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,591] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,595] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,597] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,598] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,599] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,601] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,602] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,602] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,604] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:37,605] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:37,606] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,606] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:37,607] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:37,607] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:37,608] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:37,609] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:37,609] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:37,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,613] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:37,616] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:37,618] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:37,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:37,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:37,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:37,622] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,623] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,624] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,624] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,625] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,627] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,628] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,628] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,629] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,631] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:37,632] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:37,641] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:37,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:37,644] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:37,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:37,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,646] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,647] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,648] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,649] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,649] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,650] {spark_submit.py:495} INFO - 23/03/03 10:54:36 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:37,651] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,654] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,654] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,655] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:37,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:37,657] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:37,662] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:37,664] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:37,665] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:37,665] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,666] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:37,667] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:37,668] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,669] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:37,670] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:37,671] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:37,673] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:37,674] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:37,674] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,675] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,676] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,676] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:37,677] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:37,683] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:37,684] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:37,685] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:37,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:37,687] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:37,688] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:37,689] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:37,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,691] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,693] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,694] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,694] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:37,695] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,698] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:37,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:37,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:37,701] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:37,701] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:37,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,723] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,725] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,726] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,726] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,732] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,742] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,755] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,755] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,756] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,756] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,757] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,759] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,760] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,761] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,762] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:37,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,787] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:37,788] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:37,788] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,789] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:37,790] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:37,791] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:37,791] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:37,792] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:37,793] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:37,796] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,797] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,798] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,799] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,802] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:37,804] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:37,805] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:37,806] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:37,807] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:37,808] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:37,808] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,809] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,810] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,811] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,812] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,813] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,821] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,834] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:37,837] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:37,860] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:37,861] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:37,866] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:37,867] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:37,868] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:37,868] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:37,869] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:37,870] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,871] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,882] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,889] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,890] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,900] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,903] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:37,905] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:37,905] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:37,913] {spark_submit.py:495} INFO - 23/03/03 10:54:36 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:37,915] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,920] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,920] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,923] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:37,925] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:37,926] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:37,927] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:37,928] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:37,929] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:37,929] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:37,930] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:37,931] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:37,931] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,933] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:37,933] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:37,934] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:37,935] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:37,936] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:37,936] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:37,937] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:37,938] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:37,939] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:37,939] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:37,940] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:37,940] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:37,943] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:37,944] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:37,944] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:37,945] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:37,945] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:37,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:37,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:37,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:37,951] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:37,952] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:37,952] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:37,953] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:37,954] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:37,958] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:37,966] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:37,967] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:37,968] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:37,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:37,973] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:37,973] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:37,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:37,975] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:37,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:37,997] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:37,998] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:37,999] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,000] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,000] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,001] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:38,001] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,002] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,003] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,026] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,029] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,030] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,030] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,031] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,031] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,032] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:38,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,034] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:38,034] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:38,035] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:38,036] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:38,036] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:38,037] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:38,037] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:38,058] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:38,065] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:38,066] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,067] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,067] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,068] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,068] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:38,069] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:38,069] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:38,070] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:38,099] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:38,100] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:38,102] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,115] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,129] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,130] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,130] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,131] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,132] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,145] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,147] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,149] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:38,149] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:38,167] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:38,168] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:38,169] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:38,169] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:38,175] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,176] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,176] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,177] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,177] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,177] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:38,178] {spark_submit.py:495} INFO - 23/03/03 10:54:36 ERROR Inbox: Ignoring error
[2023-03-03 10:54:38,181] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:38,191] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:38,206] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:38,207] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:38,207] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:38,208] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:38,208] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:38,209] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:38,209] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:38,214] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:38,215] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:38,216] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:38,217] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,217] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,218] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,220] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:38,231] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:38,232] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:38,233] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:38,234] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:38,235] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:38,236] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:38,236] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:38,247] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:38,248] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:38,249] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,249] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,250] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,250] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,251] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,253] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,263] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:38,265] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,266] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,266] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,267] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,268] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,290] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,295] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,295] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:38,297] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,297] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:38,298] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:38,298] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:38,299] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:38,299] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:38,300] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:38,300] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:38,300] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:38,301] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:38,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,308] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:38,314] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:38,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:38,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:38,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:38,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:38,318] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,318] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,319] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,319] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,320] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,325] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,325] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,326] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,327] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,327] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:38,329] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:38,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:38,339] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:38,340] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:38,341] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:38,342] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,343] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,343] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,344] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,345] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,345] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:38,346] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:38,347] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:38,348] {spark_submit.py:495} INFO - 23/03/03 10:54:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:38,348] {spark_submit.py:495} INFO - 23/03/03 10:54:36 ERROR Inbox: Ignoring error
[2023-03-03 10:54:38,349] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:38,350] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:38,358] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:38,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:38,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:38,360] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:38,363] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:38,364] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:38,364] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:38,365] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:38,365] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:38,366] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:38,366] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,367] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,370] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,391] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,402] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:38,404] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:38,406] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:38,407] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:38,407] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:38,408] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:38,409] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:38,409] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:38,410] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:38,410] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:38,411] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,411] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:38,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:38,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:38,416] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:38,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:38,420] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:38,421] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:38,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:38,431] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:38,431] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:38,432] {spark_submit.py:495} INFO - 23/03/03 10:54:36 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:38,433] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:38,434] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:38,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:38,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:38,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:38,442] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:38,448] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:38,449] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:38,449] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:38,450] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:38,451] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:38,451] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:38,452] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:38,452] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:38,453] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:38,453] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:38,454] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:38,455] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:38,456] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:38,457] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:38,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:38,465] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:38,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:38,467] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:38,468] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:38,468] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:38,469] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:38,470] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:38,470] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:38,472] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:38,474] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,480] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,484] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,485] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,486] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:38,488] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:38,491] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:38,494] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:38,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:38,506] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:38,507] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:38,508] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:38,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,517] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,529] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:38,530] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:38,532] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:38,533] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:38,535] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:38,536] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:38,537] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:38,537] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:38,538] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:38,539] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:38,539] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:38,540] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:38,541] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:38,546] {spark_submit.py:495} INFO - 23/03/03 10:54:37 ERROR Inbox: Ignoring error
[2023-03-03 10:54:38,549] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:38,552] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:38,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:38,558] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:38,561] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:38,564] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:38,565] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:38,566] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:38,567] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:38,568] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:38,575] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:38,578] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:38,580] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,581] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,581] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,582] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,584] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:38,584] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:38,607] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:38,618] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:38,620] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:38,627] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:38,628] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:38,629] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:38,630] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:38,631] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:38,635] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,637] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,653] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,654] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,655] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:38,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,668] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,680] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,688] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,690] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,691] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,692] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,704] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:38,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,708] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:38,715] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:38,719] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:38,737] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:38,743] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:38,756] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:38,764] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:38,767] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:38,776] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:38,776] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,780] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:38,783] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:38,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:38,787] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:38,790] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:38,799] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:38,801] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,806] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,807] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,809] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,824] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,825] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,826] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,826] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,827] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,828] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,829] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:38,829] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:38,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:38,831] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:38,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:38,847] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:38,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,850] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,852] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,853] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,854] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,855] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:38,860] {spark_submit.py:495} INFO - 23/03/03 10:54:37 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:38,861] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:38,862] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:38,863] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:38,864] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:38,864] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:38,865] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:38,866] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:38,866] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:38,867] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:38,867] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:38,869] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:38,871] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:38,872] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:38,873] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:38,880] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:38,883] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:38,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:38,888] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:38,890] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:38,899] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:38,900] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:38,901] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:38,903] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:38,904] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:38,905] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:38,906] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:38,907] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:38,908] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:38,909] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:38,912] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:38,919] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:38,920] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:38,920] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:38,921] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:38,922] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:38,924] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:38,932] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:38,932] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:38,934] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:38,935] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:38,936] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:38,936] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:38,937] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:38,937] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,940] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,941] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,942] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,957] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,958] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,959] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:38,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:38,989] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:38,990] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:38,992] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:38,993] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:38,993] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:38,994] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:38,995] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:38,998] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:38,998] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:38,999] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,000] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:39,000] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,001] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:39,002] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:39,002] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:39,003] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:39,016] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:39,016] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:39,017] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:39,018] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:39,019] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:39,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,020] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,021] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,023] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:39,024] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:39,042] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:39,048] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:39,049] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:39,050] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:39,050] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,051] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,051] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,053] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,054] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,064] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,067] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,073] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:39,083] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:39,101] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:39,115] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:39,116] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:39,116] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:39,117] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,123] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,149] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:39,150] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:39,151] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:39,166] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:39,167] {spark_submit.py:495} INFO - 23/03/03 10:54:37 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:39,167] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,168] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,178] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,179] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:39,182] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:39,183] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:39,184] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:39,185] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:39,185] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:39,186] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:39,200] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:39,201] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:39,248] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:39,259] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:39,270] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:39,270] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:39,271] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:39,272] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:39,275] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,277] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,282] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:39,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:39,289] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:39,289] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:39,290] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:39,291] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:39,291] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:39,292] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:39,293] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:39,295] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,296] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,296] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,297] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,298] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,299] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:39,305] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:39,323] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:39,324] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:39,330] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:39,331] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:39,332] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:39,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:39,334] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,334] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:39,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:39,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:39,346] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:39,347] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:39,348] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:39,349] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:39,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:39,351] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:39,352] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:39,352] {spark_submit.py:495} INFO - 23/03/03 10:54:37 ERROR Inbox: Ignoring error
[2023-03-03 10:54:39,354] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,362] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,364] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,364] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:39,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:39,366] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:39,367] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:39,367] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:39,368] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:39,369] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:39,369] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:39,370] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:39,371] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,372] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,373] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,374] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,385] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,387] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:39,389] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:39,390] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:39,390] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:39,391] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:39,392] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:39,393] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:39,394] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:39,395] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:39,396] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:39,397] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,397] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,399] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,400] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:39,402] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:39,403] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:39,409] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:39,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:39,414] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:39,416] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:39,419] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:39,420] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:39,422] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:39,425] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:39,429] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:39,430] {spark_submit.py:495} INFO - 23/03/03 10:54:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:39,431] {spark_submit.py:495} INFO - 23/03/03 10:54:37 ERROR Inbox: Ignoring error
[2023-03-03 10:54:39,432] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,433] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:39,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:39,437] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:39,438] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:39,460] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:39,461] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:39,462] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:39,462] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:39,463] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:39,474] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,479] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,485] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,489] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,489] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,490] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:39,491] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:39,492] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:39,493] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:39,494] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:39,496] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:39,497] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:39,497] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:39,498] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:39,501] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:39,502] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,503] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,504] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,504] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,505] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,506] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,506] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,507] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,508] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,508] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,509] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:39,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,512] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,513] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,514] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,515] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,515] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,517] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,517] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,524] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:39,526] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,527] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:39,528] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:39,533] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:39,534] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:39,535] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:39,536] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:39,537] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:39,538] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:39,538] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:39,539] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,539] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,540] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,541] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,541] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:39,542] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:39,542] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:39,543] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:39,544] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:39,545] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:39,546] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,547] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,550] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,552] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,554] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,554] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,555] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,555] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:39,556] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:39,557] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:39,558] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:39,563] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:39,565] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:39,566] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,567] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,568] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,569] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,569] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,571] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:39,572] {spark_submit.py:495} INFO - 23/03/03 10:54:37 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:39,572] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,573] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,574] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:39,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:39,576] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:39,576] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:39,577] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:39,578] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:39,579] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:39,580] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:39,588] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:39,589] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:39,590] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:39,590] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:39,591] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:39,593] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:39,594] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:39,594] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,595] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,596] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,597] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:39,598] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:39,599] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:39,600] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:39,600] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:39,601] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:39,602] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:39,603] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:39,604] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:39,613] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,613] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,614] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,615] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,616] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,617] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:39,617] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:39,618] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:39,619] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:39,627] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:39,633] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:39,643] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:39,644] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:39,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,647] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,653] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,660] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:39,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,666] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,669] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,673] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,674] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,680] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,681] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:39,685] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,686] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:39,687] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:39,688] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:39,688] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:39,689] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:39,699] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:39,700] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:39,701] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:39,716] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:39,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,723] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,723] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:39,724] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:39,725] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:39,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:39,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:39,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:39,728] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,732] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,737] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,738] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,738] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,748] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:39,748] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:39,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:39,751] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:39,752] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:39,753] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:39,754] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,754] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,755] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,756] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,757] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,757] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:39,758] {spark_submit.py:495} INFO - 23/03/03 10:54:38 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:39,759] {spark_submit.py:495} INFO - 23/03/03 10:54:38 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:39,759] {spark_submit.py:495} INFO - 23/03/03 10:54:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:39,760] {spark_submit.py:495} INFO - 23/03/03 10:54:38 ERROR Inbox: Ignoring error
[2023-03-03 10:54:39,760] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,761] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:39,763] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:39,765] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:39,774] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:39,775] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:39,775] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:39,776] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:39,780] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:39,793] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:39,794] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,795] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,796] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,796] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,797] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,798] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:39,799] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:39,800] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:39,801] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:39,810] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:39,810] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:39,829] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:39,834] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:39,847] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:39,854] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:39,865] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,868] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,870] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,883] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,887] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,888] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,902] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,904] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,905] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:39,910] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,911] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,915] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,919] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,920] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,920] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,921] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:39,922] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,923] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:39,924] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:39,924] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:39,925] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:39,926] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:39,926] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:39,927] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:39,929] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:39,931] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:39,932] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,938] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,939] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,945] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:39,946] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:39,947] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:39,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:39,954] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:39,955] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:39,956] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:39,957] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:39,957] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:39,958] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:39,959] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:39,959] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:39,960] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:39,961] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:39,962] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:39,971] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:39,972] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:39,973] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:39,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:39,975] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:39,975] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:39,976] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:39,977] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:39,978] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:39,983] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:39,984] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:39,984] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:39,985] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:39,986] {spark_submit.py:495} INFO - 23/03/03 10:54:38 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:39,987] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:39,993] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:39,994] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:39,995] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:40,019] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:40,023] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:40,023] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:40,024] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:40,025] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:40,026] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:40,027] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:40,051] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:40,053] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,057] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:40,058] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:40,059] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:40,060] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:40,061] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:40,062] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:40,064] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:40,075] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:40,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:40,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:40,078] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:40,079] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:40,081] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:40,082] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:40,083] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:40,084] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:40,084] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:40,085] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,096] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,097] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,097] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,098] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,099] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,100] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:40,101] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:40,128] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:40,134] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:40,140] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:40,144] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:40,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:40,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,146] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,147] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,154] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,155] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,155] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,157] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,158] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,168] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:40,174] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,176] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,179] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,181] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,183] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,184] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:40,189] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,190] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:40,191] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:40,196] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:40,197] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:40,199] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:40,199] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:40,211] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:40,212] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:40,215] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:40,216] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,222] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,224] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,232] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:40,234] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:40,236] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:40,243] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:40,245] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:40,246] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:40,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,251] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,253] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,253] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,254] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,255] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,255] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,259] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,260] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:40,268] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:40,269] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:40,270] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:40,271] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:40,277] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:40,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,282] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,285] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,323] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,324] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:40,325] {spark_submit.py:495} INFO - 23/03/03 10:54:38 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:40,325] {spark_submit.py:495} INFO - 23/03/03 10:54:38 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:40,326] {spark_submit.py:495} INFO - 23/03/03 10:54:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:40,327] {spark_submit.py:495} INFO - 23/03/03 10:54:38 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:40,327] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:40,328] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:40,329] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:40,350] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:40,367] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:40,367] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:40,368] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:40,373] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:40,383] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:40,394] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:40,411] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:40,412] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:40,413] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,424] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:40,425] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:40,426] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:40,426] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:40,427] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:40,428] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:40,431] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:40,432] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:40,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:40,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:40,440] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:40,442] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:40,464] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:40,478] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:40,489] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:40,496] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:40,504] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:40,520] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,522] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,525] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,528] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,529] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,530] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,532] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:40,539] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:40,541] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:40,546] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:40,549] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:40,550] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:40,552] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:40,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,557] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,558] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,562] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,563] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,564] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,565] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,566] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,566] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,568] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:40,568] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,569] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,576] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,577] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,579] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,581] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,583] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,584] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,586] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,590] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,591] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:40,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,601] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:40,603] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:40,604] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:40,608] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:40,609] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:40,612] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:40,615] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:40,620] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:40,624] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:40,625] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,627] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,628] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,629] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:40,632] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:40,633] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:40,637] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:40,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:40,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:40,642] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,643] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,644] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,646] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,646] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,648] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,649] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,651] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:40,654] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:40,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:40,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:40,657] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:40,658] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:40,659] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,659] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,660] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,661] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,661] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,662] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:40,666] {spark_submit.py:495} INFO - 23/03/03 10:54:38 ERROR Inbox: Ignoring error
[2023-03-03 10:54:40,668] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:40,671] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:40,672] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:40,673] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:40,674] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:40,675] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:40,676] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:40,676] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:40,677] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:40,678] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:40,679] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:40,679] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:40,680] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,682] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,682] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,683] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,685] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,691] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:40,694] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:40,695] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:40,696] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:40,696] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:40,697] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:40,698] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:40,699] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:40,700] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:40,702] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,705] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,710] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,715] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,716] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:40,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,720] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,723] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,725] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,728] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,736] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,737] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:40,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,741] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:40,746] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:40,747] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:40,747] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:40,748] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:40,749] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:40,750] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:40,752] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:40,753] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:40,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,770] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,771] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,772] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,773] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:40,777] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:40,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:40,779] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:40,780] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:40,781] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:40,781] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,783] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,784] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:40,786] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:40,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:40,791] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:40,792] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:40,792] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:40,793] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:40,794] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:40,794] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:40,795] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:40,805] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:40,821] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:40,822] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,824] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,826] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,826] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:40,828] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:40,829] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:40,831] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:40,832] {spark_submit.py:495} INFO - 23/03/03 10:54:39 ERROR Inbox: Ignoring error
[2023-03-03 10:54:40,833] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:40,833] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:40,834] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:40,835] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:40,837] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:40,843] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:40,844] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:40,844] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:40,848] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:40,861] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:40,864] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:40,866] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:40,870] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,871] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,879] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,880] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,881] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,882] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:40,883] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:40,884] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:40,885] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:40,886] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:40,887] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:40,888] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:40,889] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:40,889] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:40,890] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,891] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,891] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,892] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:40,894] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:40,895] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:40,896] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:40,896] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:40,897] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:40,898] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:40,899] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:40,901] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:40,905] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:40,906] {spark_submit.py:495} INFO - 23/03/03 10:54:39 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:40,908] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:40,909] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:40,910] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:40,912] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:40,912] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:40,913] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:40,914] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:40,915] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:40,915] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:40,916] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:40,919] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:40,920] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:40,925] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,925] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:40,926] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:40,927] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:40,929] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:40,930] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:40,931] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:40,931] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:40,932] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:40,933] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:40,934] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:40,935] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:40,935] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:40,936] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:40,937] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:40,938] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:40,938] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:40,939] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:40,940] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:40,944] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:40,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:40,949] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:40,951] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:40,952] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:40,953] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:40,954] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:40,954] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:40,963] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:40,964] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:40,964] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:40,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:40,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:40,966] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:40,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:40,977] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:40,979] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:40,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:40,983] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:40,985] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:40,986] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:40,987] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:40,988] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:40,988] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:40,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:40,990] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:40,991] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:40,992] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:40,993] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:40,998] {spark_submit.py:495} INFO - 23/03/03 10:54:39 ERROR Inbox: Ignoring error
[2023-03-03 10:54:40,999] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:41,000] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:41,001] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:41,002] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:41,003] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:41,004] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:41,005] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:41,006] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:41,007] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:41,007] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:41,009] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:41,012] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:41,014] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,017] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,019] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,021] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,022] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,023] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:41,024] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:41,025] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:41,026] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:41,031] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:41,047] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:41,048] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:41,049] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:41,051] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:41,054] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:41,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,056] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,058] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,059] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,060] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,061] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,061] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,062] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,063] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,064] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,064] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,065] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,066] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,067] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,069] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,071] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,073] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,075] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,082] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,082] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:41,083] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:41,084] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:41,086] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:41,087] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:41,089] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:41,090] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:41,091] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:41,092] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:41,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,101] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,104] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:41,105] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:41,106] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:41,106] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:41,107] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:41,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:41,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,112] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,119] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,123] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,125] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,128] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:41,129] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:41,130] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:41,130] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:41,131] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:41,132] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:41,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,134] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,136] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,136] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:41,139] {spark_submit.py:495} INFO - 23/03/03 10:54:39 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:41,141] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:41,142] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:41,144] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:41,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:41,148] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:41,149] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:41,149] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:41,150] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:41,150] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:41,151] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:41,152] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:41,153] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:41,154] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:41,154] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:41,155] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:41,156] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:41,156] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:41,157] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:41,158] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:41,159] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:41,160] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:41,163] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:41,164] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:41,164] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:41,165] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:41,166] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:41,167] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:41,167] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:41,168] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:41,169] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:41,169] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,170] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,174] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,175] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:41,175] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:41,176] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:41,177] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:41,177] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:41,178] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:41,179] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:41,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:41,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,181] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,186] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,195] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,196] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,197] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,197] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,198] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,198] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,199] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,200] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,201] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,203] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,203] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,204] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,205] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,206] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,207] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,208] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:41,209] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:41,211] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:41,213] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:41,217] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:41,218] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:41,219] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:41,221] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:41,224] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:41,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,226] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,231] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,232] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:41,233] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:41,235] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:41,236] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:41,236] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:41,237] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:41,238] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,239] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,240] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,242] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,242] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,243] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,245] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,254] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,255] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:41,256] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:41,260] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:41,261] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:41,262] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:41,263] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:41,264] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,265] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,265] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,266] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,267] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,268] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:41,269] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:41,269] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:41,270] {spark_submit.py:495} INFO - 23/03/03 10:54:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:41,271] {spark_submit.py:495} INFO - 23/03/03 10:54:39 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:41,272] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:41,273] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:41,273] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:41,274] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:41,275] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:41,276] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:41,283] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:41,289] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:41,290] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:41,292] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:41,293] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:41,294] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:41,295] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:41,297] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:41,298] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:41,299] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:41,300] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:41,302] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:41,303] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:41,304] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:41,307] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:41,308] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:41,309] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:41,309] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:41,310] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:41,327] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:41,334] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:41,338] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:41,342] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:41,347] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:41,349] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,351] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,352] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,353] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,354] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,355] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:41,356] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:41,356] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:41,357] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:41,357] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:41,358] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:41,358] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:41,359] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:41,371] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,377] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,383] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,404] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,408] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,428] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,430] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,432] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,433] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,435] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,444] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,449] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,450] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,452] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,454] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,456] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,457] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,458] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,473] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,477] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:41,481] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:41,483] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:41,485] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:41,486] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:41,487] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:41,487] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:41,488] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:41,491] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:41,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,499] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:41,502] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:41,505] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:41,511] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:41,514] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:41,515] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:41,518] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,520] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,523] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,524] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,525] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,526] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,527] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,532] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,533] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,534] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,535] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:41,537] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:41,538] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:41,539] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:41,540] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:41,540] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:41,543] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,546] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,547] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,548] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,549] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,559] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:41,561] {spark_submit.py:495} INFO - 23/03/03 10:54:39 ERROR Inbox: Ignoring error
[2023-03-03 10:54:41,563] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:41,564] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:41,565] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:41,566] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:41,568] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:41,569] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:41,582] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:41,584] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:41,588] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:41,589] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:41,589] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:41,591] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:41,605] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,606] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,608] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,609] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,611] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:41,611] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:41,612] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:41,612] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:41,614] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:41,615] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:41,616] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:41,617] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:41,620] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:41,622] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:41,629] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,631] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,632] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,655] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,656] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,669] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,673] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,675] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,679] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,683] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,690] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:41,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,696] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:41,706] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:41,721] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:41,728] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:41,739] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:41,747] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:41,764] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:41,777] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:41,785] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:41,792] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,805] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,835] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,883] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,891] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:41,894] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:41,895] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:41,896] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:41,897] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:41,907] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:41,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:41,926] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:41,926] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:41,927] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:41,928] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:41,929] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:41,930] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:41,942] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:41,942] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:41,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:41,944] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:41,944] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:41,945] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:41,946] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:41,953] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:41,957] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:41,959] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:41,973] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:41,975] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:41,978] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:41,979] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:41,981] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:41,989] {spark_submit.py:495} INFO - 23/03/03 10:54:40 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:41,993] {spark_submit.py:495} INFO - 23/03/03 10:54:40 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:41,997] {spark_submit.py:495} INFO - 23/03/03 10:54:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:42,002] {spark_submit.py:495} INFO - 23/03/03 10:54:40 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:42,007] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,011] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,023] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,028] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:42,035] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:42,038] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:42,039] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:42,040] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:42,041] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:42,042] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,043] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:42,044] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:42,045] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,046] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:42,046] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:42,047] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,048] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,049] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,064] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,067] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,069] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,070] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,072] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,073] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,074] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,074] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,075] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,075] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,076] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,078] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,079] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,080] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,080] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,081] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,082] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,083] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,085] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,100] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,114] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,116] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,122] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,123] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,124] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,125] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,125] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,126] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,127] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,127] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,129] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,129] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,130] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,131] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,132] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,135] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,140] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:42,142] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:42,143] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,144] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:42,145] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:42,146] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:42,147] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:42,148] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:42,148] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:42,149] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,149] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,152] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,152] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:42,153] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:42,154] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:42,154] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:42,155] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:42,159] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:42,163] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,164] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,165] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,166] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,167] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,169] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,170] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,181] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:42,182] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:42,183] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:42,185] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:42,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:42,187] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:42,188] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,188] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,189] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,189] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,190] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,191] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,192] {spark_submit.py:495} INFO - 23/03/03 10:54:40 ERROR Inbox: Ignoring error
[2023-03-03 10:54:42,193] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,193] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,194] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,195] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,196] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,197] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,202] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,206] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,206] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,207] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,208] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,209] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,209] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,210] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,211] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,212] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,212] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,218] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,220] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,222] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,223] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,223] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,224] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,224] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,225] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,225] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,226] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,227] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,228] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,229] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,231] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,232] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,235] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,236] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,238] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,240] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,241] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,242] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,243] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,245] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,246] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,246] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,248] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,249] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,251] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:42,254] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:42,255] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,257] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:42,258] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:42,259] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:42,260] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:42,261] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:42,262] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:42,262] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,263] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,265] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:42,266] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:42,267] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:42,268] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:42,268] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:42,271] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:42,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,275] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,276] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,277] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,277] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,278] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,279] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,279] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,280] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,280] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,281] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:42,282] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:42,282] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:42,283] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:42,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:42,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:42,285] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,294] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,295] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,296] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,296] {spark_submit.py:495} INFO - 23/03/03 10:54:40 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:42,297] {spark_submit.py:495} INFO - 23/03/03 10:54:40 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:42,298] {spark_submit.py:495} INFO - 23/03/03 10:54:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:42,299] {spark_submit.py:495} INFO - 23/03/03 10:54:40 ERROR Inbox: Ignoring error
[2023-03-03 10:54:42,299] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,300] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,301] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,301] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,302] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,303] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,304] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,305] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,305] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,306] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,306] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,308] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,309] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,311] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,311] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,313] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,314] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,315] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,316] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,317] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,317] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,318] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,319] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,320] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,321] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,322] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,324] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,324] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,325] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,327] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,329] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,330] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,331] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,332] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,334] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,335] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,339] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,340] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,342] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,343] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:42,343] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:42,345] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,346] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:42,346] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:42,347] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:42,349] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:42,350] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:42,352] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:42,353] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,354] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,354] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,355] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,356] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:42,357] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:42,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:42,358] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:42,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:42,359] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:42,360] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,361] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,361] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,363] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,364] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,364] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,366] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,367] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,368] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,370] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:42,373] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:42,379] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:42,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:42,381] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:42,382] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:42,383] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,383] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,384] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,385] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,386] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,387] {spark_submit.py:495} INFO - 23/03/03 10:54:40 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:42,388] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,389] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,390] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,390] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:42,391] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:42,392] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:42,393] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:42,394] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:42,395] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:42,396] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,398] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:42,404] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:42,405] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,406] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:42,406] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:42,407] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,408] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,409] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,409] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,410] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,411] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,411] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,412] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,414] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,415] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,416] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,417] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,418] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,420] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,424] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,425] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,426] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,426] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,427] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,428] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,429] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,429] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,430] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,431] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,432] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,432] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,433] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,434] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,435] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,435] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,436] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,437] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,438] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,440] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,441] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,441] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,442] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,443] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,445] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,447] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,449] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,450] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,451] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,452] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,454] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,456] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:42,457] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:42,458] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,458] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:42,459] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:42,460] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:42,461] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:42,461] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:42,462] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:42,463] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,464] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,465] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,465] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,466] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:42,466] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:42,467] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:42,468] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:42,468] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:42,469] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:42,469] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,470] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,471] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,473] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,476] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,478] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,478] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,479] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:42,479] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:42,480] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:42,481] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:42,481] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:42,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:42,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,484] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,485] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,485] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,486] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,486] {spark_submit.py:495} INFO - 23/03/03 10:54:41 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:42,487] {spark_submit.py:495} INFO - 23/03/03 10:54:41 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:42,488] {spark_submit.py:495} INFO - 23/03/03 10:54:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:42,488] {spark_submit.py:495} INFO - 23/03/03 10:54:41 ERROR Inbox: Ignoring error
[2023-03-03 10:54:42,489] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,489] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,490] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,490] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,491] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,494] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,496] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,498] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,498] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,499] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,499] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,500] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,502] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,502] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,504] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,505] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,505] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,506] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,506] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,507] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,509] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,509] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,510] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,510] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,511] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,520] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:42,523] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:42,550] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:42,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:42,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:42,564] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:42,571] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:42,586] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:42,587] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:42,590] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:42,591] {spark_submit.py:495} INFO - 23/03/03 10:54:41 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:42,610] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,614] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:42,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:42,621] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:42,622] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:42,623] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:42,624] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:42,625] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,626] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:42,630] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:42,635] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,636] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:42,637] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:42,637] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,638] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,639] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,640] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,640] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,641] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,643] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,644] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,645] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,646] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,646] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,647] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,648] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,649] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,649] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,650] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,650] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,651] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,654] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,656] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,657] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,658] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,659] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,660] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,661] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,661] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,663] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 10:54:42,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 10:54:42,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 10:54:42,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 10:54:42,668] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 10:54:42,668] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 10:54:42,669] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 10:54:42,670] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 10:54:42,670] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 10:54:42,671] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 10:54:42,672] {spark_submit.py:495} INFO - 23/03/03 10:54:41 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:42,673] {spark_submit.py:495} INFO - 23/03/03 10:54:41 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:42,674] {spark_submit.py:495} INFO - 23/03/03 10:54:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:42,677] {spark_submit.py:495} INFO - 23/03/03 10:54:41 ERROR Inbox: Ignoring error
[2023-03-03 10:54:42,678] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,679] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,680] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,682] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,682] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,683] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,684] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,685] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,686] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,687] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,691] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,693] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,694] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,695] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,695] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,696] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,697] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,697] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,698] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,699] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,700] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,705] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,710] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,711] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,713] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,721] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,722] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,723] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,727] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,730] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:42,736] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:42,738] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,743] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:42,747] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:42,749] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:42,756] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:42,757] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:42,757] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:42,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,759] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,761] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,762] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:42,763] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:42,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:42,764] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:42,765] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:42,766] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:42,766] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,767] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,768] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,769] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,769] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,770] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,772] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,775] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,776] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,778] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:42,785] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:42,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:42,790] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:42,791] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:42,792] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:42,792] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,793] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,800] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,806] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,820] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,825] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,827] {spark_submit.py:495} INFO - 23/03/03 10:54:41 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:42,829] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,831] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,833] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,835] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:42,836] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:42,837] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:42,838] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:42,841] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:42,842] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:42,843] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,844] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:42,844] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:42,845] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,848] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:42,851] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:42,854] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:42,873] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:42,875] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:42,876] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:42,877] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:42,878] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:42,880] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:42,883] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:42,884] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:42,887] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:42,889] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:42,892] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:42,893] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:42,894] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:42,896] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:42,897] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:42,898] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:42,898] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:42,899] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:42,900] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:42,900] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:42,901] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:42,902] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:42,904] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:42,905] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:42,905] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:42,907] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:42,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:42,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,909] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,910] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,918] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,919] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,920] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,920] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,921] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:42,923] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:42,925] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,927] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,930] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,931] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,933] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:42,934] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:42,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:42,936] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:42,937] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:42,937] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:42,938] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:42,939] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:42,941] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:42,942] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:42,944] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:42,944] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:42,945] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:42,946] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:42,947] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:42,947] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:42,948] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:42,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:42,973] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:42,976] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:42,977] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:42,986] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:42,989] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:42,991] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:42,998] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,004] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,005] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,006] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,007] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,010] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,020] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,033] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,046] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,047] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:43,050] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:43,061] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:43,064] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:43,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:43,078] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:43,081] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,084] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,085] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,086] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,087] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,087] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:43,088] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:43,089] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:43,090] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:43,094] {spark_submit.py:495} INFO - 23/03/03 10:54:42 ERROR Inbox: Ignoring error
[2023-03-03 10:54:43,099] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:43,101] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:43,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:43,103] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:43,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:43,104] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:43,105] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:43,106] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:43,116] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:43,131] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:43,142] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:43,143] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:43,145] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,146] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,160] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,167] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:43,169] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:43,170] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:43,178] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:43,179] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:43,181] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:43,182] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:43,183] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:43,184] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:43,198] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:43,199] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,200] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,200] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,201] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,209] {base_job.py:229} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.19.0.9), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 201, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2877, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2950, in _merge
    merged = self.get(mapper.class_, key[1], identity_token=key[2])
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2702, in get
    identity_token=identity_token,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2800, in _get_impl
    load_options=load_options,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 535, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.19.0.9), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-03-03 10:54:43,215] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,217] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,220] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,233] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,235] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,237] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,263] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,264] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,266] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,267] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,268] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,269] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,272] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,279] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,280] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,282] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:43,283] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:43,284] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:43,285] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:43,287] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:43,291] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:43,291] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:43,292] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:43,293] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:43,295] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,300] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,304] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,319] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,320] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:43,321] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:43,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:43,324] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:43,334] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:43,344] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:43,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,349] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,359] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,359] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,360] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,361] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,362] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,363] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:43,364] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:43,364] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:43,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:43,367] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:43,367] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:43,368] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,369] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,372] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,374] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,375] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,376] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:43,377] {spark_submit.py:495} INFO - 23/03/03 10:54:42 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:43,377] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:43,378] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:43,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:43,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:43,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:43,381] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:43,382] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:43,383] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:43,392] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:43,396] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:43,420] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:43,421] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:43,439] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:43,440] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:43,440] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:43,441] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:43,443] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:43,444] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:43,445] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:43,446] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:43,446] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:43,447] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:43,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:43,459] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:43,459] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:43,460] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:43,463] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:43,468] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:43,474] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:43,474] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:43,475] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,476] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,476] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,477] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,478] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,479] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:43,479] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:43,480] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:43,480] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:43,481] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:43,482] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:43,487] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:43,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:43,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,494] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,498] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,498] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,499] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,504] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,506] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,509] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,510] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,514] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,514] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,515] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,517] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,517] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,518] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,520] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,521] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:43,523] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:43,534] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:43,539] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:43,541] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:43,543] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:43,545] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:43,546] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:43,547] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:43,548] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,550] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,552] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:43,553] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:43,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:43,555] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:43,560] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:43,561] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:43,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,563] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,564] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,567] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,567] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,568] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,569] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,569] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,570] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,571] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:43,572] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:43,573] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:43,573] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:43,574] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:43,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:43,576] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,577] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,578] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,579] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,579] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,580] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:43,582] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:43,583] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:43,584] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:43,585] {spark_submit.py:495} INFO - 23/03/03 10:54:42 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:43,586] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:43,587] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:43,589] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:43,593] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:43,594] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:43,595] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:43,596] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:43,597] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:43,600] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:43,601] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:43,602] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:43,602] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:43,610] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:43,610] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:43,612] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:43,613] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:43,614] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:43,615] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:43,615] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:43,616] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:43,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:43,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:43,624] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:43,626] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:43,627] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:43,627] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:43,630] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:43,630] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:43,631] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:43,632] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:43,633] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,636] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,637] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:43,638] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:43,638] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:43,639] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:43,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:43,643] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:43,649] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:43,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:43,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,659] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,689] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,705] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,712] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,714] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,717] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,722] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,723] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,725] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,726] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,726] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:43,733] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:43,736] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:43,737] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:43,738] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:43,739] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:43,741] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:43,741] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:43,742] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:43,753] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,755] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,756] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:43,757] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:43,758] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:43,759] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:43,759] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:43,760] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:43,761] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,763] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,771] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,781] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,782] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,793] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,794] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,797] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,799] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:43,800] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:43,801] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:43,801] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:43,802] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:43,803] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:43,806] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,821] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,822] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,826] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:43,827] {spark_submit.py:495} INFO - 23/03/03 10:54:42 ERROR Inbox: Ignoring error
[2023-03-03 10:54:43,828] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:43,829] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:43,830] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:43,831] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:43,832] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:43,832] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:43,840] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:43,841] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:43,842] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:43,845] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:43,846] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:43,847] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:43,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:43,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:43,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:43,850] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:43,853] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:43,854] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:43,855] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:43,856] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:43,857] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:43,858] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:43,859] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:43,872] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:43,873] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:43,873] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:43,876] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:43,878] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,879] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,884] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,891] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,900] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,910] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,911] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,913] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,927] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:43,928] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:43,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,940] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,941] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:43,943] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:43,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:43,946] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:43,952] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:43,958] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:43,960] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:43,970] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:43,972] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:43,973] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:43,974] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:43,974] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:43,975] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:43,976] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:43,976] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:43,977] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:43,978] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:43,980] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:43,983] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:43,986] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:43,987] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:43,988] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:43,990] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:43,991] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:43,997] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,004] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:44,010] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:44,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,012] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,014] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,015] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:44,015] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:44,016] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:44,017] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:44,018] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:44,019] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:44,024] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:44,026] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:44,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:44,028] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:44,035] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:44,036] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:44,037] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:44,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:44,039] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:44,039] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:44,040] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:44,041] {spark_submit.py:495} INFO - 23/03/03 10:54:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:44,041] {spark_submit.py:495} INFO - 23/03/03 10:54:42 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:44,042] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:44,044] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:44,052] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:44,053] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:44,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:44,057] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:44,059] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:44,059] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:44,060] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:44,061] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:44,063] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:44,064] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:44,065] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:44,065] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:44,067] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:44,067] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:44,068] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:44,069] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:44,069] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:44,070] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:44,071] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:44,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:44,083] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:44,088] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:44,098] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:44,099] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:44,100] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:44,100] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:44,101] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:44,102] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:44,103] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:44,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:44,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:44,105] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:44,106] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:44,107] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:44,108] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:44,108] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:44,109] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:44,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:44,111] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:44,113] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:44,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:44,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,123] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:44,126] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:44,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,130] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,131] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,137] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,138] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:44,140] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:44,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:44,164] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:44,166] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,167] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:44,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:44,174] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,177] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,178] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:44,179] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:44,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:44,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:44,181] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,182] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:44,183] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:44,183] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:44,184] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:44,185] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:44,185] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:44,186] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:44,187] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:44,188] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:44,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,189] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,190] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,192] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:44,193] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:44,198] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:44,199] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:44,202] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:44,203] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:44,207] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,208] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:44,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:44,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,210] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,213] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:44,278] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:44,279] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:44,280] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:44,294] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:44,295] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:44,295] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:44,296] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:44,297] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:44,298] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:44,299] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:44,299] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:44,300] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:44,304] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:44,305] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:44,312] {spark_submit.py:495} INFO - 23/03/03 10:54:42 ERROR Inbox: Ignoring error
[2023-03-03 10:54:44,313] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:44,314] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:44,315] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:44,316] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:44,317] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:44,318] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:44,319] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:44,319] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:44,320] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:44,321] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:44,323] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:44,324] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:44,324] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:44,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:44,327] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:44,329] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:44,330] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:44,330] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:44,332] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:44,337] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:44,338] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:44,339] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:44,340] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:44,341] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:44,347] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:44,349] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:44,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:44,353] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,354] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:44,356] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:44,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,361] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,363] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,365] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,366] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:44,368] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:44,369] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:44,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:44,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,371] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:44,372] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:44,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,374] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,375] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,412] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:44,416] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:44,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:44,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:44,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,419] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:44,420] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:44,421] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:44,422] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:44,422] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:44,427] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:44,430] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:44,431] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:44,433] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:44,437] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,438] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,439] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,440] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,441] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:44,442] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:44,442] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:44,444] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:44,444] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:44,445] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:44,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:44,448] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:44,451] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:44,456] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:44,457] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:44,458] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:44,458] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:44,459] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:44,460] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:44,461] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:44,461] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:44,463] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:44,464] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:44,465] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:44,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:44,467] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:44,468] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:44,469] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:44,471] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:44,473] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:44,474] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:44,476] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:47,628] {spark_submit.py:495} INFO - 23/03/03 10:54:47 INFO Executor: Told to re-register on heartbeat
[2023-03-03 10:54:47,634] {spark_submit.py:495} INFO - 23/03/03 10:54:47 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None) re-registering with master
[2023-03-03 10:54:47,636] {spark_submit.py:495} INFO - 23/03/03 10:54:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 43621, None)
[2023-03-03 10:54:47,644] {spark_submit.py:495} INFO - 23/03/03 10:54:47 ERROR Inbox: Ignoring error
[2023-03-03 10:54:47,645] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:47,646] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:47,647] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:47,648] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:47,649] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:47,653] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:47,656] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:47,666] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:47,667] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:47,674] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:47,676] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:47,678] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:47,680] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:47,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:47,685] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:47,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:47,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:47,690] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:47,690] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:47,691] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:47,694] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:47,695] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:47,696] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:47,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:47,705] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:47,706] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:47,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:47,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:47,724] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:47,728] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:47,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:47,734] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:47,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:47,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:47,737] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:47,737] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:47,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:47,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:47,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:47,740] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:47,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:47,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:47,748] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:47,748] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:47,749] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:47,750] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:47,751] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:47,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:47,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:47,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:47,755] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:47,756] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:47,759] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:47,761] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:47,763] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:47,764] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:47,769] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:47,770] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:47,774] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:47,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:47,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:47,776] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:47,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:47,778] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:47,779] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:47,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:47,786] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:47,788] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:47,789] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:47,794] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:47,795] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:47,797] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:47,799] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:47,800] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:47,802] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:47,810] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:47,811] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:47,811] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:47,812] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:47,813] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:47,813] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:47,816] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:47,817] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:47,818] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:47,818] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:47,819] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:47,819] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:47,820] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:47,820] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:47,821] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:47,825] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:47,825] {spark_submit.py:495} INFO - 23/03/03 10:54:47 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 10:54:47,840] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:47,844] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:47,847] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:47,850] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 10:54:47,851] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 10:54:47,866] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 10:54:47,867] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 10:54:47,883] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 10:54:47,887] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 10:54:47,893] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:47,896] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 10:54:47,923] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 10:54:47,944] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:47,953] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 10:54:47,960] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 10:54:47,960] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 10:54:47,964] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 10:54:47,965] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 10:54:47,965] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 10:54:47,966] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 10:54:47,967] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 10:54:47,967] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 10:54:47,969] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 10:54:47,977] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 10:54:47,979] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 10:54:47,982] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 10:54:47,983] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 10:54:47,984] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 10:54:47,988] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 10:54:47,989] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 10:54:47,993] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:48,003] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:48,024] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:48,029] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:48,029] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:48,030] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 10:54:48,032] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 10:54:48,040] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:48,040] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:35723
[2023-03-03 10:54:48,043] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 10:54:48,045] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 10:54:48,056] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 10:54:48,062] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 10:54:48,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:48,085] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:48,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:48,088] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:48,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:48,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:48,100] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:48,102] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:48,114] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:48,136] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:48,137] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:48,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:48,146] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:48,156] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:48,160] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:48,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:48,162] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:48,163] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:48,164] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:48,165] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:48,167] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:48,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 10:54:48,174] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:48,177] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 10:54:48,179] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 10:54:48,180] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 10:54:48,183] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 10:54:48,188] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 10:54:48,190] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 10:54:48,191] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 10:54:48,193] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 10:54:48,195] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 10:54:48,198] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:48,203] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:48,209] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:48,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:48,223] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 10:54:48,224] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 10:54:48,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 10:54:48,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 10:54:48,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 10:54:48,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 10:54:48,229] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 10:54:48,230] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 10:54:48,231] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 10:54:48,235] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 10:54:48,236] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 10:54:48,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 10:54:48,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 10:54:48,243] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 10:54:48,244] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 10:54:48,248] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 10:54:48,267] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 10:54:48,269] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 10:54:48,271] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 10:54:48,273] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 10:54:48,276] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 10:54:48,277] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 10:54:48,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 10:54:48,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 10:54:48,282] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 10:54:48,283] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 10:54:48,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 10:54:48,285] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 10:54:48,621] {local_task_job.py:221} WARNING - State of this instance has been externally set to queued. Terminating instance.
[2023-03-03 10:54:48,645] {process_utils.py:129} INFO - Sending Signals.SIGTERM to group 2148. PIDs of all processes in the group: [2149, 2192, 2148]
[2023-03-03 10:54:48,647] {process_utils.py:80} INFO - Sending the signal Signals.SIGTERM to group 2148
[2023-03-03 10:54:48,659] {taskinstance.py:1541} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-03-03 10:54:48,672] {spark_submit.py:620} INFO - Sending kill signal to spark-submit
[2023-03-03 10:54:49,004] {process_utils.py:75} INFO - Process psutil.Process(pid=2192, status='terminated', started='10:44:03') (2192) terminated with exit code None
[2023-03-03 10:54:49,072] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/usr/local/lib/python3.7/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 414, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
  File "/usr/local/lib/python3.7/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 463, in _process_spark_submit_log
    for line in itr:
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1543, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-03-03 10:54:49,146] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=avg_product_price, task_id=spark_submit, execution_date=20230303T104343, start_date=20230303T104346, end_date=20230303T105449
[2023-03-03 10:54:49,546] {standard_task_runner.py:97} ERROR - Failed to execute job 3 for task spark_submit (Task received SIGTERM signal; 2148)
[2023-03-03 10:54:49,633] {process_utils.py:75} INFO - Process psutil.Process(pid=2148, status='terminated', exitcode=1, started='10:43:46') (2148) terminated with exit code 1
