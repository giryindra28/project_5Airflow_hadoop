[2023-03-03 11:41:44,212] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T11:41:42.035156+00:00 [queued]>
[2023-03-03 11:41:44,234] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T11:41:42.035156+00:00 [queued]>
[2023-03-03 11:41:44,234] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-03-03 11:41:44,235] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-03-03 11:41:44,235] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-03-03 11:41:44,263] {taskinstance.py:1377} INFO - Executing <Task(SparkSubmitOperator): spark_submit> on 2023-03-03 11:41:42.035156+00:00
[2023-03-03 11:41:44,270] {standard_task_runner.py:52} INFO - Started process 1314 to run task
[2023-03-03 11:41:44,276] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'avg_product_price', 'spark_submit', 'manual__2023-03-03T11:41:42.035156+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/avg_product_price.py', '--cfg-path', '/tmp/tmpbpa7vzb4', '--error-file', '/tmp/tmpqrjr6nuv']
[2023-03-03 11:41:44,281] {standard_task_runner.py:80} INFO - Job 11: Subtask spark_submit
[2023-03-03 11:41:44,410] {task_command.py:370} INFO - Running <TaskInstance: avg_product_price.spark_submit manual__2023-03-03T11:41:42.035156+00:00 [running]> on host 7f5e973bdd66
[2023-03-03 11:41:44,638] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=ayyoub
AIRFLOW_CTX_DAG_ID=avg_product_price
AIRFLOW_CTX_TASK_ID=spark_submit
AIRFLOW_CTX_EXECUTION_DATE=2023-03-03T11:41:42.035156+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-03-03T11:41:42.035156+00:00
[2023-03-03 11:41:44,662] {base.py:68} INFO - Using connection ID 'spark-hadoop' for task execution.
[2023-03-03 11:41:44,664] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master local[*] --name arrow-spark /hadoop-data/map_reduce/spark/average_price.py
[2023-03-03 11:41:52,778] {spark_submit.py:495} INFO - 23/03/03 11:41:52 INFO SparkContext: Running Spark version 3.3.2
[2023-03-03 11:41:53,022] {spark_submit.py:495} INFO - 23/03/03 11:41:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-03-03 11:41:53,287] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO ResourceUtils: ==============================================================
[2023-03-03 11:41:53,290] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-03-03 11:41:53,291] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO ResourceUtils: ==============================================================
[2023-03-03 11:41:53,293] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO SparkContext: Submitted application: average_product_price
[2023-03-03 11:41:53,386] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-03-03 11:41:53,420] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO ResourceProfile: Limiting resource is cpu
[2023-03-03 11:41:53,423] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-03-03 11:41:53,591] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO SecurityManager: Changing view acls to: ***
[2023-03-03 11:41:53,593] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO SecurityManager: Changing modify acls to: ***
[2023-03-03 11:41:53,595] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO SecurityManager: Changing view acls groups to:
[2023-03-03 11:41:53,596] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO SecurityManager: Changing modify acls groups to:
[2023-03-03 11:41:53,598] {spark_submit.py:495} INFO - 23/03/03 11:41:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(***); groups with view permissions: Set(); users  with modify permissions: Set(***); groups with modify permissions: Set()
[2023-03-03 11:41:54,365] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO Utils: Successfully started service 'sparkDriver' on port 34603.
[2023-03-03 11:41:54,521] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO SparkEnv: Registering MapOutputTracker
[2023-03-03 11:41:54,722] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO SparkEnv: Registering BlockManagerMaster
[2023-03-03 11:41:54,780] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-03-03 11:41:54,781] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-03-03 11:41:54,798] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-03-03 11:41:54,877] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d162a7e9-532d-44cc-8049-8261f9d483ab
[2023-03-03 11:41:54,961] {spark_submit.py:495} INFO - 23/03/03 11:41:54 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-03-03 11:41:55,027] {spark_submit.py:495} INFO - 23/03/03 11:41:55 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-03-03 11:41:55,999] {spark_submit.py:495} INFO - 23/03/03 11:41:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-03-03 11:41:56,405] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO Executor: Starting executor ID driver on host 7f5e973bdd66
[2023-03-03 11:41:56,427] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-03-03 11:41:56,498] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42669.
[2023-03-03 11:41:56,499] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO NettyBlockTransferService: Server created on 7f5e973bdd66:42669
[2023-03-03 11:41:56,504] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-03-03 11:41:56,528] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 11:41:56,541] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO BlockManagerMasterEndpoint: Registering block manager 7f5e973bdd66:42669 with 434.4 MiB RAM, BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 11:41:56,549] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 11:41:56,553] {spark_submit.py:495} INFO - 23/03/03 11:41:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 11:41:58,176] {spark_submit.py:495} INFO - /opt/spark-3.3.2-bin-hadoop3/python/lib/pyspark.zip/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2023-03-03 11:54:44,625] {spark_submit.py:495} INFO - 23/03/03 11:54:25 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 129834 ms exceeds timeout 120000 ms
[2023-03-03 12:15:15,564] {spark_submit.py:495} INFO - 23/03/03 12:15:15 WARN NettyRpcEnv: Ignored message: true
[2023-03-03 12:15:15,634] {spark_submit.py:495} INFO - 23/03/03 12:15:15 WARN SparkContext: Killing executors is not supported by current scheduler.
[2023-03-03 12:15:19,330] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:19,333] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:19,334] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:19,423] {spark_submit.py:495} INFO - 23/03/03 12:15:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:19,425] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,427] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,429] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:19,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:19,435] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:19,443] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:19,444] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:19,444] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:19,445] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:19,445] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:19,446] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:19,447] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,449] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:19,449] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:19,453] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:19,454] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:19,455] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:19,458] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,464] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,465] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:19,466] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:19,467] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:19,471] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:19,484] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:19,485] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:19,486] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:19,487] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:19,488] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:19,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,495] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,497] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,505] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,508] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:19,509] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:19,510] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:19,512] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:19,513] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:19,514] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:19,515] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:19,516] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,517] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,518] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,519] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,520] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,521] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,523] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:19,528] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:19,530] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:19,532] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:19,534] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,537] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,543] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,544] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,546] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,552] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:19,553] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:19,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:19,554] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:19,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,557] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:19,559] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:19,560] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:19,561] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:19,563] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:19,566] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:19,567] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:19,568] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:19,568] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:19,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,577] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,581] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:19,582] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:19,583] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:19,586] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:19,589] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:19,590] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:19,592] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,595] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,596] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,597] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,598] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,602] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,605] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,610] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:19,611] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:19,612] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:19,614] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:19,614] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:19,615] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:19,626] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:19,629] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:19,636] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:19,638] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,640] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,643] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,648] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:19,656] {spark_submit.py:495} INFO - 23/03/03 12:15:19 ERROR Inbox: Ignoring error
[2023-03-03 12:15:19,657] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,657] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,658] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,659] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:19,659] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:19,660] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:19,660] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:19,661] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:19,662] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:19,663] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:19,664] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:19,664] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:19,666] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,667] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,669] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,670] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,671] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,673] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:19,675] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:19,676] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:19,677] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:19,680] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:19,680] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:19,681] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:19,681] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:19,682] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:19,683] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,684] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,684] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,685] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,688] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,690] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,695] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:19,696] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:19,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:19,699] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:19,701] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,702] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,704] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,710] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:19,712] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:19,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:19,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:19,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,715] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:19,717] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:19,720] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:19,721] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:19,722] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:19,723] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:19,724] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:19,726] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:19,727] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:19,728] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,732] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,734] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:19,735] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:19,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:19,739] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:19,741] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:19,742] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:19,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,744] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,746] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,747] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:19,748] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:19,749] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:19,753] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:19,754] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:19,760] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:19,762] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:19,768] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:19,770] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:19,773] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:19,775] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:19,777] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:19,779] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,781] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,782] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,783] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,784] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,785] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:19,787] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:19,789] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:19,790] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:19,791] {spark_submit.py:495} INFO - 23/03/03 12:15:19 ERROR Inbox: Ignoring error
[2023-03-03 12:15:19,792] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,793] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,795] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,797] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:19,798] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:19,799] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:19,800] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:19,800] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:19,801] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:19,802] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:19,803] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:19,803] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:19,804] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,805] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,806] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,808] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,809] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,810] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,810] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:19,811] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:19,812] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:19,813] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:19,814] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:19,815] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:19,816] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:19,817] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:19,818] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:19,819] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,821] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,823] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,824] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,825] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:19,825] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:19,826] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:19,827] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:19,828] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:19,830] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:19,832] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:19,834] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:19,835] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:19,837] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:19,838] {spark_submit.py:495} INFO - 23/03/03 12:15:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:19,839] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,840] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,841] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,842] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:19,844] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:19,844] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:19,845] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:19,846] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:19,847] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:19,847] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:19,848] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:19,849] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:19,849] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,850] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:19,851] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:19,852] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:19,852] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:19,853] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:19,854] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,854] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,860] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,861] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:19,861] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:19,862] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:19,863] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:19,864] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:19,864] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:19,865] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:19,866] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:19,866] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:19,867] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,868] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,869] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,869] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,870] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,871] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,876] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:19,878] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:19,879] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:19,880] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:19,881] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:19,882] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:19,882] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:19,883] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,884] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,885] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,885] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,886] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:19,887] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:19,888] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:19,888] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:19,890] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:19,891] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:19,891] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:19,892] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:19,893] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:19,894] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:19,894] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:19,896] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:19,898] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:19,899] {spark_submit.py:495} INFO - 23/03/03 12:15:19 ERROR Inbox: Ignoring error
[2023-03-03 12:15:19,899] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,901] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,902] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,903] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:19,904] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:19,905] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:19,909] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:19,911] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:19,912] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:19,914] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:19,914] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:19,915] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:19,917] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,918] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,920] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,921] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,922] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,923] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,924] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:19,925] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:19,925] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:19,926] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:19,927] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:19,928] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:19,929] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:19,930] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:19,930] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:19,931] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,932] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,932] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:19,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:19,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:19,937] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:19,938] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:19,939] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:19,940] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:19,943] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:19,945] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:19,945] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:19,946] {spark_submit.py:495} INFO - 23/03/03 12:15:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:19,947] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,948] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,949] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:19,950] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:19,950] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:19,951] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:19,952] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:19,952] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:19,953] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:19,953] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:19,954] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:19,954] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,955] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:19,956] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:19,956] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:19,957] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:19,958] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:19,959] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:19,961] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:19,963] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:19,964] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:19,965] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:19,966] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:19,966] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:19,967] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:19,968] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:19,968] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:19,969] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:19,970] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:19,970] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:19,971] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:19,972] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:19,972] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:19,973] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:19,974] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:19,974] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:19,975] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:19,975] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:19,976] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:19,976] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:19,978] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:19,983] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:19,984] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:19,985] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:19,986] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:19,987] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:19,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:19,993] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:19,994] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:19,998] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:20,000] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:20,002] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:20,003] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:20,004] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:20,006] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:20,006] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:20,007] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:20,008] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:20,010] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:20,011] {spark_submit.py:495} INFO - 23/03/03 12:15:19 ERROR Inbox: Ignoring error
[2023-03-03 12:15:20,014] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,015] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,020] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,023] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:20,025] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:20,026] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:20,030] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:20,033] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:20,047] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:20,053] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:20,054] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:20,061] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:20,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,075] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,078] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,079] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:20,080] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:20,084] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:20,085] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:20,086] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:20,092] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:20,092] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:20,093] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:20,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:20,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,096] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,097] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,098] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,099] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,100] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,101] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,101] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,102] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,108] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,110] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,111] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,115] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,116] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,127] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,129] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:20,130] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:20,130] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,131] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:20,132] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:20,134] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:20,135] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:20,136] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:20,136] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:20,137] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,137] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,146] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,147] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:20,148] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:20,148] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:20,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:20,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:20,150] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:20,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,151] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,152] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,152] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,153] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,153] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,154] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,161] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,163] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,189] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:20,190] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:20,192] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:20,193] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:20,195] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:20,201] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:20,203] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,205] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,206] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,210] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,211] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,214] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,215] {spark_submit.py:495} INFO - 23/03/03 12:15:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:20,216] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,218] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:20,221] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:20,221] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:20,222] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:20,223] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:20,223] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:20,224] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,224] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:20,225] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:20,226] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,227] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:20,229] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:20,231] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:20,232] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:20,233] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:20,235] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,236] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,237] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,238] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:20,238] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:20,240] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:20,241] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:20,242] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:20,243] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:20,244] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:20,244] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:20,245] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:20,251] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,252] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,254] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,255] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,256] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:20,257] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,258] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:20,259] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:20,260] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:20,261] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:20,262] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:20,263] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,264] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,265] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,265] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,266] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,267] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,268] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,269] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,270] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,272] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,273] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,275] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,277] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,279] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,281] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,282] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,283] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,284] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,284] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,287] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,288] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:20,289] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:20,289] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,290] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:20,291] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:20,291] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:20,292] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:20,293] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:20,294] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:20,295] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,297] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,304] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:20,304] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:20,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:20,306] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:20,307] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:20,308] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:20,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,311] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,315] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,316] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,317] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,318] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,318] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,319] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,320] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,321] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:20,322] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:20,322] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:20,323] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:20,324] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:20,324] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:20,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,327] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,328] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,329] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,330] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:20,330] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:20,331] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:20,333] {spark_submit.py:495} INFO - 23/03/03 12:15:19 ERROR Inbox: Ignoring error
[2023-03-03 12:15:20,335] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,337] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,339] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,341] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:20,342] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:20,346] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:20,348] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:20,350] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:20,352] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:20,357] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:20,361] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:20,363] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:20,364] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,365] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,366] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,368] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,369] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,370] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:20,372] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:20,373] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:20,375] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:20,376] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:20,377] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:20,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:20,380] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:20,381] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:20,382] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,383] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,383] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,384] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,389] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,390] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,390] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,394] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,396] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,397] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,398] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,399] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,400] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,401] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,401] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,402] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,403] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,404] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,405] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,405] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,406] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,407] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,408] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:20,409] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:20,410] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,411] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:20,412] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:20,413] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:20,414] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:20,414] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:20,415] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:20,416] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,419] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:20,419] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:20,421] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:20,422] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:20,423] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:20,423] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:20,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,425] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,426] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,426] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,427] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,429] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,430] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,431] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,431] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,432] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:20,432] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:20,435] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:20,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:20,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:20,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:20,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,440] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,448] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,452] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,453] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,454] {spark_submit.py:495} INFO - 23/03/03 12:15:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:20,455] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,455] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,456] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:20,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:20,458] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:20,459] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:20,460] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:20,461] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:20,467] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,469] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:20,474] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:20,474] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,475] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:20,476] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:20,483] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:20,489] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:20,490] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:20,491] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,491] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:20,497] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:20,498] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:20,499] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:20,500] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:20,501] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:20,502] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:20,504] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:20,507] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:20,509] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,514] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,520] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,531] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,531] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,532] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,536] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:20,543] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,544] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:20,545] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:20,545] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:20,546] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:20,548] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:20,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,550] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,563] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,564] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,565] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,573] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,574] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,575] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,575] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,577] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,580] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,582] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,583] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,583] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,585] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,588] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,589] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,591] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,599] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,606] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:20,612] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:20,613] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,614] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:20,615] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:20,620] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:20,623] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:20,624] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:20,625] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:20,625] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,627] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,629] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:20,630] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:20,631] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:20,631] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:20,632] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:20,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:20,635] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,636] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,636] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,637] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,638] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,639] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,641] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,649] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,651] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:20,652] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:20,652] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:20,659] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:20,662] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:20,665] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:20,665] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,666] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,667] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,667] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,669] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,669] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:20,670] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:20,670] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:20,672] {spark_submit.py:495} INFO - 23/03/03 12:15:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:20,673] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,689] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,691] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:20,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:20,693] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:20,694] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:20,694] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:20,696] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:20,697] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,698] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:20,699] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:20,700] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,700] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:20,702] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:20,702] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:20,706] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:20,710] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:20,711] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,712] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,713] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,714] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:20,714] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:20,715] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:20,716] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:20,717] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:20,717] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:20,718] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:20,719] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:20,720] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:20,722] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,724] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,729] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,730] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,730] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:20,731] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,732] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:20,732] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:20,733] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:20,734] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:20,734] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:20,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,738] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,746] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,748] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,749] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,750] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,753] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,754] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,756] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,759] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,760] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,764] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,764] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,767] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,770] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,777] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,778] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:20,779] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:20,780] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,781] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:20,782] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:20,785] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:20,786] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:20,787] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:20,787] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:20,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,789] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,789] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,791] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:20,791] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:20,792] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:20,793] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:20,794] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:20,795] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:20,798] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,799] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,800] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,801] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,804] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,805] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,807] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,808] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,809] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,810] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,811] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:20,812] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:20,820] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:20,822] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:20,823] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:20,824] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:20,825] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,826] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,826] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,827] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,828] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,828] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,829] {spark_submit.py:495} INFO - 23/03/03 12:15:19 ERROR Inbox: Ignoring error
[2023-03-03 12:15:20,830] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,832] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,833] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,833] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:20,834] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:20,835] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:20,836] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:20,836] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:20,837] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:20,838] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:20,839] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:20,839] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:20,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,840] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,841] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,842] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,842] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,843] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,843] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:20,844] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:20,845] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:20,845] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:20,846] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:20,847] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:20,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:20,850] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:20,851] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:20,852] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,853] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,854] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,855] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,856] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,856] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,857] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,858] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,858] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,859] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,860] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,860] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,861] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,862] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,862] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,863] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,864] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,864] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,865] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,866] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,867] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,872] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,873] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,874] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:20,875] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:20,875] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,876] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:20,876] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:20,877] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:20,878] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:20,878] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:20,880] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:20,884] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,885] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,888] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,889] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,890] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:20,892] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:20,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:20,893] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:20,894] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:20,895] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:20,895] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,896] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,897] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,898] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,901] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,903] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,903] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,905] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,906] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,910] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:20,911] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:20,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:20,912] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:20,914] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:20,915] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:20,917] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,921] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,922] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,923] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,923] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,924] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:20,925] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:20,930] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:20,932] {spark_submit.py:495} INFO - 23/03/03 12:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:20,933] {spark_submit.py:495} INFO - 23/03/03 12:15:19 ERROR Inbox: Ignoring error
[2023-03-03 12:15:20,934] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:20,934] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:20,935] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:20,936] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:20,937] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:20,937] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:20,938] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:20,938] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:20,939] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:20,940] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:20,940] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:20,941] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:20,942] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:20,943] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:20,944] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:20,944] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:20,945] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:20,946] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:20,947] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:20,948] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:20,948] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:20,949] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:20,950] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:20,950] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:20,951] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:20,952] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:20,953] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:20,955] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,955] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,956] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,957] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,958] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,958] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,959] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,960] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,962] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,964] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,965] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,968] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,969] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,969] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,970] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,971] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:20,971] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:20,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,973] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:20,974] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:20,975] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:20,977] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:20,977] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:20,978] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:20,979] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:20,980] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:20,981] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:20,982] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,983] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,983] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,984] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,985] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:20,986] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:20,986] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:20,987] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:20,987] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:20,988] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:20,989] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:20,989] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:20,990] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:20,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:20,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:20,992] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:20,993] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:20,993] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:20,998] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:20,999] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,000] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,001] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,002] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,003] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,004] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,005] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,007] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,008] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,010] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,011] {spark_submit.py:495} INFO - 23/03/03 12:15:19 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:21,011] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,012] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,013] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,013] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:21,017] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:21,019] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:21,021] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:21,021] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:21,022] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:21,023] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,023] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:21,024] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:21,024] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,025] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:21,026] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:21,026] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,027] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,029] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,030] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,031] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,034] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,035] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,040] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,040] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,041] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,042] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,045] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,046] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,046] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,048] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,049] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,051] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,057] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,058] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,059] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,060] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,061] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,062] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,071] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,076] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,080] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,081] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,082] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,082] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,083] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,084] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,084] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,085] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,086] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,088] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,089] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,089] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,090] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,091] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,092] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,095] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,096] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,097] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,099] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,100] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:21,101] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:21,102] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:21,103] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:21,103] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:21,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,106] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,107] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:21,108] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:21,108] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:21,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:21,109] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:21,110] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:21,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,115] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,116] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,122] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,125] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,128] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,132] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,133] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,134] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,135] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,135] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,136] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,137] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,138] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,139] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,140] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,141] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,142] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,142] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,143] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,143] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-03-03 12:15:21,144] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:21,145] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO SharedState: Warehouse path is 'file:/home/***/spark-warehouse'.
[2023-03-03 12:15:21,145] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:21,146] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:21,146] {spark_submit.py:495} INFO - 23/03/03 12:15:20 ERROR Inbox: Ignoring error
[2023-03-03 12:15:21,147] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,148] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,149] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,150] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,151] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,151] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,152] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,153] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,154] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,154] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,155] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,155] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,156] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,157] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,158] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,158] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,159] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,160] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,160] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,161] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,162] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,162] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,163] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,164] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,165] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,165] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,166] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,167] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,167] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,169] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,170] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,170] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,171] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,172] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,174] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,174] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,175] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,177] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,178] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,181] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,181] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,182] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,183] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,184] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,184] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,185] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,185] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,186] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,187] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:21,188] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:21,188] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:21,189] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:21,190] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:21,190] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,191] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,192] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,194] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,195] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:21,198] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:21,199] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:21,200] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:21,200] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:21,201] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:21,202] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,202] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,203] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,204] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,205] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,205] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,206] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,207] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,208] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,208] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,209] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,210] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,211] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,214] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,223] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,224] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,225] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,225] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,227] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,228] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,229] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,231] {spark_submit.py:495} INFO - 23/03/03 12:15:20 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:21,232] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,239] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,240] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,241] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:21,242] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:21,243] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:21,244] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:21,244] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:21,245] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:21,247] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,248] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:21,249] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:21,250] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,250] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:21,257] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:21,258] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,260] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,262] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,262] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,263] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,264] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,265] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,266] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,267] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,267] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,269] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,269] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,270] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,271] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,271] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,273] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,275] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,276] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,277] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,280] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,281] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,282] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,283] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,283] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,284] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,286] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,287] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,288] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,289] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,290] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,291] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,292] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,292] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,293] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,295] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,296] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,298] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,300] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,304] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,305] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,307] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,308] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,309] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,309] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,310] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:21,312] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:21,314] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:21,315] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:21,316] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:21,322] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,324] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,325] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:21,325] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:21,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:21,330] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:21,331] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:21,334] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:21,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,338] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,340] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,342] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,343] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,344] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,346] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,347] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,348] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,349] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,351] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,352] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,357] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,361] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,364] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,368] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,369] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,372] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,372] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:21,373] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:21,374] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:21,376] {spark_submit.py:495} INFO - 23/03/03 12:15:20 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:21,377] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,377] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,378] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:21,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:21,380] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:21,381] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:21,381] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:21,382] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:21,383] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,384] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:21,385] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:21,386] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,386] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:21,387] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:21,388] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,389] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,390] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,390] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,391] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,392] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,392] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,393] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,393] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,394] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,395] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,395] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,397] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,400] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,401] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,402] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,403] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,403] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,404] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,405] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,405] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,406] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,407] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,407] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,408] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,409] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,409] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,410] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,411] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,412] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:21,416] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:21,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:21,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:21,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:21,419] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:21,419] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:21,420] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:21,421] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:21,422] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:21,422] {spark_submit.py:495} INFO - 23/03/03 12:15:20 ERROR Inbox: Ignoring error
[2023-03-03 12:15:21,423] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,425] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,426] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,428] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,429] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,431] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,432] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,433] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,434] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,434] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,435] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,436] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,456] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,459] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,461] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,468] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,469] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,469] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,471] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,479] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,480] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,483] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,484] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,486] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,492] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:21,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:21,496] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:21,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:21,498] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:21,498] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:21,499] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:21,500] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:21,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:21,502] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:21,505] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:21,507] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:21,509] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:21,510] {spark_submit.py:495} INFO - 23/03/03 12:15:20 ERROR Inbox: Ignoring error
[2023-03-03 12:15:21,511] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,512] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,513] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,514] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,516] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,517] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,519] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,522] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,525] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,527] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,528] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,530] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,532] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,533] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,535] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,536] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,538] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,542] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,543] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,544] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,545] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,547] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,548] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,549] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,556] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,564] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,565] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,566] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,567] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,568] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,571] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,572] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,574] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,576] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,577] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,579] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,580] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,581] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,581] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,582] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,583] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,583] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,584] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,585] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,586] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,586] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,587] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,587] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,588] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,589] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,589] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:21,590] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:21,590] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:21,591] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:21,592] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:21,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,595] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,598] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:21,599] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:21,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:21,601] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:21,601] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:21,602] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:21,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,603] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,605] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,606] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,606] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,607] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,607] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,608] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,609] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,609] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,614] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,615] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,616] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,617] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,618] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,618] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,619] {spark_submit.py:495} INFO - 23/03/03 12:15:20 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:21,620] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,620] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,621] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,622] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:21,622] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:21,623] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:21,624] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:21,624] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:21,625] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:21,625] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,626] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:21,627] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:21,627] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,628] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:21,628] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:21,630] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,631] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,632] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,633] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,634] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,636] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,637] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,638] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,639] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,640] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,640] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,641] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,642] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,643] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,643] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,644] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,646] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,647] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,648] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,649] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,650] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,651] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,652] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,653] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,656] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,657] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,658] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,660] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,661] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,663] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,664] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,668] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,672] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,673] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,674] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,675] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,675] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,676] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,676] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,677] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,678] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:21,680] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:21,681] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:21,683] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:21,684] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:21,684] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,685] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,686] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,687] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,688] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:21,688] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:21,689] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:21,691] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:21,692] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:21,693] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:21,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,696] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,698] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,699] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,700] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,702] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,704] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,706] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,707] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,708] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,709] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,711] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,715] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,715] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,716] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,717] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,718] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,719] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,719] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,720] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:21,721] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:21,722] {spark_submit.py:495} INFO - 23/03/03 12:15:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:21,723] {spark_submit.py:495} INFO - 23/03/03 12:15:20 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:21,724] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,725] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:21,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:21,728] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:21,729] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:21,730] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:21,731] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:21,731] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,733] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:21,735] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:21,736] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,737] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:21,738] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:21,740] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,742] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,744] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,745] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,747] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,747] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,749] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,751] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,752] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,752] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,754] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,754] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,755] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,756] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,757] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,759] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,761] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,762] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,764] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,764] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,765] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,766] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,767] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,767] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,768] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,769] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,771] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,772] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,775] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,777] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,779] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,782] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,783] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,784] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,785] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,785] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,786] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,787] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,787] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,791] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,792] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,793] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,794] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,796] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,797] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,799] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,800] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,801] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,802] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,803] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,805] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,807] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:21,808] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:21,808] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:21,809] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:21,812] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:21,813] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,813] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,814] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,815] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,816] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:21,816] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:21,817] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:21,818] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:21,819] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:21,821] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:21,822] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,823] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,824] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,826] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,827] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,828] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,829] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,830] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,830] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,832] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,833] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,834] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,834] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,835] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,836] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,838] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,841] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,842] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,842] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,843] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,844] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,844] {spark_submit.py:495} INFO - 23/03/03 12:15:20 ERROR Inbox: Ignoring error
[2023-03-03 12:15:21,846] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,847] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,850] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,850] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,851] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,852] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,853] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,854] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,854] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,855] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,856] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,856] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,857] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,858] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,858] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,860] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,861] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,863] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,865] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,866] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,867] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,869] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,871] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,873] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,874] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,875] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,875] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,876] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,877] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,878] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,878] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,880] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,881] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,883] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,884] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,885] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,886] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,886] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,887] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,888] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,888] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,890] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,890] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,891] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,892] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,892] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,894] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,895] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,898] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,902] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,903] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:21,908] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:21,909] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:21,910] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:21,911] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:21,911] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,920] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,923] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:21,925] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:21,927] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:21,930] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:21,931] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:21,932] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:21,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,935] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,936] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,937] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,938] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,939] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,940] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,941] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,941] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,942] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,942] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:21,943] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:21,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:21,944] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:21,945] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:21,945] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:21,946] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,947] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,948] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,949] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,950] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,950] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:21,951] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:21,951] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:21,952] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:21,953] {spark_submit.py:495} INFO - 23/03/03 12:15:21 ERROR Inbox: Ignoring error
[2023-03-03 12:15:21,953] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:21,954] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:21,954] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:21,955] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:21,956] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:21,956] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:21,957] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:21,958] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:21,959] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:21,960] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:21,960] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:21,962] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:21,962] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:21,963] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:21,964] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:21,965] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:21,966] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:21,967] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:21,968] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:21,968] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:21,969] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:21,970] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:21,970] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:21,971] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:21,972] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:21,973] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:21,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:21,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,975] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,976] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,977] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,977] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,978] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,979] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,980] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,980] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,984] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,986] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,988] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:21,988] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:21,989] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:21,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:21,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:21,992] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:21,993] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:21,994] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:21,994] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:21,995] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:21,996] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:21,996] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:21,997] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:21,998] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:21,998] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:21,999] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,000] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,000] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,001] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,002] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,002] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,003] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,004] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,005] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,005] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,006] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,007] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,008] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,009] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,010] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,011] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,013] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,015] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,016] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,017] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,019] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,020] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,020] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,022] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,023] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,024] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,025] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,025] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,026] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,027] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,028] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,028] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,032] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,035] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,035] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,036] {spark_submit.py:495} INFO - 23/03/03 12:15:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:22,037] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,037] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,039] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:22,040] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:22,041] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:22,042] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:22,043] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:22,043] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:22,044] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,045] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:22,046] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:22,047] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,048] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:22,048] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:22,049] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,050] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,050] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,051] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,052] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,054] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,056] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,057] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,058] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,059] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,060] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,060] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,061] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,062] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,063] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,064] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,065] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,068] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,069] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,069] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,070] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,071] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,073] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,074] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,076] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,079] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,080] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,081] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,081] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,082] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,083] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,084] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,086] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,086] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,088] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,089] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,089] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,090] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,091] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,091] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:22,096] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:22,097] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,098] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:22,099] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,100] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,101] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,103] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,103] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,104] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,105] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,106] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,107] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,108] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,110] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,115] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,116] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,118] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,119] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,120] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,122] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,122] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,123] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,124] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,125] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,125] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,126] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,127] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,132] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,134] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,136] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,136] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,137] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,138] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,139] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:22,139] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:22,140] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:22,141] {spark_submit.py:495} INFO - 23/03/03 12:15:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:22,142] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,142] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,143] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,144] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:22,144] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:22,145] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:22,146] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:22,147] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:22,148] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:22,149] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,152] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:22,153] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:22,154] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,155] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:22,155] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:22,156] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,158] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,159] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,160] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,162] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,162] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,163] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,164] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,165] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,165] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,166] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,167] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,167] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,168] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,170] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,171] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,173] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,175] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,176] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,177] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,178] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,179] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,180] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,181] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,182] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,183] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,183] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,184] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,184] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,185] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,186] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,186] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:22,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:22,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:22,189] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:22,190] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:22,190] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:22,191] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:22,192] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:22,192] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:22,193] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:22,194] {spark_submit.py:495} INFO - 23/03/03 12:15:21 ERROR Inbox: Ignoring error
[2023-03-03 12:15:22,196] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,198] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,199] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,200] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,201] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,201] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,202] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,202] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,203] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,204] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,204] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,205] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,205] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,206] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,207] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,207] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,208] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,208] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,209] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,210] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,210] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,211] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,212] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,214] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,215] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,216] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,217] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,218] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,219] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,219] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,220] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,220] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:22,221] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:22,222] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:22,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:22,224] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:22,224] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:22,225] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:22,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:22,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:22,227] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:22,227] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:22,228] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:22,229] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:22,230] {spark_submit.py:495} INFO - 23/03/03 12:15:21 ERROR Inbox: Ignoring error
[2023-03-03 12:15:22,231] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,231] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,233] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,235] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,235] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,236] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,237] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,237] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,238] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,239] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,240] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,240] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,241] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,242] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,242] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,243] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,244] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,244] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,245] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,245] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,246] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,247] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,248] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,249] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,250] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,251] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,252] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,253] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,254] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,255] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,255] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,256] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,256] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,257] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,258] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,258] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,259] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,260] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,260] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,260] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,261] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,262] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,263] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,264] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,265] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,266] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,266] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,267] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,268] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:22,269] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:22,269] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,270] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:22,270] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,271] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,272] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,272] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,273] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,274] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,275] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,275] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,276] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,276] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,277] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,279] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,281] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,281] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,282] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,283] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,284] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,287] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,289] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,289] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,291] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,291] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,292] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,293] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,294] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,294] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,295] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,296] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,297] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,298] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,299] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,301] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,302] {spark_submit.py:495} INFO - 23/03/03 12:15:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:22,303] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,303] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,304] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,305] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:22,306] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:22,306] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:22,307] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:22,308] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:22,309] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:22,310] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,310] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:22,311] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:22,311] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,312] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:22,313] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:22,314] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,315] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,316] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,317] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,317] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,318] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,319] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,319] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,321] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,321] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,322] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,323] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,324] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,325] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,325] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,327] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,327] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,328] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,329] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,329] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,330] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,331] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,332] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,333] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,334] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,334] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,336] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,339] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,340] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,341] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,342] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,343] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,343] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,344] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,344] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,345] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,346] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,347] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,350] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,351] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,352] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,352] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,353] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,353] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,354] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:22,355] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:22,355] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,356] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:22,356] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,357] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,358] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,358] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,359] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,360] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,360] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,361] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,364] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,364] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,365] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,366] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,366] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,367] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,368] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,368] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,369] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,370] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,371] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,371] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,372] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,372] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,373] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,374] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,375] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,375] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,376] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,376] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,377] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,378] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,379] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,380] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,381] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,381] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:22,382] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:22,383] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:22,384] {spark_submit.py:495} INFO - 23/03/03 12:15:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:22,385] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,386] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:22,387] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:22,388] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:22,389] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:22,389] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:22,390] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:22,391] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,391] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:22,392] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:22,393] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,393] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:22,394] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:22,394] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,395] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,396] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,397] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,397] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,398] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,399] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,399] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,400] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,401] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,401] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,402] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,402] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,403] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,403] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,404] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,405] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,406] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,406] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,407] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,408] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,408] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,409] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,409] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,410] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,410] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,411] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,413] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,414] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:22,416] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:22,421] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:22,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:22,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:22,423] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:22,423] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:22,424] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:22,424] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:22,425] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:22,425] {spark_submit.py:495} INFO - 23/03/03 12:15:21 ERROR Inbox: Ignoring error
[2023-03-03 12:15:22,426] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,427] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,427] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,428] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,428] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,430] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,431] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,432] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,432] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,433] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,433] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,434] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,436] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,438] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,438] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,439] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,439] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,440] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,440] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,442] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,442] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,443] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,443] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,445] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:15:22,445] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:15:22,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:15:22,447] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:15:22,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:15:22,448] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:15:22,449] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:15:22,450] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:15:22,450] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:15:22,451] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:15:22,451] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:22,452] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:22,452] {spark_submit.py:495} INFO - 23/03/03 12:15:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:22,453] {spark_submit.py:495} INFO - 23/03/03 12:15:21 ERROR Inbox: Ignoring error
[2023-03-03 12:15:22,453] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,454] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,455] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,456] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,457] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,457] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,458] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,458] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,459] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,459] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,460] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,461] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,461] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,462] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,463] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,464] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,464] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,465] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,465] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,466] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,467] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,468] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,468] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,468] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,469] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,469] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,471] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,471] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,473] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,473] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,475] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,475] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,476] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,476] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,477] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,477] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,478] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,479] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,480] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,481] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,481] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,482] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,482] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:22,483] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:22,483] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,484] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:22,484] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,485] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,486] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,486] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,487] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,487] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,489] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,490] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,490] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,491] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,491] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,493] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,496] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,497] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,498] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,499] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,499] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,500] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,500] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,504] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,505] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,505] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,505] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,506] {spark_submit.py:495} INFO - 23/03/03 12:15:21 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:22,507] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,507] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:22,509] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:22,510] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:22,510] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:22,511] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:22,511] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:22,512] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,512] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:22,513] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:22,514] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,514] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:22,515] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:22,515] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,516] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,517] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,517] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,517] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,518] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,518] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,519] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,520] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,520] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,521] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,521] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,521] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,522] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,522] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,523] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,524] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,524] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,525] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,525] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,526] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,526] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,527] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,527] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,528] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,529] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,530] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,531] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,531] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,532] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,532] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,533] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,533] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,534] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,534] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,535] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,535] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,536] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,536] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,537] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,538] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,538] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,539] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,539] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,540] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,541] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,541] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,542] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,543] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,543] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,543] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,544] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:22,544] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:22,545] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,546] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:22,547] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,547] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,548] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,548] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,549] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,549] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,550] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,551] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,552] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,552] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,553] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,554] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,554] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,555] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,555] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,557] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,558] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,558] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,559] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,559] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,560] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,560] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,561] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,561] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,562] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,563] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,563] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,564] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,564] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,565] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,565] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,566] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,567] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,568] {spark_submit.py:495} INFO - 23/03/03 12:15:22 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:22,569] {spark_submit.py:495} INFO - 23/03/03 12:15:22 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:22,572] {spark_submit.py:495} INFO - 23/03/03 12:15:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:22,573] {spark_submit.py:495} INFO - 23/03/03 12:15:22 ERROR Inbox: Ignoring error
[2023-03-03 12:15:22,574] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,575] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,575] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,576] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,577] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,577] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,578] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,579] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,579] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,580] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,581] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,582] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,582] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,583] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,584] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,585] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,586] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,588] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,590] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,592] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,593] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,593] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,594] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,595] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,596] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,596] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,597] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,598] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,599] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,599] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,602] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,602] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,605] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,606] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,618] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,619] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,619] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,620] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,620] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,621] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,622] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,622] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,623] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:22,623] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:22,624] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,624] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:22,625] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,626] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,626] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,627] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,627] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,628] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,628] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,629] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,630] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,631] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,631] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,632] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,633] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,634] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,635] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,636] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,637] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,637] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,638] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,639] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,639] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,641] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,641] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,642] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,643] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,643] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,644] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,644] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,646] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,646] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,647] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,648] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,649] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,649] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,650] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,651] {spark_submit.py:495} INFO - 23/03/03 12:15:22 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:22,652] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,653] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,653] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,654] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:22,654] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:22,655] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:22,656] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:22,656] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:22,657] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:22,658] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,658] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:22,659] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:22,659] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,660] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:22,660] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:22,661] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:22,661] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:22,661] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:22,662] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:22,663] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:22,664] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:22,664] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:22,665] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:22,666] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:22,666] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:22,667] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:22,667] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:22,668] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:22,668] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:22,669] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:22,669] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,670] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,670] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,671] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,671] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,672] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:22,673] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:22,673] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,674] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:22,674] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:22,675] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:22,675] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:22,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:22,676] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,677] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,677] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,678] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,678] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,679] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,690] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,714] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,715] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,717] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,720] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,720] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:22,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,722] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:22,722] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:22,723] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:22,723] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:22,724] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:22,724] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:22,725] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:22,725] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:22,726] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:22,726] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,727] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,727] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,728] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,728] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:22,730] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:22,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:22,732] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:22,733] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:22,733] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:22,734] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:22,735] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:22,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:22,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:22,736] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:22,737] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:22,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:22,738] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:22,739] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:22,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:22,740] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:22,740] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:22,741] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:22,741] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:22,742] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:22,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:22,743] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:22,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:22,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:22,746] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:22,749] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:22,750] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:22,751] {spark_submit.py:495} INFO - 23/03/03 12:15:22 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:22,752] {spark_submit.py:495} INFO - 23/03/03 12:15:22 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:22,752] {spark_submit.py:495} INFO - 23/03/03 12:15:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:15:23,138] {spark_submit.py:495} INFO - 23/03/03 12:15:22 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:15:23,202] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:23,202] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:23,203] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:23,204] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:15:23,204] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:15:23,204] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:15:23,205] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:15:23,205] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:15:23,206] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:15:23,206] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:23,207] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:15:23,207] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:15:23,208] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:23,208] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:15:23,209] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:15:23,210] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:23,210] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:23,211] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:23,211] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:23,212] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:23,213] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:23,213] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:23,214] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:23,214] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:23,214] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:23,215] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:23,215] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:23,216] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:23,216] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:23,217] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:23,217] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:23,218] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:23,218] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:23,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:23,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:23,220] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:23,220] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:23,221] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:23,221] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:23,222] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:23,222] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:23,223] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:23,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:23,223] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,224] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:23,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:23,225] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,226] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,226] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,227] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,227] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:23,228] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:23,228] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:23,229] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:23,229] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,230] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:23,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:23,231] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,232] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,232] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,232] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,233] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:23,233] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:23,234] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:23,234] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:23,235] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,235] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:23,236] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:23,236] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:23,237] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:23,237] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:23,238] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:23,239] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:23,239] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:23,240] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:23,240] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,240] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,241] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,242] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:23,242] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:23,242] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:23,243] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:23,244] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:23,244] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:23,245] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,246] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:23,246] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:23,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,248] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,248] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,249] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,249] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:23,250] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:23,250] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:23,251] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:23,251] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:23,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:23,252] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:23,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:23,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:23,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:23,254] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:23,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:23,255] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:23,256] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:23,256] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:23,257] {spark_submit.py:495} INFO - 23/03/03 12:15:22 ERROR Inbox: Ignoring error
[2023-03-03 12:15:23,261] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:15:23,261] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:15:23,263] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:15:23,263] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:15:23,264] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:15:23,264] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:15:23,265] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:15:23,265] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:15:23,266] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:15:23,267] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:15:23,267] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:15:23,268] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:15:23,268] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:23,269] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:23,270] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:23,270] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:23,271] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:23,271] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:15:23,272] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:15:23,272] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:15:23,273] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:15:23,273] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:15:23,274] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:15:23,274] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:15:23,275] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:15:23,275] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:15:23,276] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:15:23,276] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,277] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:23,279] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:23,280] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,281] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,281] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,282] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,283] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:23,284] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:23,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:23,285] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:23,286] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,287] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:23,287] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:23,288] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,289] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,289] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,290] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,290] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:23,291] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:23,292] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:23,292] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:15:23,293] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,293] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:15:23,295] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:15:23,296] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:15:23,297] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:15:23,298] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:15:23,298] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:15:23,299] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:15:23,300] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:15:23,300] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:15:23,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,304] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:15:23,304] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:15:23,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:15:23,306] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:15:23,306] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:15:23,307] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:15:23,308] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:15:23,309] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:15:23,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:15:23,310] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:15:23,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:15:23,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:15:23,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:15:23,313] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:15:23,316] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:15:23,318] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:15:23,319] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:15:23,320] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:15:23,321] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:15:23,321] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:15:23,322] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:15:23,323] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:15:23,323] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:15:23,324] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:15:23,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:15:23,325] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:15:23,326] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:15:23,327] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:15:23,409] {spark_submit.py:495} INFO - 23/03/03 12:15:23 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:15:23,547] {spark_submit.py:495} INFO - 23/03/03 12:15:23 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:15:24,005] {spark_submit.py:495} INFO - 23/03/03 12:15:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:16:50,057] {spark_submit.py:495} INFO - 23/03/03 12:16:49 ERROR Inbox: Ignoring error
[2023-03-03 12:16:50,058] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:16:50,059] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:16:50,059] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:16:50,060] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:16:50,060] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:16:50,061] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:16:50,061] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:16:50,062] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:16:50,062] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:16:50,063] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:16:50,064] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:16:50,064] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:16:50,065] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:16:50,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:16:50,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:16:50,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:16:50,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:16:50,068] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:16:50,068] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:16:50,069] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:16:50,070] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:16:50,070] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:16:50,071] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:16:50,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:16:50,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:16:50,073] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:16:50,073] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:16:50,074] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:50,074] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:50,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:50,075] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:50,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:16:50,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:16:50,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:16:50,077] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:16:50,078] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:16:50,079] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:16:50,079] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:16:50,080] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:16:50,080] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:16:50,081] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:16:50,081] {spark_submit.py:495} INFO - 23/03/03 12:16:49 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:16:50,082] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:16:50,083] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:16:50,083] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:16:50,084] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:16:50,084] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:16:50,085] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:16:50,085] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:16:50,086] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:16:50,087] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:16:50,087] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:16:50,088] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:16:50,089] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:16:50,089] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:16:50,090] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:16:50,090] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:16:50,091] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:16:50,091] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:16:50,092] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:16:50,092] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:16:50,093] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:16:50,094] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:16:50,094] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:16:50,095] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:16:50,096] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:16:50,096] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:16:50,097] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:16:50,097] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:16:50,098] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:16:50,099] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:16:50,100] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:16:50,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:16:50,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:16:50,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:16:50,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:16:50,103] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:16:50,103] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:16:50,104] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:16:50,105] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:16:50,106] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:16:50,106] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:16:50,107] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:16:50,108] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:16:50,108] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:16:50,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:50,110] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:50,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:50,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:50,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:16:50,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:16:50,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:16:50,114] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:16:50,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:16:50,116] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:16:50,116] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:16:50,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:16:50,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:16:50,119] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:16:50,160] {spark_submit.py:495} INFO - 23/03/03 12:16:50 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:16:50,161] {spark_submit.py:495} INFO - 23/03/03 12:16:50 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:16:50,162] {spark_submit.py:495} INFO - 23/03/03 12:16:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:16:46,754] {base_job.py:229} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/jobs/base_job.py", line 201, in heartbeat
    session.merge(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2877, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2950, in _merge
    merged = self.get(mapper.class_, key[1], identity_token=key[2])
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2702, in get
    identity_token=identity_token,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2800, in _get_impl
    load_options=load_options,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 535, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1669, in execute
    conn = self._connection_for_bind(bind, close_with_result=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1520, in _connection_for_bind
    engine, execution_options
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3095, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 91, in __init__
    else engine.raw_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3174, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3145, in _wrap_pool_connect
    e, dialect, self
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2004, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3141, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 301, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 755, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 419, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 259, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 247, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 362, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 605, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 599, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 583, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: http://sqlalche.me/e/14/e3q8)
[2023-03-03 12:16:51,356] {spark_submit.py:495} INFO - 23/03/03 12:16:50 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:16:51,383] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:16:51,384] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:16:51,384] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:16:51,385] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:16:51,385] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:16:51,386] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:16:51,387] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:16:51,387] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:16:51,388] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:16:51,389] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:16:51,389] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:16:51,390] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:16:51,390] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:16:51,391] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:16:51,392] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:16:51,392] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:16:51,393] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:16:51,393] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:16:51,394] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:16:51,394] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:16:51,395] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:16:51,395] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:16:51,396] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:16:51,397] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:16:51,397] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:16:51,398] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:16:51,398] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:16:51,399] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:16:51,400] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:16:51,400] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:16:51,401] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:16:51,401] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:16:51,402] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:16:51,403] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:16:51,403] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:16:51,404] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:16:51,405] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:16:51,405] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:16:51,406] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:16:51,406] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:16:51,407] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:16:51,408] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:16:51,408] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:16:51,409] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,409] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:51,410] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:51,411] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,412] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,413] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,414] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:16:51,414] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:16:51,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:16:51,415] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:16:51,416] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,416] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:51,417] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:51,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,418] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,419] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,419] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,420] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:16:51,421] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:16:51,421] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:16:51,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:16:51,422] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,423] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:16:51,424] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:16:51,424] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:16:51,425] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:16:51,425] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:16:51,426] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:16:51,426] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:16:51,427] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:16:51,427] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:16:51,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,428] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,429] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,429] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,430] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:16:51,430] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:16:51,431] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:16:51,432] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:16:51,432] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:16:51,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:16:51,434] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,434] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:51,435] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:51,435] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,435] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,436] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,437] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,438] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:16:51,438] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:16:51,438] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:16:51,439] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:16:51,439] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:16:51,440] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:16:51,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:16:51,445] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:16:51,446] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:16:51,447] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:16:51,447] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:16:51,448] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:16:51,448] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:16:51,449] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:16:51,449] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:16:51,450] {spark_submit.py:495} INFO - 23/03/03 12:16:50 ERROR Inbox: Ignoring error
[2023-03-03 12:16:51,450] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:16:51,451] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:16:51,451] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:16:51,451] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:16:51,452] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:16:51,452] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:16:51,453] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:16:51,454] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:16:51,455] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:16:51,455] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:16:51,456] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:16:51,456] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:16:51,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:16:51,457] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:16:51,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:16:51,458] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:16:51,459] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:16:51,459] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:16:51,460] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:16:51,460] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:16:51,461] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:16:51,461] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:16:51,462] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:16:51,463] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:16:51,464] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:16:51,464] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:16:51,465] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:16:51,465] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,466] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:51,466] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:51,467] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,467] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,468] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,468] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,469] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:16:51,469] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:16:51,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:16:51,471] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:16:51,471] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,472] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:51,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:51,473] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,474] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,475] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,475] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:16:51,476] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:16:51,476] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:16:51,477] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:16:51,477] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,478] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:16:51,479] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:16:51,479] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:16:51,480] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:16:51,480] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:16:51,481] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:16:51,481] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:16:51,482] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:16:51,483] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:16:51,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,484] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,484] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,485] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,486] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:16:51,486] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:16:51,488] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:16:51,489] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:16:51,490] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:16:51,490] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:16:51,491] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:16:51,491] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:16:51,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:16:51,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:16:51,493] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:16:51,494] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:16:51,495] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:16:51,496] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:16:51,496] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:16:51,497] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:16:51,497] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:16:51,498] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:16:51,498] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:16:51,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:16:51,500] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:16:51,500] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:16:51,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:16:51,501] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:16:51,502] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:16:51,503] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:16:51,504] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:16:51,504] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:16:53,194] {spark_submit.py:495} INFO - 23/03/03 12:16:52 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:16:53,480] {spark_submit.py:495} INFO - 23/03/03 12:16:53 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:16:53,873] {spark_submit.py:495} INFO - 23/03/03 12:16:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:02,483] {spark_submit.py:495} INFO - 23/03/03 12:17:00 ERROR Inbox: Ignoring error
[2023-03-03 12:17:02,777] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:02,875] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:02,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:02,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:02,877] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:02,878] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:02,878] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:02,879] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:02,879] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:02,880] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:02,881] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:02,881] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:02,881] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:02,882] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:02,883] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:02,883] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:02,884] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:02,884] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:02,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:02,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:02,886] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:02,886] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:02,887] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:02,887] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:02,888] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:02,888] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:02,889] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:02,889] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,890] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:02,890] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:02,891] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,892] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,892] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,893] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,894] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:02,894] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:02,895] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:02,895] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:02,896] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,896] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:02,897] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:02,897] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,898] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,899] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,899] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,900] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:02,900] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:02,901] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:02,901] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:02,902] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,903] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:02,903] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:02,904] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:02,904] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:02,905] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:02,905] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:02,906] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:02,906] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:02,907] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:02,907] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,908] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,909] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,910] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:02,911] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:02,912] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:02,912] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:02,913] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:02,913] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:02,914] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,914] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:02,915] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:02,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,916] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,917] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,918] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:02,919] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:02,919] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:02,920] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:02,920] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:02,921] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:02,922] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:02,922] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:02,923] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:02,923] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:02,924] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:02,924] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:02,925] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:02,926] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:02,926] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:02,941] {spark_submit.py:495} INFO - 23/03/03 12:17:00 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:02,941] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:02,942] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:02,942] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:02,943] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:02,944] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:02,944] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:02,945] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:02,945] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:02,946] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:02,946] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:02,947] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:02,947] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:02,948] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:02,948] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:02,949] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:02,949] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:02,950] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:02,950] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:02,951] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:02,951] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:02,952] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:02,952] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:02,953] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:02,953] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:02,954] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:02,954] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:02,955] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:02,955] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:02,956] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:02,956] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:02,957] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:02,957] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:02,958] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:02,958] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:02,959] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:02,959] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:02,960] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:02,961] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:02,961] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:02,962] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:02,962] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:02,963] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:02,963] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:02,964] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,964] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:02,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:02,965] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,967] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:02,968] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:02,968] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:02,969] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:02,969] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,970] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:02,970] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:02,971] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,972] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,973] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:02,973] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:02,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:02,974] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:02,975] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,975] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:02,976] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:02,977] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:02,977] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:02,978] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:02,978] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:02,979] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:02,979] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:02,980] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:02,980] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,981] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,982] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,982] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:02,983] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:02,984] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:02,984] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:02,984] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:02,985] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:02,985] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:02,986] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:02,986] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:02,987] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:02,987] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:02,988] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:02,988] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:02,989] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:02,989] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:02,990] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:02,990] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:02,991] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:02,991] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:02,992] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:02,992] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:02,993] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:02,994] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:02,994] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:02,995] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:02,996] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:02,996] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:02,996] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:08,851] {spark_submit.py:495} INFO - 23/03/03 12:17:08 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:09,387] {spark_submit.py:495} INFO - 23/03/03 12:17:09 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:09,978] {spark_submit.py:495} INFO - 23/03/03 12:17:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:15,872] {spark_submit.py:495} INFO - 23/03/03 12:17:12 ERROR Inbox: Ignoring error
[2023-03-03 12:17:16,028] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:16,376] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:16,603] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:16,604] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:16,604] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:16,605] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:16,605] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:16,606] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:16,606] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:16,607] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:16,608] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:16,609] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:16,609] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:16,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:16,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:16,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:16,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:16,612] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:16,612] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:16,613] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:16,614] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:16,614] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:16,615] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:16,615] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:16,616] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:16,617] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:16,617] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:16,618] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,618] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:16,619] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:16,620] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,621] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,621] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,622] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,622] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:16,623] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:16,623] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:16,625] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:16,626] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,626] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:16,627] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:16,628] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,628] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,629] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,629] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,630] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:16,631] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:16,631] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:16,632] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:16,633] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,633] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:16,634] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:16,635] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:16,636] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:16,636] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:16,637] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:16,638] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:16,638] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:16,639] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:16,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,641] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,642] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,643] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:16,644] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:16,645] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:16,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:16,646] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:16,647] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:16,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,648] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:16,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:16,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,651] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,652] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:16,652] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:16,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:16,654] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:16,654] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:16,655] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:16,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:16,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:16,657] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:16,658] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:16,659] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:16,660] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:16,661] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:16,661] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:16,662] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:16,662] {spark_submit.py:495} INFO - 23/03/03 12:17:12 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:16,663] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:16,663] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:16,664] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:16,665] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:16,665] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:16,666] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:16,666] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:16,667] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:16,668] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:16,668] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:16,669] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:16,670] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:16,670] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:16,671] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:16,671] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:16,672] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:16,673] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:16,674] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:16,675] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:16,675] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:16,676] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:16,677] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:16,678] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:16,678] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:16,679] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:16,680] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:16,681] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:16,681] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:16,682] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:16,683] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:16,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:16,684] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:16,685] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:16,686] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:16,686] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:16,687] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:16,688] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:16,688] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:16,689] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:16,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:16,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:16,691] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:16,692] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:16,693] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,693] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:16,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:16,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,696] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,696] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,698] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:16,699] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:16,699] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:16,700] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:16,700] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,701] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:16,701] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:16,702] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,704] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,705] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:16,705] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:16,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:16,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:16,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,708] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:16,709] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:16,710] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:16,710] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:16,711] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:16,711] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:16,712] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:16,712] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:16,713] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:16,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,714] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,715] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:16,716] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:16,716] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:16,717] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:16,717] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:16,718] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:16,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:16,719] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:16,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:16,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:16,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:16,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:16,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:16,722] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:16,722] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:16,723] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:16,723] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:16,724] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:16,724] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:16,725] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:16,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:16,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:16,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:16,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:16,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:16,729] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:16,729] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:16,730] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:17,980] {spark_submit.py:495} INFO - 23/03/03 12:17:17 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:17,981] {spark_submit.py:495} INFO - 23/03/03 12:17:17 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@435155df)) by listener AppStatusListener took 15.965682s.
[2023-03-03 12:17:17,982] {spark_submit.py:495} INFO - 23/03/03 12:17:17 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@435155df)) by listener HeartbeatReceiver took 1.0180177s.
[2023-03-03 12:17:17,983] {spark_submit.py:495} INFO - 23/03/03 12:17:17 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:17,984] {spark_submit.py:495} INFO - 23/03/03 12:17:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:18,021] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:18,022] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,023] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,023] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,024] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,025] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,025] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,026] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,026] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,027] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,028] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,028] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,029] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,030] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,031] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,032] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,033] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,033] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,034] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,035] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,035] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,036] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,036] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,037] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,038] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,039] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,041] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,042] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,042] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,043] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,044] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,046] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,046] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,047] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,048] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,049] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,049] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,050] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,050] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,051] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,051] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,052] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,053] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,053] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,054] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,055] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,056] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,057] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:18,057] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:18,058] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,059] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:18,059] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:18,060] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:18,060] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:18,061] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:18,061] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:18,062] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,063] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,063] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,064] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,064] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:18,065] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:18,066] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:18,066] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:18,067] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:18,068] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:18,068] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,069] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,069] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,070] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,071] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,071] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,072] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,073] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,074] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,075] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:18,076] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:18,076] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:18,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:18,078] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:18,079] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:18,080] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,081] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,082] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,082] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,083] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,083] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,084] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:18,085] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,085] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,086] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,086] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:18,087] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:18,088] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:18,088] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:18,089] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:18,090] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:18,090] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,091] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:18,092] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:18,092] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,093] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:18,093] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:18,094] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,094] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,095] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,095] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,096] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,097] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,098] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,098] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,099] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,100] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,101] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,101] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,102] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,102] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,103] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,103] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,104] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,105] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,105] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,106] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,106] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,107] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,108] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,108] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,108] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,109] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,110] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,110] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,111] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,112] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,113] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,114] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,114] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,115] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,116] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,116] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,117] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,118] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,119] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,120] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,120] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,121] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,121] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,122] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,123] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,124] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:18,124] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:18,125] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,126] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:18,126] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:18,127] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:18,128] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:18,131] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:18,132] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:18,132] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,133] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,134] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,134] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,135] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:18,136] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:18,136] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:18,138] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:18,139] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:18,140] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:18,141] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,143] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,145] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,146] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,147] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,148] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,149] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,149] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:18,150] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:18,150] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:18,151] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:18,152] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:18,153] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:18,154] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,155] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,155] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,157] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,158] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,159] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,160] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:18,161] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:18,162] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:18,163] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:18,164] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,165] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,165] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,166] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,167] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,167] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,168] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,168] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,169] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,170] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,170] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,171] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,172] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,172] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,173] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,174] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,175] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,176] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,177] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,177] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,178] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,179] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,179] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,180] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,180] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,181] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,182] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,183] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,184] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,184] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,185] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:18,186] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:18,186] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:18,187] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:18,188] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:18,188] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:18,189] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:18,190] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:18,191] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:18,191] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:18,193] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:18,193] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,194] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,195] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,196] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:18,197] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:18,198] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:18,199] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:18,199] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:18,200] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:18,201] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,201] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:18,202] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:18,203] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,203] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:18,204] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:18,204] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,205] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,205] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,206] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,206] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,208] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,210] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,211] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,212] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,215] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,216] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,216] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,217] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,218] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,219] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,221] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,222] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,222] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,223] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,223] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,225] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,226] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,228] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,229] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,230] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,231] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,232] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,233] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,233] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:18,234] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:18,236] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:18,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:18,240] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:18,241] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:18,249] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:18,250] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:18,251] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:18,251] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:18,252] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:18,253] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:18,254] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:18,254] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:18,255] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,256] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,257] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,258] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,259] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,259] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,260] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,262] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,266] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,269] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,271] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,275] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,276] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,278] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,279] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,280] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,282] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,283] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,284] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,285] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,286] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,287] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,288] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,289] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,289] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,291] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,297] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,299] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,299] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,300] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,313] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,316] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,317] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,320] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,322] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,325] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,328] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,330] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,337] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,338] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,340] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,340] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,343] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,343] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:18,344] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:18,345] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,346] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:18,348] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:18,349] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:18,350] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:18,351] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:18,355] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:18,357] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,362] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,364] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,364] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,365] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:18,366] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:18,368] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:18,368] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:18,369] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:18,369] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:18,371] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,372] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,373] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,374] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,375] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,376] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,377] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,377] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,378] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,379] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:18,380] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:18,380] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:18,382] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:18,383] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:18,384] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:18,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,386] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,388] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,389] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,390] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,391] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,392] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:18,393] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,394] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,395] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,396] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:18,397] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:18,397] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:18,398] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:18,399] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:18,400] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:18,402] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,403] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:18,405] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:18,407] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,408] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:18,411] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:18,413] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,415] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,417] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,418] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,419] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,421] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,422] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,423] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,424] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,425] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,425] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,427] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,429] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,430] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,430] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,431] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,433] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,436] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,436] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,437] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,437] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,438] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,439] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,439] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,443] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,444] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,445] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,446] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,447] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,448] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,449] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,450] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,451] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,452] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,452] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,453] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,454] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,454] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,455] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,455] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,456] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,457] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,458] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,459] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,460] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,461] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,461] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,462] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:18,463] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:18,464] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,464] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:18,466] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:18,467] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:18,468] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:18,469] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:18,470] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:18,470] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,472] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,473] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,474] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:18,474] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:18,475] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:18,476] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:18,477] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:18,478] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:18,479] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,480] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,482] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,483] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,484] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,486] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,487] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,487] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,489] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,489] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,491] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:18,491] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:18,492] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:18,492] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:18,493] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:18,494] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:18,494] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,495] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,496] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,508] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,508] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,509] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:18,511] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:18,512] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:18,515] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:18,517] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,520] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,534] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,536] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,537] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,538] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,539] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,546] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,548] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,550] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,551] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,551] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,552] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,553] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,554] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,555] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,555] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,556] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,558] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,559] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,559] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,563] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,564] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,565] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,567] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,569] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,571] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,572] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,572] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,573] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,574] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,575] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,576] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,576] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,577] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,578] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,591] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,602] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,602] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,604] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,605] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,607] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,608] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,608] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,610] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,611] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,612] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:18,612] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:18,613] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,614] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:18,615] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:18,616] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:18,617] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:18,621] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:18,627] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:18,634] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,635] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,636] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,637] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,638] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:18,638] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:18,640] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:18,641] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:18,642] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:18,643] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:18,644] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,646] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,647] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,648] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,649] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,650] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,651] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,652] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,653] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,653] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:18,654] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:18,654] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:18,655] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:18,656] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:18,657] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:18,658] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,660] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,660] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,662] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,663] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,664] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,665] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:18,666] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,667] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,668] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:18,669] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:18,670] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:18,670] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:18,671] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:18,672] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:18,673] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,674] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:18,678] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:18,678] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,679] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:18,681] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:18,683] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,685] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,686] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,687] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,687] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,688] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,690] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,691] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,692] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,692] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,694] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,695] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,696] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,697] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,697] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,698] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,698] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,699] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,700] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,701] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,701] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,702] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,702] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,703] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,704] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,705] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,706] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,707] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,708] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,709] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,710] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,711] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,712] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,713] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,714] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,715] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,717] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,718] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,719] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,720] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,720] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,721] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,721] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,722] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,723] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:18,724] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:18,724] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,725] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:18,725] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:18,726] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:18,728] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:18,728] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:18,729] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:18,730] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,731] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,732] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,733] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,734] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:18,734] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:18,735] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:18,735] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:18,736] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:18,736] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:18,737] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,737] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,738] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,739] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,740] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,741] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,741] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,742] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,742] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,743] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:18,743] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:18,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:18,744] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:18,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:18,745] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:18,746] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,747] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,747] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,748] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,751] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,752] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,754] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:18,754] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:18,755] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:18,755] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:18,756] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,757] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,758] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,759] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,760] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,760] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,761] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,763] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,764] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,765] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,765] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,767] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,767] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,768] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,769] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,770] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,770] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,771] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,771] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,772] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,773] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,775] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,775] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,776] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,777] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,778] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,779] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,780] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,780] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,788] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,789] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,790] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,791] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,792] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,792] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,794] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,795] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,796] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,798] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,800] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,803] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,806] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,810] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,815] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,815] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,827] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,828] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,829] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,831] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:18,834] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:18,835] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,836] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:18,836] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:18,837] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:18,838] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:18,838] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:18,839] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:18,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,840] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,841] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,843] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,844] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:18,846] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:18,847] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:18,847] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:18,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:18,849] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:18,850] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,851] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,851] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,852] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,853] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,853] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,854] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,854] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,855] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,856] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,857] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:18,858] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:18,859] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:18,860] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:18,861] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:18,865] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:18,867] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,868] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,869] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,870] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,871] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,872] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,873] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:18,873] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,874] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,875] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:18,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:18,877] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:18,879] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:18,880] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:18,881] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:18,881] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:18,882] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:18,884] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:18,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,885] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:18,886] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:18,887] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:18,887] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:18,888] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:18,889] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:18,890] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:18,890] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:18,891] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:18,893] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:18,894] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:18,895] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:18,896] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:18,896] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:18,897] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:18,898] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:18,899] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:18,907] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:18,908] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:18,908] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:18,909] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:18,910] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:18,911] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:18,912] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:18,913] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:18,913] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:18,915] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:18,917] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:18,919] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:18,922] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:18,925] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,926] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,927] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,927] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,928] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,929] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:18,930] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:18,931] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:18,932] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:18,934] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:18,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:18,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:18,945] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:18,947] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:18,948] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:18,961] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:18,967] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,009] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,010] {local_task_job.py:221} WARNING - State of this instance has been externally set to queued. Terminating instance.
[2023-03-03 12:17:19,010] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,012] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,012] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,013] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,018] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,018] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:19,019] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:19,020] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,021] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:19,021] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:19,022] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:19,024] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:19,025] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:19,026] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:19,027] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,028] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,036] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,036] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:19,037] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:19,038] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:19,039] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:19,039] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:19,040] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:19,042] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,043] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,044] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,050] {process_utils.py:129} INFO - Sending Signals.SIGTERM to group 1314. PIDs of all processes in the group: [1315, 1368, 1314]
[2023-03-03 12:17:19,051] {process_utils.py:80} INFO - Sending the signal Signals.SIGTERM to group 1314
[2023-03-03 12:17:19,075] {taskinstance.py:1541} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-03-03 12:17:19,077] {spark_submit.py:620} INFO - Sending kill signal to spark-submit
[2023-03-03 12:17:19,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,089] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,094] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,095] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,097] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:19,097] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:19,098] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:19,099] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:19,102] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:19,105] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:19,110] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,117] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,118] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,119] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,120] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,121] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,123] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:19,125] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:19,127] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:19,129] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:19,130] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,131] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,132] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:19,135] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:19,135] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:19,136] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:19,137] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:19,138] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:19,139] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:19,140] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:19,142] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:19,143] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,144] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,145] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,146] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,151] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,152] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:19,153] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:19,154] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:19,155] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:19,156] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:19,159] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:19,160] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:19,162] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:19,165] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:19,168] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,170] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,171] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,172] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,173] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:19,174] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:19,175] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:19,176] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:19,177] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:19,178] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:19,179] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:19,180] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:19,181] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:19,182] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:19,182] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:19,184] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,185] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,186] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,187] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:19,187] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:19,188] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:19,189] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:19,189] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:19,190] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:19,191] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,192] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:19,192] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:19,193] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,196] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:19,200] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:19,200] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:19,201] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:19,202] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:19,203] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,204] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,204] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,205] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:19,206] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:19,208] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:19,210] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:19,212] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:19,213] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:19,214] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:19,215] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:19,216] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:19,218] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,219] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,220] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,222] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,224] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,225] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,226] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:19,227] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,228] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:19,229] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:19,230] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:19,235] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:19,237] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:19,239] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,242] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,244] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,245] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,246] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:19,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:19,247] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:19,248] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:19,249] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:19,250] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:19,251] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:19,252] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:19,253] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:19,254] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:19,255] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:19,262] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:19,262] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:19,264] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:19,265] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,266] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,267] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,269] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:19,270] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:19,271] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:19,272] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:19,273] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:19,274] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:19,274] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:19,275] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:19,276] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:19,279] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,280] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,281] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,284] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,286] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,287] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,287] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:19,288] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:19,289] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:19,289] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:19,290] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:19,291] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:19,292] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:19,293] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:19,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:19,294] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,296] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,296] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,297] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,298] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,298] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,299] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,300] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,300] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,301] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,302] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,303] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,303] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,304] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,305] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,306] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,307] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,308] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,309] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,309] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,311] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,312] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,313] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:19,313] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:19,314] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,315] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:19,316] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:19,317] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:19,317] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:19,318] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:19,319] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:19,320] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,323] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,325] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,326] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,327] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:19,328] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:19,330] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:19,331] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:19,332] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:19,333] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:19,333] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,334] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,335] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,336] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,338] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,340] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,341] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,429] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,429] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,430] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,431] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:19,432] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:19,433] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:19,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:19,434] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:19,435] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:19,437] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,441] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,436] {process_utils.py:75} INFO - Process psutil.Process(pid=1368, status='terminated', started='11:41:50') (1368) terminated with exit code None
[2023-03-03 12:17:19,442] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,443] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,444] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,445] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,445] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:19,446] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,448] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,448] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,449] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:19,450] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:19,451] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:19,451] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:19,452] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:19,454] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:19,456] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,461] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:19,467] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:19,473] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,479] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:19,480] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:19,481] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:19,482] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:19,483] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:19,485] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,486] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,487] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,487] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:19,488] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:19,489] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:19,491] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:19,493] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:19,494] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:19,494] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:19,495] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:19,497] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:19,498] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,499] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,505] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,506] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,507] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,508] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,509] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:19,511] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,515] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:19,516] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:19,517] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:19,518] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:19,522] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:19,528] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,530] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,532] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,536] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,537] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,540] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,542] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,543] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,544] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,545] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,546] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,547] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,548] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,556] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,563] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,564] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,565] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,566] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,567] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,568] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,569] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,570] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,572] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,573] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:19,575] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:19,576] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,577] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:19,577] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:19,581] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:19,583] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:19,584] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:19,585] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:19,587] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,589] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,593] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,594] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,594] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:19,595] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:19,596] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:19,596] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:19,597] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:19,598] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:19,598] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,599] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,600] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,601] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,602] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,603] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,603] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,604] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,605] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,605] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:19,607] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:19,607] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:19,608] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:19,609] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:19,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:19,610] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,611] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,612] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,613] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,613] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,614] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,614] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:19,615] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:19,616] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:19,616] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:19,617] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,617] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,619] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:19,620] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:19,622] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:19,628] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:19,629] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:19,629] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:19,630] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,631] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:19,632] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:19,632] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,633] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:19,633] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:19,634] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:19,634] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:19,635] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:19,636] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,636] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,637] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,638] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:19,638] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:19,639] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:19,640] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:19,641] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:19,642] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:19,643] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:19,643] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:19,644] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:19,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,645] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,647] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,648] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,649] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,650] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,651] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:19,652] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,653] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:19,654] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:19,654] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:19,655] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:19,656] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:19,657] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,658] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,659] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,660] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,661] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,662] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,663] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,663] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,664] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,665] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,666] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,666] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,667] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,668] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,669] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,669] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,670] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,671] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,671] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,672] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,673] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:19,676] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:19,678] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,679] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:19,680] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:19,680] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:19,681] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:19,682] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:19,683] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:19,683] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,684] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,685] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,686] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,687] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:19,688] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:19,689] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:19,689] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:19,690] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:19,691] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:19,691] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,692] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,693] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,694] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,695] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,697] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,700] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,702] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,703] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,704] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:19,705] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:19,706] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:19,707] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:19,707] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:19,708] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:19,708] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,709] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,710] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,710] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,711] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,712] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,712] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:19,713] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,714] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,715] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,716] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:19,717] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:19,718] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:19,720] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:19,722] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:19,723] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:19,724] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:19,725] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:19,726] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:19,726] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,727] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,728] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,729] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,729] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,730] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,731] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:19,731] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:19,732] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:19,733] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:19,733] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:19,734] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:19,735] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:19,736] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:19,742] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:19,743] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,744] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,744] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,745] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,746] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,746] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,747] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,747] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,748] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,749] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,749] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,750] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,750] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,751] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,752] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,761] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,761] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,762] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,763] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,773] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,793] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,796] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2023-03-03 12:17:19,797] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,798] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2023-03-03 12:17:19,798] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2023-03-03 12:17:19,801] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,802] {spark_submit.py:495} INFO - at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2023-03-03 12:17:19,804] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2023-03-03 12:17:19,805] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2023-03-03 12:17:19,806] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2023-03-03 12:17:19,807] {spark_submit.py:495} INFO - at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2023-03-03 12:17:19,809] {spark_submit.py:495} INFO - at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2023-03-03 12:17:19,812] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,817] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,819] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,820] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,822] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2023-03-03 12:17:19,824] {spark_submit.py:495} INFO - at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2023-03-03 12:17:19,825] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2023-03-03 12:17:19,826] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2023-03-03 12:17:19,828] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2023-03-03 12:17:19,828] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2023-03-03 12:17:19,829] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,830] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,830] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,831] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2023-03-03 12:17:19,835] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2023-03-03 12:17:19,836] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2023-03-03 12:17:19,837] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete(Promise.scala:53)
[2023-03-03 12:17:19,838] {spark_submit.py:495} INFO - at scala.concurrent.Promise.complete$(Promise.scala:52)
[2023-03-03 12:17:19,839] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2023-03-03 12:17:19,842] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success(Promise.scala:86)
[2023-03-03 12:17:19,844] {spark_submit.py:495} INFO - at scala.concurrent.Promise.success$(Promise.scala:86)
[2023-03-03 12:17:19,846] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2023-03-03 12:17:19,847] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2023-03-03 12:17:19,847] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2023-03-03 12:17:19,848] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2023-03-03 12:17:19,853] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,855] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,861] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,862] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,865] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,865] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:19,866] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:19,870] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:19,871] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:19,872] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:19,875] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,875] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,876] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,877] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:19,877] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:19,878] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:19,878] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:19,879] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:19,889] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:19,892] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:19,895] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:19,896] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:19,897] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:19,898] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:19,898] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:19,899] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:19,901] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:19,901] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:19,903] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:19,912] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:19,913] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:19,914] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:19,915] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:19,916] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:19,917] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:19,919] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:19,921] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:19,922] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:19,926] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:19,933] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:19,935] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:19,936] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:19,941] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:19,944] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:19,946] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:19,948] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:19,953] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:19,954] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:19,966] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:19,968] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:19,969] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:19,971] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:19,973] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:19,976] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:19,982] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:19,985] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:19,990] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:19,995] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:19,996] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:19,997] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:19,998] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:19,998] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:19,999] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:20,000] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:20,001] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:20,002] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:20,003] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:20,005] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:20,007] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:20,008] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:20,009] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:20,010] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:20,010] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:20,012] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:20,013] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:20,014] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:20,015] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:20,015] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:20,016] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:20,017] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:20,018] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:20,018] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:20,019] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:20,020] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:20,023] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:20,024] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:20,026] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:20,027] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:20,029] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:20,030] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:20,030] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:20,031] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:20,032] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:20,032] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:20,033] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:20,034] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:20,036] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:20,037] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:20,040] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:20,043] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:20,044] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:20,045] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:20,046] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:20,047] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:20,048] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:20,049] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:20,049] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:20,052] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:20,053] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:20,054] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:20,055] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:20,056] {spark_submit.py:495} INFO - 23/03/03 12:17:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:20,057] {spark_submit.py:495} INFO - 23/03/03 12:17:18 ERROR Inbox: Ignoring error
[2023-03-03 12:17:20,058] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:20,060] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:20,061] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:20,062] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:20,064] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:20,065] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:20,066] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:20,069] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:20,069] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:20,070] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:20,071] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:20,071] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:20,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:20,072] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:20,076] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:20,077] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:20,078] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:20,078] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:20,079] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:20,079] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:20,080] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:20,081] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:20,081] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:20,082] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:20,083] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:20,084] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:20,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:20,085] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:20,086] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:20,087] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:20,090] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:20,092] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:20,093] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:20,094] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:20,095] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:20,096] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:20,098] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:20,100] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:20,101] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:20,101] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:20,102] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:20,103] {spark_submit.py:495} INFO - 23/03/03 12:17:18 WARN Executor: Issue communicating with driver in heartbeater
[2023-03-03 12:17:20,103] {spark_submit.py:495} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:20,104] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:20,105] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:20,105] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
[2023-03-03 12:17:20,106] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)
[2023-03-03 12:17:20,107] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2023-03-03 12:17:20,108] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)
[2023-03-03 12:17:20,109] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)
[2023-03-03 12:17:20,110] {spark_submit.py:495} INFO - at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)
[2023-03-03 12:17:20,110] {spark_submit.py:495} INFO - at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2023-03-03 12:17:20,111] {spark_submit.py:495} INFO - at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
[2023-03-03 12:17:20,112] {spark_submit.py:495} INFO - at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2023-03-03 12:17:20,113] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:20,115] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
[2023-03-03 12:17:20,116] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
[2023-03-03 12:17:20,117] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2023-03-03 12:17:20,118] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2023-03-03 12:17:20,118] {spark_submit.py:495} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2023-03-03 12:17:20,119] {spark_submit.py:495} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2023-03-03 12:17:20,120] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
[2023-03-03 12:17:20,120] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2023-03-03 12:17:20,122] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2023-03-03 12:17:20,122] {spark_submit.py:495} INFO - at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2023-03-03 12:17:20,123] {spark_submit.py:495} INFO - at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2023-03-03 12:17:20,123] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2023-03-03 12:17:20,124] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2023-03-03 12:17:20,125] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)
[2023-03-03 12:17:20,125] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)
[2023-03-03 12:17:20,126] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)
[2023-03-03 12:17:20,126] {spark_submit.py:495} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2023-03-03 12:17:20,127] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2023-03-03 12:17:20,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2023-03-03 12:17:20,128] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2023-03-03 12:17:20,129] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2023-03-03 12:17:20,129] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2023-03-03 12:17:20,130] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2023-03-03 12:17:20,131] {spark_submit.py:495} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2023-03-03 12:17:20,131] {spark_submit.py:495} INFO - ... 3 more
[2023-03-03 12:17:20,132] {spark_submit.py:495} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@7f5e973bdd66:34603
[2023-03-03 12:17:20,132] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2023-03-03 12:17:20,133] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2023-03-03 12:17:20,133] {spark_submit.py:495} INFO - at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2023-03-03 12:17:20,134] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2023-03-03 12:17:20,135] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2023-03-03 12:17:20,135] {spark_submit.py:495} INFO - at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2023-03-03 12:17:20,137] {spark_submit.py:495} INFO - at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2023-03-03 12:17:20,138] {spark_submit.py:495} INFO - at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2023-03-03 12:17:20,139] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)
[2023-03-03 12:17:20,142] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)
[2023-03-03 12:17:20,143] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith(Promise.scala:40)
[2023-03-03 12:17:20,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)
[2023-03-03 12:17:20,144] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)
[2023-03-03 12:17:20,145] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap(Future.scala:306)
[2023-03-03 12:17:20,145] {spark_submit.py:495} INFO - at scala.concurrent.Future.flatMap$(Future.scala:306)
[2023-03-03 12:17:20,146] {spark_submit.py:495} INFO - at scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)
[2023-03-03 12:17:20,147] {spark_submit.py:495} INFO - at org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)
[2023-03-03 12:17:20,147] {spark_submit.py:495} INFO - ... 19 more
[2023-03-03 12:17:20,148] {spark_submit.py:495} INFO - 23/03/03 12:17:19 INFO Executor: Told to re-register on heartbeat
[2023-03-03 12:17:20,148] {spark_submit.py:495} INFO - 23/03/03 12:17:19 INFO BlockManager: BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None) re-registering with master
[2023-03-03 12:17:20,149] {spark_submit.py:495} INFO - 23/03/03 12:17:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7f5e973bdd66, 42669, None)
[2023-03-03 12:17:20,172] {process_utils.py:75} INFO - Process psutil.Process(pid=1315, status='terminated', started='11:41:44') (1315) terminated with exit code None
[2023-03-03 12:17:20,210] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/usr/local/lib/python3.7/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 427, in submit
    f"Cannot execute: {self._mask_cmd(spark_submit_cmd)}. Error code is: {returncode}."
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master local[*] --name arrow-spark /hadoop-data/map_reduce/spark/average_price.py. Error code is: -9.
[2023-03-03 12:17:20,233] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=avg_product_price, task_id=spark_submit, execution_date=20230303T114142, start_date=20230303T121718, end_date=20230303T121720
[2023-03-03 12:17:20,275] {standard_task_runner.py:97} ERROR - Failed to execute job 11 for task spark_submit (Cannot execute: spark-submit --master local[*] --name arrow-spark /hadoop-data/map_reduce/spark/average_price.py. Error code is: -9.; 1314)
[2023-03-03 12:17:20,306] {process_utils.py:75} INFO - Process psutil.Process(pid=1314, status='terminated', exitcode=1, started='11:41:44') (1314) terminated with exit code 1
